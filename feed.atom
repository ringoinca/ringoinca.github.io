<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Through the Looking-Glass</title>
  <subtitle>Mort’s random homepage.</subtitle>
  <link rel="alternate" type="text/html" href="https://www.soimort.org/" />
  <link rel="self" type="application/atom+xml" href="https://www.soimort.org/feed.atom" />
  <id>tag:www.soimort.org,2017:/</id>
  <updated>2017-09-02T00:00:00+02:00</updated>
  <author>
    <name>Mort Yao</name>
    <email>soi@mort.ninja</email>
  </author>

  <entry>
    <title>When GNOME Shell Freezes (But You Have Unsaved Stuff There)</title>
    <link rel="alternate" type="text/html" href="https://www.soimort.org/notes/170902" />
    <id>tag:www.soimort.org,2017:/notes/170902</id>
    <published>2017-09-02T00:00:00+02:00</published>
    <updated>2017-09-02T00:00:00+02:00</updated>
    <author>
      <name>Mort Yao</name>
    </author>
    
    <content type="html" xml:lang="en" xml:base="https://www.soimort.org/">
<![CDATA[
<p>In the past few months, I was running into the mysterious bug that GNOME Shell crashes with a segfault in <code>libgjs.so.0.0.0</code>, leaving me an unresponsive desktop:</p>
<pre><code>  kernel: gnome-shell[963]: segfault at 7f06645fffe8 ip 00007f06d94898dd
  sp 00007fff562ee7e0 error 4 in libgjs.so.0.0.0[7f06d9</code></pre>
<p>On crashing GNOME Shell does not restart itself correctly, nor <code>gnome-shell</code> processes are actually terminated, for some unknown reason. When this happens Mutter is completely frozen, <kbd>Alt</kbd>+<kbd>F2</kbd> is unavailable; what’s even worse, <kbd>Ctrl</kbd>+<kbd>Alt</kbd>+<kbd>F3</kbd> can’t get you a lifesaving TTY.</p>
<p>Clearly, the only way one can access the box then is via SSH. But what to do next? While it is possible to simply restart <code>gdm</code> like: (for systemd users)</p>
<pre><code>$ systemctl restart gdm</code></pre>
<p>This would, however, destroy the whole X session and all your open GUI processes will be lost! A desirable, more elegant approach is to restart <code>gnome-shell</code> alone, but this requires a few tricks in case you’re working through <code>ssh</code> and <code>killall -9 gnome-shell</code> doesn’t restart GNOME Shell properly.</p>
<ol type="1">
<li>Login to the (borked) remote machine, and enable X11 Forwarding in its SSH daemon by modifying <code>/etc/ssh/sshd_config</code>, if you’ve never done it before:<br />
(Note that this option is not the default on most distros; you’ll have to restart <code>sshd</code> on the remote machine after then.)</li>
</ol>
<pre><code>        X11Forwarding yes</code></pre>
<ol start="2" type="1">
<li>Login to the remote machine again, with X11 forwarding enabled this time:</li>
</ol>
<pre><code>        $ ssh yourUser@yourHost -X</code></pre>
<ol start="3" type="1">
<li>On the borked remote machine, kill all the FUBARed <code>gnome-shell</code> processes, if any:</li>
</ol>
<pre><code>        $ pkill gnome-shell</code></pre>
<ol start="4" type="1">
<li>Set the correct <code>DISPLAY</code> environment otherwise you won’t be able to run a WM from a remote shell:</li>
</ol>
<pre><code>        $ export DISPLAY=:0</code></pre>
<ol start="5" type="1">
<li>Bring back the GNOME Shell WM, detached (so it can keep running after closing the remote shell):</li>
</ol>
<pre><code>        $ setsid gnome-shell</code></pre>
<p><strong>Related Gjs bug(s).</strong> The bug was there since gjs 1.48 and has been reported multiple times: <a href="https://bugzilla.gnome.org/show_bug.cgi?id=781799">#781799</a>, <a href="https://bugzilla.gnome.org/show_bug.cgi?id=783935">#783935</a>, <a href="https://bugzilla.gnome.org/show_bug.cgi?id=785657">#785657</a>. Still, a recent gjs 1.49 build crashes my desktop: ( It seems rather hard to find out what would trigger the issue, but no more worries when it bumps in the night – Just get back the WM and no running window is lost.</p>

]]>
    </content>
  </entry>
  <entry>
    <title>Understanding Colors – A Walkthrough of Modern Color Theory and Practice</title>
    <link rel="alternate" type="text/html" href="https://blog.soimort.org/cv/colors/" />
    <id>tag:www.soimort.org,2017:/posts/170803</id>
    <published>2017-08-03T00:00:00+02:00</published>
    <updated>2017-08-03T00:00:00+02:00</updated>
    <author>
      <name>Mort Yao</name>
    </author>
    <category term="blog" />
    <content type="html" xml:lang="en" xml:base="https://www.soimort.org/">
<![CDATA[


]]>
    </content>
  </entry>
  <entry>
    <title>The Stateful Automata</title>
    <link rel="alternate" type="text/html" href="https://www.soimort.org/mst/6" />
    <id>tag:www.soimort.org,2017:/mst/6</id>
    <published>2017-04-12T00:00:00+02:00</published>
    <updated>2017-04-18T00:00:00+02:00</updated>
    <author>
      <name>Mort Yao</name>
    </author>
    
    <content type="html" xml:lang="en" xml:base="https://www.soimort.org/">
<![CDATA[
<ul>
<li>What is a <a href="https://wiki.soimort.org/comp/language/">formal language</a>? (review of <a href="/mst/1/">Mst. #1</a>)
<ul>
<li>An <em>alphabet</em> <span class="math inline">\(\Sigma\)</span> is a well-defined set of symbols. A <em>string</em> is a sequence of symbols.</li>
<li>A <em>language</em> <span class="math inline">\(L\)</span> over alphabet <span class="math inline">\(\Sigma\)</span> is a set of strings, where each string <span class="math inline">\(w \in \Sigma^*\)</span>.</li>
<li>We can define a <em>class of languages</em> (which is a set of languages with some common properties).</li>
<li>Operations on languages (as sets): <em>union</em>, <em>intersection</em>, <em>complement</em>, <em>concatenation</em>, <em>Kleene star</em>.</li>
<li>A class of languages is said to be <em>closed under some operation</em>, if the operation yields a language that is in the same class. (closure properties)</li>
</ul></li>
<li><a href="https://wiki.soimort.org/comp/language/finite/"><strong>Finite language</strong></a>: Any finite set of strings.
<ul>
<li>Closure properties: FL is closed under union, intersection and concatenation. (but not under complementation or Kleene star)</li>
</ul></li>
<li><a href="https://wiki.soimort.org/comp/language/regular/"><strong>Regular language</strong></a>: Any language that is recognized by a DFA.
<ul>
<li>Closure properties: RL is closed under union, concatenation and Kleene star. (<em>regular operations</em>)</li>
<li>Equivalent models and conversions:
<ul>
<li><strong>DFA</strong> (Deterministic finite automaton)</li>
<li><strong>NFA</strong> (Nondeterministic finite automaton)
<ul>
<li>DFA to NFA: trivial (every DFA is an NFA).</li>
<li>NFA to DFA: powerset (Rabin-Scott construction).</li>
</ul></li>
<li><strong>Regular expression</strong>
<ul>
<li>RegExp to NFA: structural induction (Thompson’s construction).</li>
<li>RegExp to DFA: via NFA (structural induction and powerset).</li>
<li>NFA to RegExp: via GNFA (node removal).</li>
<li>DFA to RegExp: Kleene’s algorithm.</li>
</ul></li>
</ul></li>
<li>Show that a language is regular:
<ol type="1">
<li>By construction: find a DFA/NFA that recognizes it or a RegExp that describes it.</li>
<li>By the Myhill-Nerode theorem.</li>
<li>By hierarchy: every finite language is regular.</li>
</ol></li>
<li>Show that a language is <em>not</em> regular:
<ol type="1">
<li>By the pumping lemma.</li>
<li>By the Myhill-Nerode theorem.</li>
</ol></li>
</ul></li>
</ul>
<figure>
<img src="https://i0.wp.com/dl.dropboxusercontent.com/s/i05152kpetd8xyc/fsm.png" alt="Conversion among different models of RL" style="width:75.0%" /><figcaption>Conversion among different models of RL</figcaption>
</figure>
<ul>
<li>(Nondeterministic) <a href="https://wiki.soimort.org/comp/language/context-free/"><strong>Context-free language</strong></a>: Any language that is generated by a context-free grammar.
<ul>
<li>Closure properties: CFL is closed under union, concatenation and Kleene star. (but not under complementation or intersection)</li>
<li>Equivalent models:
<ul>
<li><strong>Context-free grammar</strong>
<ul>
<li>Every CFG can be converted into <em>Chomsky normal form</em>.</li>
</ul></li>
<li><strong>PDA</strong> (Nondeterministic pushdown automaton)
<ul>
<li>Finite automaton + 1 infinite stack</li>
</ul></li>
</ul></li>
<li>Show that a language is context-free:
<ol type="1">
<li>By construction: find a CFG that generates it or a PDA that recognizes it.</li>
<li>By hierarchy: every regular language is context-free.</li>
</ol></li>
<li>Show that a language is <em>not</em> context-free:
<ol type="1">
<li>By the pumping lemma.</li>
</ol></li>
</ul></li>
<li><a href="https://wiki.soimort.org/comp/church-turing/">Church-Turing thesis</a>
<ul>
<li>It is (informally) a “thesis” because it cannot be formalized as a provable proposition (since we use it to give a notion for what a <em>computation</em> is).</li>
<li>Computation may be performed on <em>unrestricted languages</em>:
<ul>
<li><em>Recognizing</em> a language <span class="math inline">\(L\)</span>:
<ul>
<li>For every string <span class="math inline">\(w \in L\)</span>, the machine <span class="math inline">\(M\)</span> must <em>accept</em> it.</li>
<li>We call such a machine <span class="math inline">\(M\)</span> an <em>acceptor</em> or a <em>recognizer</em> of the language <span class="math inline">\(L\)</span>.</li>
</ul></li>
<li><em>Deciding</em> a language <span class="math inline">\(L\)</span>:
<ul>
<li>For every string <span class="math inline">\(w \in L\)</span>, the machine <span class="math inline">\(M\)</span> must <em>accept</em> it; moreover, for every <span class="math inline">\(w \notin L\)</span>, the machine <span class="math inline">\(M\)</span> must <em>reject</em> it. That is, the machine <span class="math inline">\(M\)</span> must halt on every input <span class="math inline">\(w\)</span>.</li>
<li>We call such a machine <span class="math inline">\(M\)</span> a <em>decider</em> of the language <span class="math inline">\(L\)</span>.</li>
</ul></li>
</ul></li>
<li>Equivalent <em>Turing-complete models of computation</em>:
<ul>
<li>(Single-tape, deterministic, read-write) <strong>Turing machine</strong>
<ul>
<li>Finite automaton + 1 infinite linear table (or 2 infinite stacks)</li>
</ul></li>
<li>Multi-tape Turing machine</li>
<li>Nondeterministic Turing machine</li>
<li>Enumerator</li>
<li>Abstract rewriting system</li>
<li>Lambda calculus (combinatory logic)</li>
<li>…</li>
</ul></li>
<li>The Church-Turing thesis claims that all Turing-complete models are equivalent in their abilities to compute (recognize / decide a language).</li>
<li>There are some languages that cannot be recognized by any Turing machine, that is, <strong>unrecognizable languages</strong> exist. (shown by the diagonal method)</li>
<li><strong>Turing-recognizable language</strong>: Any language that is recognized by a Turing machine.
<ul>
<li>Closure properties: closed under union, intersection, concatenation and Kleene star. (but not under complementation)</li>
</ul></li>
<li><strong>Co-Turing-recognizable language</strong>: Any language whose complement is recognized by a Turing machine.</li>
<li><strong>Turing-decidable language</strong> (or simply <strong>decidable language</strong>): Any language that is decided by a Turing machine.
<ul>
<li>A language is decidable if and only if it is both Turing-recognizable and co-Turing-recognizable.</li>
<li>Closure properties: closed under union, intersection, complementation, concatenation and Kleene star.</li>
</ul></li>
<li>Show that a language is Turing-recognizable:
<ol type="1">
<li>By construction: find a Turing machine that recognizes it.</li>
<li>By mapping reducibility: <span class="math inline">\(L \leq_\text{m} L&#39;\)</span>, where <span class="math inline">\(L&#39;\)</span> is Turing-recognizable.</li>
<li>By hierarchy: any context-sensitive language (thus also context-free language or regular language) is Turing-recognizable.</li>
</ol></li>
<li>Show that a language is <em>not</em> Turing-recognizable:
<ol type="1">
<li>By contraposition: we already know that <span class="math inline">\(\overline{L}\)</span> is Turing-recognizable; if <span class="math inline">\(L\)</span> is Turing-recognizable, then <span class="math inline">\(L\)</span> would be decidable. But we know that <span class="math inline">\(L\)</span> is undecidable, thus <span class="math inline">\(L\)</span> cannot be Turing-recognizable.</li>
<li>By mapping reducibility: <span class="math inline">\(L&#39; \leq_\text{m} L\)</span>, where <span class="math inline">\(L&#39;\)</span> is not Turing-recognizable.</li>
</ol></li>
<li>Show that a language is decidable:
<ol type="1">
<li>By construction: find a Turing machine that decides it.</li>
<li>Show that it is both Turing-recognizable and co-Turing-recognizable.</li>
<li>By mapping reducibility: <span class="math inline">\(L \leq_\text{m} L&#39;\)</span>, where <span class="math inline">\(L&#39;\)</span> is decidable.</li>
<li>By Turing reducibility: <span class="math inline">\(L \leq_\text{T} L&#39;\)</span>, where <span class="math inline">\(L&#39;\)</span> is decidable.</li>
<li>By hierarchy: any context-sensitive language (thus also context-free language or regular language) is decidable.</li>
</ol></li>
<li>Show that a language is <em>undecidable</em>:
<ol type="1">
<li>By mapping reducibility: <span class="math inline">\(L&#39; \leq_\text{m} L\)</span>, where <span class="math inline">\(L&#39;\)</span> is undecidable.</li>
<li>By Rice’s theorem.</li>
</ol></li>
</ul></li>
</ul>
<section id="chomsky-hierarchy-of-languages-grammars-and-automata" class="level2">
<h2>Chomsky hierarchy of languages, grammars and automata</h2>
<p><span class="math display">\[\text{FL} \subsetneq \text{RL} \subsetneq \text{DCFL} \subsetneq \text{CFL} \subsetneq \text{CSL} \subsetneq \text{R} \subsetneq \text{U} \subsetneq \mathcal{P}(\mathcal{P}(\Sigma^*))
\]</span></p>
<ul>
<li>FL (<strong>Finite languages</strong>), described by finite enumeration, recognized by finite Boolean circuits.</li>
<li>RL (<strong>Regular languages</strong>, Type-3 grammars), described by regular expressions, recognized by DFAs/NFAs.</li>
<li>DCFL (<strong>Deterministic context-free languages</strong>), described by deterministic context-free grammars, recognized by deterministic pushdown automata.</li>
<li>CFL (<strong>Context-free languages</strong>, Type-2 grammars), described by nondeterministic context–free grammars, recognized by nondeterministic pushdown automata.</li>
<li>CSL (<strong>Context-sensitive languages</strong>, Type-1 grammars), described by context-sensitive grammars, recognized by linear bounded automata (restricted form of Turing machines).</li>
<li>R (<strong>Turing-decidable languages</strong> or <strong>recursive languages</strong>), described by recursive grammars, recognized by Turing machines that always halt (i.e., deciders).</li>
<li>U (<strong>Turing-recognizable languages</strong> or <strong>recursively enumerable languages</strong>, Type-0 grammars), described by unrestricted grammars, recognized by Turing machines (but not guaranteed to halt thus not necessarily decidable).</li>
<li><span class="math inline">\(\mathcal{P}(\mathcal{P}(\Sigma^*))\)</span>, may have unrestricted grammars or no grammar at all, not necessarily Turing-recognizable.</li>
</ul>
<p><em>Grammars</em> provide a mathematical, recursive perspective for describing languages, while <em>automata</em> provide a physically implementable, iterative approach of recognizing languages (via finite states and possibly infinite stacks). A language is Turing-recognizable if and only if it has a well-defined grammar (so that it’s possible to construct some Turing machine that recognizes it), although it can sometimes be hard to formulate. Quite naturally, if we cannot specify a grammar for a language <span class="math inline">\(L \subset \mathcal{P}(\Sigma^*)\)</span> theoretically, it would be impossible to construct a Turing machine that recognizes it.</p>
</section>
<section id="decidability-and-undecidability" class="level2">
<h2>Decidability and undecidability</h2>
<p>We consider mainly three types of decision problems concerning different computational models: (generative grammars may be viewed as a form of machines like automata, in the following setting)</p>
<ol type="1">
<li>Acceptance problem: <span class="math inline">\(A_\mathsf{X} = \{ \langle M, w\rangle\ |\ M \text{ is a machine of type } X \text{, and } M \text{ accepts } w \}\)</span>.</li>
<li>Emptiness problem: <span class="math inline">\(E_\mathsf{X} = \{ \langle M \rangle\ |\ M \text{ is a machine of type } X \text{, and } \mathcal{L}(M) = \emptyset \}\)</span>.</li>
<li>Equality problem: <span class="math inline">\(EQ_\mathsf{X} = \{ \langle M_1, M_2 \rangle\ |\ M_1 \text{ and } M_2 \text{ are machines of type } X \text{, and } \mathcal{L}(M_1) = \mathcal{L}(M_2) \}\)</span>.</li>
</ol>
<table style="width:96%;">
<colgroup>
<col style="width: 8%" />
<col style="width: 12%" />
<col style="width: 26%" />
<col style="width: 25%" />
<col style="width: 23%" />
</colgroup>
<thead>
<tr class="header">
<th>Model</th>
<th>Language</th>
<th>Acceptance problem</th>
<th>Emptiness problem</th>
<th>Equality problem</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>DFA <br>(Deterministic finite automaton)</td>
<td>Regular language: <strong><em>decidable</em></strong></td>
<td><span class="math inline">\(A_\textsf{DFA}\)</span>: <strong><em>decidable</em></strong></td>
<td><span class="math inline">\(E_\textsf{DFA}\)</span>: <strong><em>decidable</em></strong></td>
<td><span class="math inline">\(EQ_\textsf{DFA}\)</span>: <strong><em>decidable</em></strong></td>
</tr>
<tr class="even">
<td>NFA <br>(Nondeterministic finite automaton)</td>
<td>Regular language: <strong>decidable</strong></td>
<td><span class="math inline">\(A_\textsf{NFA}\)</span>: <strong><em>decidable</em></strong></td>
<td><span class="math inline">\(E_\textsf{NFA}\)</span>: <strong><em>decidable</em></strong></td>
<td><span class="math inline">\(EQ_\textsf{NFA}\)</span>: <strong><em>decidable</em></strong></td>
</tr>
<tr class="odd">
<td>Regular expression</td>
<td>Regular language: <strong><em>decidable</em></strong></td>
<td><span class="math inline">\(A_\textsf{REX}\)</span>: <strong><em>decidable</em></strong></td>
<td><span class="math inline">\(E_\textsf{REX}\)</span>: <strong><em>decidable</em></strong></td>
<td><span class="math inline">\(EQ_\textsf{REX}\)</span>: <strong><em>decidable</em></strong></td>
</tr>
<tr class="even">
<td>CFG <br>(Context-free grammar)</td>
<td>Context-free language: <strong><em>decidable</em></strong></td>
<td><span class="math inline">\(A_\textsf{CFG}\)</span>: <strong><em>decidable</em></strong></td>
<td><span class="math inline">\(E_\textsf{CFG}\)</span>: <strong><em>decidable</em></strong></td>
<td><span class="math inline">\(EQ_\textsf{CFG}\)</span>: <em>undecidable</em></td>
</tr>
<tr class="odd">
<td>PDA <br>(Pushdown automaton)</td>
<td>Context-free language: <strong><em>decidable</em></strong></td>
<td><span class="math inline">\(A_\textsf{PDA}\)</span>: <strong><em>decidable</em></strong></td>
<td><span class="math inline">\(E_\textsf{PDA}\)</span>: <strong><em>decidable</em></strong></td>
<td><span class="math inline">\(EQ_\textsf{PDA}\)</span>: <em>undecidable</em></td>
</tr>
<tr class="even">
<td>CSG <br>(Context-sensitive grammar)</td>
<td>Context-sensitive language: <strong><em>decidable</em></strong></td>
<td><span class="math inline">\(A_\textsf{CSG}\)</span>: <strong><em>decidable</em></strong></td>
<td><span class="math inline">\(E_\textsf{CSG}\)</span>: <em>undecidable</em></td>
<td><span class="math inline">\(EQ_\textsf{CSG}\)</span>: <em>undecidable</em></td>
</tr>
<tr class="odd">
<td>LBA <br>(Linear bounded automaton)</td>
<td>Context-sensitive language: <strong><em>decidable</em></strong></td>
<td><span class="math inline">\(A_\textsf{LBA}\)</span>: <strong><em>decidable</em></strong></td>
<td><span class="math inline">\(E_\textsf{LBA}\)</span>: <em>undecidable</em></td>
<td><span class="math inline">\(EQ_\textsf{LBA}\)</span>: <em>undecidable</em></td>
</tr>
<tr class="even">
<td>Turing machine and equivalent Turing-complete models</td>
<td>Turing-recognizable language: may be <strong><em>decidable</em></strong> or <em>undecidable</em></td>
<td><span class="math inline">\(A_\textsf{TM}\)</span>: <em>undecidable</em></td>
<td><span class="math inline">\(E_\textsf{TM}\)</span>: <em>undecidable</em></td>
<td><span class="math inline">\(EQ_\textsf{TM}\)</span>: <em>undecidable</em> <br>(not Turing-recognizable)</td>
</tr>
</tbody>
</table>
<p>The fact that <span class="math inline">\(A_\mathsf{TM}\)</span> is undecidable implies that a Turing machine may not halt on some input <span class="math inline">\(w\)</span>. Consider the following problem: (<strong>the halting problem</strong> <span class="citation" data-cites="turing1937computable">[1]</span>) <span class="math display">\[\textit{HALT}_\textsf{TM} = \{ \langle M, w \rangle\ | \ M \text{ is a TM, and } M \text{ halts on input } w \}\]</span></p>
<p><strong>Corollary 6.1.</strong> <span class="math inline">\(\textit{HALT}_\textsf{TM}\)</span> is undecidable.</p>
<p><strong>Proof.</strong> (By contraposition) Assume that there exists a Turing machine <span class="math inline">\(R\)</span> that decides <span class="math inline">\(\textit{HALT}_\textsf{TM}\)</span>. We construct a Turing machine <span class="math inline">\(S\)</span> that decides <span class="math inline">\(A_\mathsf{TM}\)</span>, using <span class="math inline">\(R\)</span>:</p>
<blockquote>
<p><span class="math inline">\(S =\)</span> “On input <span class="math inline">\(\langle M, w \rangle\)</span>:</p>
<ol type="1">
<li>Run <span class="math inline">\(R\)</span> on input <span class="math inline">\(\langle M, w \rangle\)</span>.</li>
<li>If <span class="math inline">\(R\)</span> rejects, reject.</li>
<li>If <span class="math inline">\(R\)</span> accepts (so that we know <span class="math inline">\(M\)</span> always halt on <span class="math inline">\(w\)</span>), simulate <span class="math inline">\(M\)</span> on <span class="math inline">\(w\)</span> until it halts.</li>
<li>If <span class="math inline">\(M\)</span> accepts, accept; otherwise, reject.’’</li>
</ol>
</blockquote>
<p>If <span class="math inline">\(R\)</span> decides <span class="math inline">\(\textit{HALT}_\textsf{TM}\)</span>, then <span class="math inline">\(S\)</span> decides <span class="math inline">\(A_\mathsf{TM}\)</span> by construction. Since <span class="math inline">\(A_\mathsf{TM}\)</span> is undecidable, such an <span class="math inline">\(R\)</span> that decides <span class="math inline">\(\textit{HALT}_\textsf{TM}\)</span> does not exist. <p style='text-align:right !important;text-indent:0 !important;position:relative;top:-1em'>&#9632;</p></p>
<p>Apart from Turing’s original halting problem, other undecidable problems of historical importance include:</p>
<ul>
<li><strong>Post correspondence problem</strong> (Post 1946 <span class="citation" data-cites="post1946variant">[2]</span>)</li>
<li><strong>Word problem for semigroups</strong> (proposed by Axel Thue in 1914; its undecidability was shown by Emil Post and Andrey Markov Jr. independently in 1947 <span class="citation" data-cites="post1947recursive">[3]</span>)</li>
<li><strong>The busy beaver game</strong> (Rado 1962 <span class="citation" data-cites="rado1962non">[4]</span>)</li>
<li><strong>Hilbert’s tenth problem</strong> (proposed by D. Hilbert in 1900; its undecidability was shown by Matiyasevich’s theorem in 1970, and is in no way an obvious result)</li>
</ul>
<p>Some problems, such as <span class="math inline">\(EQ_\mathsf{TM}\)</span>, are not even Turing-recognizable. Another example is <span class="math inline">\(MIN_\mathsf{TM}\)</span>: <span class="math display">\[MIN_\mathsf{TM} = \{ \langle M \rangle\ | \ M \text{ is a minimal Turing machine} \}\]</span></p>
<p><strong>Theorem 6.2.</strong> <span class="math inline">\(MIN_\mathsf{TM}\)</span> is not Turing-recognizable.</p>
<p><strong>Proof.</strong> Assume that there exists an enumerator <span class="math inline">\(E\)</span> that enumerates <span class="math inline">\(MIN_\mathsf{TM}\)</span> (note that an enumerator is equivalent to a Turing machine). We construct a Turing machine <span class="math inline">\(C\)</span> using <span class="math inline">\(E\)</span>:</p>
<blockquote>
<p><span class="math inline">\(C =\)</span> “On input <span class="math inline">\(w\)</span>:</p>
<ol type="1">
<li>Obtain the own description <span class="math inline">\(\langle C \rangle\)</span>. (by the recursion theorem)</li>
<li>Run <span class="math inline">\(E\)</span> until a machine <span class="math inline">\(D\)</span> appears with a longer description than that of <span class="math inline">\(C\)</span>.</li>
<li>Simulate <span class="math inline">\(D\)</span> on <span class="math inline">\(w\)</span>.’’</li>
</ol>
</blockquote>
<p>Since <span class="math inline">\(MIN_\textsf{TM}\)</span> is infinitely large but the description of <span class="math inline">\(C\)</span> is of finite length, the enumerator <span class="math inline">\(E\)</span> must eventually terminate with some <span class="math inline">\(D\)</span> that has a longer description than that of <span class="math inline">\(C\)</span>. As <span class="math inline">\(C\)</span> simulates <span class="math inline">\(D\)</span> in the last step, <span class="math inline">\(C\)</span> is equivalent to <span class="math inline">\(D\)</span>. But then the description of <span class="math inline">\(C\)</span> is shorter than that of <span class="math inline">\(D\)</span>, thus <span class="math inline">\(D\)</span> could not be an output of <span class="math inline">\(E\)</span> (which enumerates only <span class="math inline">\(MIN_\mathsf{TM}\)</span>). That is a contradiction. Therefore, such an enumerator <span class="math inline">\(E\)</span> for <span class="math inline">\(MIN_\mathsf{TM}\)</span> does not exist, that is, <span class="math inline">\(MIN_\mathsf{TM}\)</span> is not Turing-recognizable. <p style='text-align:right !important;text-indent:0 !important;position:relative;top:-1em'>&#9632;</p></p>
<p>The Turing-unrecognizability of <span class="math inline">\(MIN_\textsf{TM}\)</span> implies that the Kolmogorov complexity (descriptive complexity) <span class="math inline">\(K(x)\)</span> is not a computable function.</p>
</section>
<section id="beyond-turing-machines" class="level2">
<h2>Beyond Turing machines</h2>
<p>Per the Church-Turing thesis, a Turing machine (one finite automaton + one infinite linear table) defines the “limitation of computation”. Several hypothetical models (sometimes referred to as <em>hypercomputation</em> <span class="citation" data-cites="davis2004myth">[5]</span> as they are assumed to have the abilities to solve non-Turing-computable problems) have been proposed for the sake of theoretical interest:</p>
<ul>
<li><strong>Oracle machine</strong>: a know-all machine that can solve a certain non-Turing-computable problem such as <span class="math inline">\(A_\textsf{TM}\)</span> or <span class="math inline">\(\textit{HALT}_\textsf{TM}\)</span> (in a black-boxed way).</li>
<li><strong>Real computer</strong> (e.g., Blum-Shub-Smale machine): an idealized analog computer that can compute infinite-precision real numbers. (Real numbers are uncountable as shown by Cantor’s diagonal argument, so Turing machines are incapable of handling arbitrary reals)</li>
<li><strong>Zeno machine</strong> (i.e., supertasking): a Turing machine that can complete infinitely many steps in finite time.</li>
<li><strong>Infinite-time Turing machine</strong>: a Turing machine that is simply allowed to halt in an infinite amount of time.</li>
</ul>
<p>Note that standard (qubit-based) quantum computers are PSPACE-reducible, thus they are still a Turing-complete model of computation (i.e., quantum computers cannot be real computers or Zeno machines, and they do not break the Church-Turing thesis). Moreover, it has been proposed that the simulation of every (quantum) physical process, where only computable reals present, is actually a Turing-computable problem (Church-Turing-Deutsch principle).</p>
</section>
<section id="notes-on-interesting-problems-in-computability-theory" class="level2">
<h2>Notes on interesting problems in computability theory</h2>
<p><strong>Finite languages.</strong> A finite language consists of a finite set of strings, thus it may be written as a regular expression of a finite union of those strings. It may be recognized by a time-independent combinational circuit, which can be viewed as a special form of acyclic finite automaton. (See also the blog post: <a href="https://blog.soimort.org/comp/c/boolean-circuit/">What I Wish I Knew When Learning Boolean Circuits</a>) There are several unsolved problems concerning the circuit complexity.</p>
<p><strong>Generalized regular expression.</strong> A generalized regular expression is defined as <span class="math display">\[R ::= a\ |\ \varepsilon\ |\ \emptyset\ |\ (R_1 \cup R_2)\ |\ (R_1 \cap R_2)\ |\ (R_1 \circ R_2)\ |\ (\lnot R_1)\ |\ (R_1^*)\]</span> where <span class="math inline">\(a \in \Sigma\)</span>, <span class="math inline">\(R_1\)</span> and <span class="math inline">\(R_2\)</span> are generalized regular expressions. Although it comes with two extra operators (intersection <span class="math inline">\(\cap\)</span> and complementation <span class="math inline">\(\lnot\)</span>), it actually has the same representational power as regular expressions, due to the fact that the class of regular languages is closed under intersection and complementation.</p>
<p><strong>Star-free languages.</strong> A star-free language is a regular language that can be described by a generalized regular expression but without the Kleene star operation. Clearly, this class includes all finite languages. One example of an infinite star-free language is <span class="math inline">\(a^*\)</span>, because <span class="math inline">\(a^* = \lnot((\lnot\emptyset) \circ (\lnot{a}) \circ (\lnot\emptyset))\)</span>. On the other hand, <span class="math inline">\((a \circ a)^*\)</span> is not star-free.</p>
<p>(Unsolved) <strong>Generalized star height problem.</strong> Can all regular languages be expressed using generalized regular expressions with a limited nesting depth of Kleene stars (star height)? Moreover, is the minimum required star height a computable function? For example, <span class="math inline">\(((((a \circ a)^*)^*)\cdots)^*\)</span> can be expressed as <span class="math inline">\((a \circ a)^*\)</span>, which has a minimum required star height of 1 (but it is not star-free). The general result and whether the minimum star height is decidable are not yet known.</p>
<p><strong>Linear bounded automata.</strong> LBAs provide an accurate model for real-world computers, which have only bounded memories. Given sufficient memory on an LBA, we can simulate another (smaller) LBA; a practical example would be a virtual machine running on VirtualBox or QEMU.</p>
<p>(Unsolved) <strong>LBA problem.</strong> Is the class of languages accepted by LBA equal to the class of languages accepted by deterministic LBA? Or, in terms of the complexity theory, is <span class="math inline">\(\text{SPACE}(n) = \text{NSPACE}(n)\)</span>? We know that DFA and NFA accept the same class of languages, so do TM and NTM, while PDA and DPDA are not completely equivalent. However, it is still an open question whether LBA and DLBA are equivalent models. Note that it is known that <span class="math inline">\(\text{PSPACE} = \bigcup_k \text{SPACE}(n^k)\)</span> is equivalent to <span class="math inline">\(\text{NPSPACE} = \bigcup_k \text{NSPACE}(n^k)\)</span>, that is, deterministic polynomially bounded automata and nondeterministic polynomially bounded automata are equivalent, by Savitch’s theorem.</p>
</section>
<section id="references-and-further-reading" class="level2">
<h2>References and further reading</h2>
<p><strong>Books:</strong></p>
<p>M. Sipser, <em>Introduction to the Theory of Computation</em>, 3rd ed.</p>
<p>J. E. Hopcroft, R. Motwani, J. D. Ullman, <em>Introduction to Automata Theory, Languages, and Computation</em>, 3rd ed.</p>
<p><strong>Articles:</strong></p>
<p>M. Davis, “What is a computation?” <em>Mathematics Today: Twelve Informal Essays</em>, pp. 241–267, 1978.</p>
<p>D. Zeilberger, “A 2-minute proof of the 2nd-most important theorem of the 2nd millennium,” <a href="http://www.math.rutgers.edu/~zeilberg/mamarim/mamarimTeX/halt" class="uri">http://www.math.rutgers.edu/~zeilberg/mamarim/mamarimTeX/halt</a>.</p>
<p><strong>Papers:</strong></p>
<div id="refs" class="references">
<div id="ref-turing1937computable">
<p>[1] A. M. Turing, “On computable numbers, with an application to the Entscheidungsproblem,” <em>Proceedings of the London Mathematical Society</em>, vol. 2, no. 1, pp. 230–265, 1937. </p>
</div>
<div id="ref-post1946variant">
<p>[2] E. L. Post, “A variant of a recursively unsolvable problem,” <em>Bulletin of the American Mathematical Society</em>, vol. 52, no. 4, pp. 264–268, 1946. </p>
</div>
<div id="ref-post1947recursive">
<p>[3] E. L. Post, “Recursive unsolvability of a problem of Thue,” <em>The Journal of Symbolic Logic</em>, vol. 12, no. 01, pp. 1–11, 1947. </p>
</div>
<div id="ref-rado1962non">
<p>[4] T. Rado, “On non-computable functions,” <em>Bell System Technical Journal</em>, vol. 41, no. 3, pp. 877–884, 1962. </p>
</div>
<div id="ref-davis2004myth">
<p>[5] M. Davis, “The myth of hypercomputation,” in <em>Alan Turing: Life and legacy of a great thinker</em>, Springer, 2004, pp. 195–211. </p>
</div>
</div>
</section>

]]>
    </content>
  </entry>
  <entry>
    <title>Recovering from a Corrupted Arch Linux Upgrade</title>
    <link rel="alternate" type="text/html" href="https://www.soimort.org/notes/170407" />
    <id>tag:www.soimort.org,2017:/notes/170407</id>
    <published>2017-04-07T00:00:00+02:00</published>
    <updated>2017-04-08T00:00:00+02:00</updated>
    <author>
      <name>Mort Yao</name>
    </author>
    <category term="engineering" />
    <content type="html" xml:lang="en" xml:base="https://www.soimort.org/">
<![CDATA[
<p><strong>(Probably unimportant) Backstory:</strong> It’s been a while since the last full-system upgrade of my Arch Linux laptop – It sat well with me for a span of months’ uptime. When I finally got the time to run a <code>pacman -Syu</code> (so well as to dare any potential issues due to Arch’s infamous instability) earlier today, weird things did happen: Something other than <code>pacman</code> was eating up my CPU. I assumed it was Chromium in the first place, unless it wasn’t this time. It turned out to be <code>gnome-settings-daemon</code> together with some other GUI processes running on GNOME, that were consistently hogging my CPU in turn. And that made a percent of 100% (!). As I killed the seemingly problematic process, something else would insist to emerge on the top of <code>top</code> with similarly excessive CPU usage. I decided that this was an unusual situation and without much further thought, forced a <code>reboot</code> while <code>pacman</code> was still running. Then I ended up with a corrupted system: the kernel didn’t load during the early boot process, complaining about missing <code>modules.devname</code> and that <code>/dev/sda11</code> (which is the root partition) could not be found:</p>
<pre><code>  Warning: /lib/modules/4.10.8-1-ARCH/modules.devname not found - ignoring
  starting version 232
  Waiting 10 seconds for device /dev/sda11 ...
  ERROR: device &#39;/dev/sda11&#39; not found. Skipping fsck.
  mount: you must specify the filesystem type
  You are now being dropped into an emergency shell.</code></pre>
<p>Without proper modules loaded even the keyboard was not working, so I couldn’t do anything under the emergency shell. But I wasn’t completely out of luck – I have a dual-booting of Arch and Ubuntu, which is prepared just for recovery purposes like this. (otherwise I had to make room for another Live USB, which was a little bit inconvenient; I don’t use those rescue-ware for years)</p>
<p><strong>Recover an (unbootable) Arch system from another distro:</strong> This is mostly relevant if you can’t boot into the system (due to a corrupted kernel upgrade), otherwise it’s possible to just login from TTY (locally or via SSH) and perform the fix (e.g., in the case that it’s just X, display manager or WM that fails to load but the kernel boots well).</p>
<ol type="1">
<li>On the host system (e.g., Ubuntu), create a working chroot environment: (Assume that the root for Arch is mounted to <code>/dev/sda11</code>)</li>
</ol>
<pre><code>    # TARGETDEV=&quot;/dev/sda11&quot;
    # TARGETDIR=&quot;/mnt/arch&quot;

    # mount $TARGETDEV $TARGETDIR
    # mount -t proc /proc $TARGETDIR/proc
    # mount --rbind /sys $TARGETDIR/sys
    # mount --rbind /dev $TARGETDIR/dev

    # cp /etc/hosts $TARGETDIR/etc
    # cp /etc/resolv.conf $TARGETDIR/etc
    # chroot $TARGETDIR rm /etc/mtab 2&gt; /dev/null
    # chroot $TARGETDIR ln -s /proc/mounts /etc/mtab

    # chroot $TARGETDIR</code></pre>
<p>Alternatively, use the <code>arch-chroot</code> script from an <a href="https://mirrors.kernel.org/archlinux/iso/latest/">Arch bootstrap image</a>:</p>
<pre><code>    # arch-chroot $TARGETDIR</code></pre>
<ol start="2" type="1">
<li>Now that we have a chroot environment with access to the (currently broken) Arch system, continue with unfinished <code>pacman</code> upgrades and clean up any lock file if needed:</li>
</ol>
<pre><code>    [/mnt/arch]# pacman -Syu</code></pre>
<p>Or, if there’s any unwanted package upgrade that causes the system to fail, downgrade it.<br />
The important thing to remember is that, while continuing, a previously failed transaction will not run its hooks anymore. Therefore it might be wiser to find out which exact packages <code>pacman</code> was trying to upgrade in the last transaction (from <code>/var/log/pacman.log</code>) and <em>reinstall</em> all of them, rather than a complementing <code>pacman -Syu</code>. But if it’s known which package is causing the problem (and in this very common case, <code>linux</code>), simply run the following to regenerate initramfs for the new kernel:</p>
<pre><code>    [/mnt/arch]# mkinitcpio -p linux</code></pre>
<p>And we are done. A few commands and our Arch system is now back and booting.</p>
<p><strong>Why the mess?</strong> Initramfs images need to be regenerated (from a corresponding mkinitcpio preset file) after each kernel update. Starting from Arch’s package <code>linux 4.8.8-2</code>, the calling of <code>mkinitcpio</code> was specified in a PostTransaction alpm hook, in place of an explicit <code>post_install()</code> command to be invoked from the <code>.install</code> script <a href="https://git.archlinux.org/svntogit/packages.git/commit/trunk/linux.install?h=packages/linux&amp;id=617173dcde960f00112ebdfee4c80ede71e67375">as before</a>: (The move towards alpm hooks is said to be a fix for <a href="https://bugs.archlinux.org/task/51818">#51818</a>, as two or more packages in one transaction may need the regeneration of initramfs images)</p>
<div class="sourceCode"><pre class="sourceCode ini"><code class="sourceCode ini"><span class="kw">[Trigger]</span>
<span class="dt">Type </span><span class="ot">=</span><span class="st"> File</span>
<span class="dt">Operation </span><span class="ot">=</span><span class="st"> Install</span>
<span class="dt">Operation </span><span class="ot">=</span><span class="st"> Upgrade</span>
<span class="dt">Target </span><span class="ot">=</span><span class="st"> boot/vmlinuz-%PKGBASE%</span>
<span class="dt">Target </span><span class="ot">=</span><span class="st"> usr/lib/initcpio/*</span>

<span class="kw">[Action]</span>
<span class="dt">Description </span><span class="ot">=</span><span class="st"> Updating %PKGBASE% initcpios</span>
<span class="dt">When </span><span class="ot">=</span><span class="st"> PostTransaction</span>
<span class="dt">Exec </span><span class="ot">=</span><span class="st"> /usr/bin/mkinitcpio -p %PKGBASE%</span></code></pre></div>
<p>The faulty part about PostTransaction alpm hooks is that they run in a <em>post-transaction</em> manner; in the context of Arch Linux, a “transaction” means a complete run of <code>pacman</code>, regardless of how many packages it installs or upgrades. Such PostTransaction hooks will not run until all preceding operations succeed. Quoted from the CAVEATS section in the <a href="https://www.archlinux.org/pacman/alpm-hooks.5.html">alpm-hooks(5) Manual Page</a>:</p>
<blockquote>
<p>“PostTransaction hooks will <strong>not</strong> run if the transaction fails to complete for any reason.”</p>
</blockquote>
<p>This (kind of) misbehavior could lead to unintended aftermath in a failed system upgrade, as it does in the case of the <code>linux</code> package. Confusingly, a <code>pacman</code> “transaction” can be an arbitrary set of unrelated package updates; it could possibly fail to complete at any point (e.g., <code>.install</code> script errors, process accidentally killed, or even power lost), and ideally, it should remain safe while encountering such failures before commit. However, since the generation of <code>initramfs</code> in the PostTransaction hook is actually an <strong>indispensable</strong> step for the newly upgraded <code>linux</code> package here (whether other packages complete their upgrades or not), it is not safe if a <code>pacman</code> “transaction” fails halfway; PostTransaction hook won’t run and all you get is a halfway system that doesn’t boot (so you’ll need to fix that through a fallback or alternative kernel). To see this problem more clearly, think of the following two scenarios:</p>
<p><strong><em>A successful system upgrade:</em></strong></p>
<pre><code>    pacman -Syu
        sanity check (for packages to upgrade)
            |
        start upgrading package L (requires hook M to run)
            |
        finish upgrading package L
        start upgrading package A
            |
        finish upgrading package A
        start upgrading package B
            |
        finish upgrading package B
        complete transaction
        run post-transaction hook M
            |
        done.
    [packages L, A, B are upgraded; hook M is run; working system]</code></pre>
<p><strong><em>An (ungracefully) failing system upgrade:</em></strong></p>
<pre><code>    pacman -Syu
        sanity check (for packages to upgrade)
            |
        start upgrading package L (requires hook M to run)
            |
        finish upgrading package L
        start upgrading package A
            |
        finish upgrading package A
        start upgrading package B
            |
            crash!
    [packages L, A are upgraded; hook M is not run; broken system]</code></pre>
<p><strong>How to perform a system upgrade safely?</strong> Although it ultimately depends on how we define a “safe system upgrade” and how much we want it, some robustness may be achieved at least. It’s clear to see that the upgrade of package <code>L</code> and the run of hook <code>M</code> should be dealt as one transaction, or treating <code>M</code> in a post-transaction way will put us on the risk that if some other package fails to upgrade (or maybe it’s just computer crashes), we end up with having only <code>L</code> upgraded, but not <code>M</code> run (while it is desirable to have both or none).</p>
<p><strong><em>A (gracefully) failing system upgrade:</em></strong></p>
<pre><code>        sanity check (for packages to upgrade)
            |
        start upgrading package L (requires hook M to run)
            |
        finish upgrading package L
        run hook M
            |
        complete transaction
        start upgrading package A
            |
        finish upgrading package A
        start upgrading package B
            |
            crash!
    [packages L, A are upgraded; hook M is run; working system]</code></pre>
<p>This is exactly the way things worked before (using the old-fashioned <code>post_install()</code>): It’s less fragile under possible failures, although in order to fix #51818 (another package <code>L2</code> also requires hook <code>M</code> to run), we’ll need to manage the ordering of package upgrades properly:</p>
<pre><code>        start upgrading package L (requires hook M to run)
            |
        finish upgrading package L
        start upgrading package L2 (requires hook M to run)
            |
        finish upgrading package L2
        run hook M
            |
        complete transaction
        start upgrading package A
            ...</code></pre>
<p>That is, <code>L</code>, <code>L2</code> and <code>M</code> are one transaction. It is not allowed to have only <code>L</code> and <code>L2</code>, or only <code>L</code>, without a run of hook <code>M</code>. Other unrelated packages (<code>A</code>, <code>B</code>, …) are prevented from causing such issues in the above scheme. There is still a possibility that the process crashes during the phase of <code>L</code>, <code>L2</code> or <code>M</code>, but the chance would be much smaller, because we are working with a transaction consisting of the strongly coupling upgrades of <code>L</code>, <code>L2</code> and <code>M</code>, not a whole <code>pacman</code> “transaction” consisting of easily hundreds of arbitrary system upgrades and post-transaction hooks. Even better, in case of such failures, we can ask to redo uncommitted transactions anyway so we don’t rerun hooks manually:</p>
<pre><code>        redo uncommitted transactions (upgrades &amp; hooks)
            |
        start upgrading package B
            ...</code></pre>
<p>I don’t know if there’s any software management tool implementing this fully recovering approach. Transactions need to be more refined (<code>pacman</code>’s “all is a transaction” is really a naïve semantics to have) and the ordering of upgrades is essential, in order to give best robustness in case of possible crashes during a system upgrade, so it might not be as implementable as most package managers are (although still far less sophisticated than a real-world database). Or – with reasonable efforts – if we cannot guarantee anything for a transaction – maybe a Windows-inspired “user-friendly” warning message like “Don’t turn off your computer” is good enough. (At least you’ll know when you’re breaking shit: a transaction is not completed yet, some necessary hooks are not run, and you’re on your own then.)</p>
<section id="references" class="level2">
<h2>References</h2>
<p>[1] ArchWiki, “Install from existing Linux”. <a href="https://wiki.archlinux.org/index.php/Install_from_existing_Linux" class="uri">https://wiki.archlinux.org/index.php/Install_from_existing_Linux</a></p>
<p>[2] ArchWiki, “Change root”. <a href="https://wiki.archlinux.org/index.php/change_root" class="uri">https://wiki.archlinux.org/index.php/change_root</a></p>
<p>[3] ArchWiki, “mkinitcpio”. <a href="https://wiki.archlinux.org/index.php/mkinitcpio" class="uri">https://wiki.archlinux.org/index.php/mkinitcpio</a></p>
<p>[4] alpm-hooks(5) Manual Page. <a href="https://www.archlinux.org/pacman/alpm-hooks.5.html" class="uri">https://www.archlinux.org/pacman/alpm-hooks.5.html</a></p>
</section>

]]>
    </content>
  </entry>
  <entry>
    <title>A Pandoc Filter for Typesetting Operational Semantics</title>
    <link rel="alternate" type="text/html" href="https://www.soimort.org/notes/170323" />
    <id>tag:www.soimort.org,2017:/notes/170323</id>
    <published>2017-03-23T00:00:00+01:00</published>
    <updated>2017-03-24T00:00:00+01:00</updated>
    <author>
      <name>Mort Yao</name>
    </author>
    <category term="tooling" />
    <content type="html" xml:lang="en" xml:base="https://www.soimort.org/">
<![CDATA[
<p>Recently I decided to make my life a little easier by simplifying the laborious, tedious math typing that I had to do from time to time. For me this is most relevant for typesetting the formal semantics of programming languages, where proof trees are interwoven with a variety of programming constructs. Here’s my initial intention: To typeset something like (in big-step semantics) <span class="math display">\[
\frac{
  \stackrel{\mathcal{E}_0}
    {\langle b, \sigma \rangle \downarrow \textbf{true}} \qquad
  \stackrel{\mathcal{E}_1}
    {\langle c_0, \sigma \rangle \downarrow \sigma&#39;&#39;} \qquad
  \stackrel{\mathcal{E}_2}
    {\langle \textbf{while } b \textbf{ do } c_0, \sigma&#39;&#39; \rangle \downarrow \sigma&#39;}
  }{
    \langle \textbf{while } b \textbf{ do } c_0, \sigma \rangle \downarrow \sigma&#39;}
\]</span> Instead of the bloated TeX syntax:</p>
<div class="sourceCode"><pre class="sourceCode latex"><code class="sourceCode latex">  <span class="fu">\frac</span>{
    <span class="fu">\stackrel</span>{<span class="fu">\mathcal</span>{E}_0}
      {<span class="fu">\langle</span> b, <span class="fu">\sigma</span> <span class="fu">\rangle</span> <span class="fu">\downarrow</span> <span class="fu">\textbf</span>{true}} <span class="fu">\qquad</span>
    <span class="fu">\stackrel</span>{<span class="fu">\mathcal</span>{E}_1}
      {<span class="fu">\langle</span> c_0, <span class="fu">\sigma</span> <span class="fu">\rangle</span> <span class="fu">\downarrow</span> <span class="fu">\sigma</span>&#39;&#39;} <span class="fu">\qquad</span>
    <span class="fu">\stackrel</span>{<span class="fu">\mathcal</span>{E}_2}
      {<span class="fu">\langle</span> <span class="fu">\textbf</span>{while } b <span class="fu">\textbf</span>{ do } c_0, <span class="fu">\sigma</span>&#39;&#39; <span class="fu">\rangle</span> <span class="fu">\downarrow</span> <span class="fu">\sigma</span>&#39;}
  }{
    <span class="fu">\langle</span> <span class="fu">\textbf</span>{while } b <span class="fu">\textbf</span>{ do } c_0, <span class="fu">\sigma</span> <span class="fu">\rangle</span> <span class="fu">\downarrow</span> <span class="fu">\sigma</span>&#39;}</code></pre></div>
<p>I could just write it more neatly, intuitively, without all those hexes in magic backslashes and braces:</p>
<pre><code>  &lt;b, sig&gt; ! true                 -- E_0
  &lt;c_0, sig&gt; ! sig&#39;&#39;              -- E_1
  &lt;while b do c_0, sig&#39;&#39;&gt; ! sig&#39;  -- E_2
  ----
  &lt;while b do c_0, sig&gt; ! sig&#39;</code></pre>
<p>But, of course, preserving the nice-looking outcome (from either TeX or MathJax).</p>
<p>Besides natural derivations, we also got a lot of evidently agreeable conventions for typesetting general mathematics: parentheses (brackets, braces) are almost always paired; “<code>\left</code>” and “<code>\right</code>” are very often desired since <span class="math inline">\(\left[\frac{1}{2}\right]\)</span> is a bit less awkward than <span class="math inline">\([\frac{1}{2}]\)</span>; when referring to a function name, “<code>\operatorname</code>” looks aesthetically better; etc. Furthermore, if we write down some math notations in plain text, clearly, “<code>=&gt;</code>” has to be a “<span class="math inline">\(\Rightarrow\)</span>” and “<code>|-&gt;</code>” has to be a “<span class="math inline">\(\mapsto\)</span>”; “<code>|-</code>” means “<span class="math inline">\(\vdash\)</span>” and “<code>|=</code>” means “<span class="math inline">\(\vDash\)</span>”; a standalone letter “<code>N</code>” is just <span class="math inline">\(\mathbb{N}\)</span>; etc. Taking such matters into consideration, there could be some handy alternative syntax (I call it “lazybones’ syntax”) for typesetting formulas, at least for a specific field someone specializes in, where these conventions are consistent:</p>
<table style="width:75%;">
<colgroup>
<col style="width: 23%" />
<col style="width: 27%" />
<col style="width: 23%" />
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>Typesetting outcome</th>
<th>Syntax</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Provability</td>
<td><span class="math inline">\(\Gamma \vdash \varphi\)</span></td>
<td><strong>TeX:</strong><br> <code>\Gamma \vdash \varphi</code> <br> <strong>Lazybones’:</strong><br> <code>Gam |- phi</code></td>
</tr>
<tr class="even">
<td>Validity</td>
<td><span class="math inline">\(\Gamma \vDash \varphi\)</span></td>
<td><strong>TeX:</strong><br> <code>\Gamma \vDash \varphi</code> <br> <strong>Lazybones’:</strong><br> <code>Gam |= phi</code></td>
</tr>
<tr class="odd">
<td>Big-step semantics</td>
<td><span class="math inline">\(\langle b_0 \land b_1, \sigma \rangle \downarrow t\)</span></td>
<td><strong>TeX:</strong><br> <code>\langle b_0 \land b_1, \sigma</code><br><code>\rangle \downarrow t</code> <br> <strong>Lazybones’:</strong><br> <code>&lt;b_0 &amp;&amp; b_1, sig&gt; ! t</code></td>
</tr>
<tr class="even">
<td>Small-step semantics</td>
<td><span class="math inline">\(\sigma \vdash b_0 \land b_1 \to^* t\)</span></td>
<td><strong>TeX:</strong><br> <code>\sigma \vdash b_0 \land b_1</code><br><code>\to^* t</code> <br> <strong>Lazybones’:</strong><br> <code>sig |- b_0 &amp;&amp; b_1 -&gt;* t</code></td>
</tr>
<tr class="odd">
<td>Hoare logic</td>
<td><span class="math inline">\(\vdash \{A\} \textbf{if } b \textbf{ then } c_0 \textbf{ else } c_1 \{B\}\)</span></td>
<td><strong>TeX:</strong><br> <code>\vdash \{A\} \textbf{if } b</code><br><code>\textbf{ then } c_0</code><br><code>\textbf{ else } c_1 \{B\}</code> <br> <strong>Lazybones’:</strong><br> <code>|- &lt;[A]&gt; if b then c_0</code><br><code>else c_1 &lt;[B]&gt;</code></td>
</tr>
<tr class="even">
<td>Denotational semantics</td>
<td><span class="math inline">\(\mathcal{C}[\![X:=a]\!] = \lambda \sigma . \eta (\sigma[X \mapsto \mathcal{A}[\![a]\!] \sigma])\)</span></td>
<td><strong>TeX:</strong><br> <code>\mathcal{C}[\![X:=a]\!] =</code><br><code>\lambda \sigma . \eta</code><br><code>(\sigma[X \mapsto</code><br><code>\mathcal{A}[\![a]\!] \sigma])</code> <br> <strong>Lazybones’:</strong><br> <code>C[[X:=a]] = lam sig . eta</code><br><code>(sig[X |-&gt; A[[a]] sig])</code></td>
</tr>
</tbody>
</table>
<p>For simplicity, we require that all such transformations are <em>regular</em>, i.e., “lazybones’ syntax” may be translated into plain TeX code using merely substitutions of regular expressions.</p>
<p>As a basic example, let’s consider angle brackets, for which we desire to type in simply “<code>&lt;</code>” and “<code>&gt;</code>” instead of “<code>\langle</code>” and “<code>\rangle</code>”. To avoid any ambiguity (with normal less-than or greater-than sign), it is required that such brackets have no internal spacing, that is, we write “<code>&lt;x, y&gt;</code>” rather than “<code>&lt; x, y &gt;</code>”, but “<code>1 &lt; 2</code>” instead of “<code>1&lt;2</code>”. Once we fix the transformation rules, implementation would be quite straightforward in Haskell with <code>Text.Regex</code>, if we want a pandoc filter to handle these substitutions for everything embedded in TeX math mode:</p>
<div class="sourceCode"><pre class="sourceCode hs"><code class="sourceCode haskell">subLAngle s <span class="fu">=</span>
  subRegex (mkRegex <span class="st">&quot;&lt;([^[:blank:]])&quot;</span>) s <span class="fu">$</span> <span class="st">&quot;\\langle \\1&quot;</span>
subRAngle s <span class="fu">=</span>
  subRegex (mkRegex <span class="st">&quot;([^[:blank:]])&gt;&quot;</span>) s <span class="fu">$</span> <span class="st">&quot;\\1\\rangle &quot;</span>

semType m<span class="fu">@</span>(<span class="dt">Math</span> mathType s) <span class="fu">=</span> <span class="kw">do</span>
  <span class="kw">let</span> s&#39; <span class="fu">=</span> subLAngle <span class="fu">$</span> subRAngle s
  return <span class="fu">$</span> <span class="dt">Math</span> mathType s&#39;
semType x <span class="fu">=</span> return x</code></pre></div>
<p>So, why bother implementing a pandoc filter rather than just defining some TeX macros? Two main reasons:</p>
<ol type="1">
<li>TeX code is nontrivial to write. And you can’t get rid of the overwhelming backslashes quite easily. It would be very hard, if not impossible, to achieve the same thing you’d do with a pandoc filter. (I would say that TeX is rather fine for <em>typesetting</em>, but <em>only</em> for typesetting; actual programming/manipulating macros in TeX seems very awkward for me.)</li>
<li>TeX macros are just… code in TeX, which means that they’re not designated to work for non-DVI originated publishing formats, such as HTML with MathJax. So if you do a lot of heavy lifting with TeX macros, they won’t play well for display on the Web (unless you’re willing to convert math formulas into pictures).</li>
</ol>
<p>Surely you can write pandoc filters in <em>any</em> language as you like (officially Haskell and Python). Nothing like plain TeX (despite the fact that it’s Turing-complete): filters are easier to implement, unrestricted in the way that they interact with structured documents, with a great deal of cool supporting libraries even to blow up the earth. Although here in this case, we are only using some no-brainer pattern matching to release our fingers from heavy math typing.</p>
<p>A proof-of-concept of this is in <a href="https://github.com/soimort/pandoc-filters/blob/aad6033dfbd7d460d22aa627e04ca388f72af020/semtype.hs">semtype.hs</a>. While undocumented, all tricks it does should be clear from the comments and regular expressions themselves.</p>

]]>
    </content>
  </entry>
  <entry>
    <title>An Intuitive Exposition of<br />
“Proof by Contradiction vs. Proof of Negation”</title>
    <link rel="alternate" type="text/html" href="https://www.soimort.org/notes/170306" />
    <id>tag:www.soimort.org,2017:/notes/170306</id>
    <published>2017-03-06T00:00:00+01:00</published>
    <updated>2017-03-06T00:00:00+01:00</updated>
    <author>
      <name>Mort Yao</name>
    </author>
    <category term="logic" />
    <content type="html" xml:lang="en" xml:base="https://www.soimort.org/">
<![CDATA[
<p style="text-align:center !important;text-indent:0 !important">(Inspired by <a href="https://existentialtype.wordpress.com/2017/03/04/a-proof-by-contradiction-is-not-a-proof-that-derives-a-contradiction/"><em>A “proof by contradiction” is not a proof that ends with a contradiction</em></a> by Robert Harper.)</p>
<p>There seem to be some common misconceptions about “proof by contradiction”. Recently I came across Robert’s <a href="https://existentialtype.wordpress.com/2017/03/04/a-proof-by-contradiction-is-not-a-proof-that-derives-a-contradiction/">blog post</a> on this issue, and couldn’t help reviewing it in my own way. I prefer a more formal treatment, nevertheless, without sacrificing its intuitive comprehensibility.</p>
<p>What is a “proof by contradiction”, exactly? When a classical mathematician (probably you) talks about proving by contradiction, they can mean either one of these two (syntactically) different things:</p>
<ol type="1">
<li>Prove <span class="math inline">\(P\)</span>: Assume <span class="math inline">\(\lnot P\)</span>, we derive a contradiction (<span class="math inline">\(\bot\)</span>). Therefore, we have <span class="math inline">\(P\)</span>.</li>
<li>Prove <span class="math inline">\(\lnot P\)</span>: Assume <span class="math inline">\(P\)</span>, we derive a contradiction (<span class="math inline">\(\bot\)</span>). Therefore, we have <span class="math inline">\(\lnot P\)</span>.</li>
</ol>
<p>Both syntactic forms have some kind of <em>reductio ad absurdum</em> (reduction to / derivation of contradiction) argument. However, the first form provides an <em>indirect proof</em> for <span class="math inline">\(P\)</span>; this is what we call a genuine “proof by contradiction”. The second form provides a <em>direct proof</em> for <span class="math inline">\(\lnot P\)</span> which is just the negation of <span class="math inline">\(P\)</span>; this is preferably called a “proof of negation”, as it’s not a proof of <span class="math inline">\(P\)</span> itself, but rather a proof of the negation of <span class="math inline">\(P\)</span>.</p>
<p>But how are they any different? You may ask. In a classical setting, there is no semantic difference. Notice that in the first form (“proof by contradiction”), we could rewrite <span class="math inline">\(P\)</span> as <span class="math inline">\(\lnot Q\)</span>, then we get</p>
<ol start="3" type="1">
<li>Prove <span class="math inline">\(\lnot Q\)</span>: Assume <span class="math inline">\(Q\)</span>, we derive a contradiction (<span class="math inline">\(\bot\)</span>). Therefore, we have <span class="math inline">\(\lnot Q\)</span>.</li>
</ol>
<p>which is just the second form, i.e., a “proof of negation”. Likewise, if we rewrite <span class="math inline">\(P\)</span> as <span class="math inline">\(\lnot Q\)</span> in the second form, we get</p>
<ol start="4" type="1">
<li>Prove <span class="math inline">\(Q\)</span>: Assume <span class="math inline">\(\lnot Q\)</span>, we derive a contradiction (<span class="math inline">\(\bot\)</span>). Therefore, we have <span class="math inline">\(Q\)</span>.</li>
</ol>
<p>which is just the first form, i.e., a “proof by contradiction”. That’s the very reason people often misconceive them – classically, a proof by contradiction and a proof of negation can be simply converted to the form of one another, without losing their semantic validity.</p>
<p>From a constructivist perspective, things are quite different. In the above rewritten forms, we introduced a new term <span class="math inline">\(\lnot Q := P\)</span>. For the rewrite in the 3rd form to be valid, the new assumption <span class="math inline">\(Q\)</span> must be as strong as the original assumption <span class="math inline">\(\lnot P\)</span>, which is just <span class="math inline">\(\lnot \lnot Q\)</span>. Formally, there must be <span class="math inline">\(\lnot \lnot Q \implies Q\)</span>. For the rewrite in the 4th form to be valid, the new statement <span class="math inline">\(Q\)</span> must be not any stronger than the original statement <span class="math inline">\(\lnot P\)</span>, so formally there must also be <span class="math inline">\(Q \implies \lnot \lnot Q\)</span>. In intuitionistic logic, although we can derive a “double negation introduction” (thus complete the rewrite in the 4th form), there is no way to derive a “double negation elimination” as required to get the 3rd form. So technically, while we can soundly rewrite from a “proof of negation” to a “proof by contradiction”, the other direction is impossible. Indeed, we must make a clear distinction between a “proof by contradiction” and a “proof of negation” here: Semantically, they are not even dual and should not be fused with each other.</p>
<p>Why is this distinction important? Because in intuitionistic logic, the second form (proof of negation) is a valid proof; the first form (proof by contradiction) is not. Take a look at the negation introduction rule: <span class="math display">\[\lnot_\mathsf{I} : \frac{\Gamma, P \vdash \bot}{\Gamma \vdash \lnot P}\]</span> which justifies the validity of “proof of negation”. However, there is no such rule saying that <span class="math display">\[\mathsf{PBC} : \frac{\Gamma, \lnot P \vdash \bot}{\Gamma \vdash P}\]</span> In classical logic, where a rule like <span class="math inline">\(\mathsf{PBC}\)</span> is allowed, one can easily derive the double negation elimination which we begged for before: Given <span class="math inline">\(\Gamma \vdash \lnot \lnot P\)</span>, the only rule that ever introduces a negation is <span class="math inline">\(\lnot_\mathsf{I}\)</span>, so we must also have <span class="math inline">\(\Gamma, \lnot P \vdash \bot\)</span>. Then by <span class="math inline">\(\mathsf{PBC}\)</span>, we get a derivation of <span class="math inline">\(\Gamma \vdash P\)</span>, as desired. <span class="math display">\[\mathsf{DNE} : \frac{\Gamma \vdash \lnot \lnot P}{\Gamma \vdash P}\]</span> If we adopt <span class="math inline">\(\mathsf{PBC}\)</span>, then we will also have adopted <span class="math inline">\(\mathsf{DNE}\)</span>; if we have <span class="math inline">\(\mathsf{DNE}\)</span>, then it would be perfectly valid to rewrite a “proof by contradiction” into the form of a “proof of negation”, or the other way around, as is already shown before. Since constructivists do not want to accept rules like <span class="math inline">\(\mathsf{PBC}\)</span> or <span class="math inline">\(\mathsf{DNE}\)</span> at all, they claim that a “proof by contradiction” and a “proof of negation” are essentially different, in that the latter is a valid proof but the former is doubtful, while their distinction is purely syntactical for classical mathematicians as the semantic equivalence would be trivial with <span class="math inline">\(\mathsf{PBC}\)</span> or <span class="math inline">\(\mathsf{DNE}\)</span>.</p>
<p>The rationale behind constructivists’ choice of ruling out indirect proofs by rejecting derivation rules like <span class="math inline">\(\mathsf{PBC}\)</span> and <span class="math inline">\(\mathsf{DNE}\)</span> comes into view when talking about first-order theories, where existential quantifiers are used. Say, if we wish to prove that there exists some <span class="math inline">\(x\)</span> with a property <span class="math inline">\(P\)</span>, we must specify an example <span class="math inline">\(t\)</span> which makes this property holds: <span class="math display">\[\exists_{\mathsf{I}_t} : \frac{\Gamma \vdash P[t/x]}{\Gamma \vdash \exists x : S.P}\]</span></p>
<p style="text-align:center !important;text-indent:0 !important">(<span class="math inline">\(t\)</span> is a term of sort <span class="math inline">\(S\)</span>)</p>
<p>This is something called a <em>constructive proof</em>, in the sense that in order to derive an existentialization, one must construct such a term explicitly, directly.</p>
<p>What if we allow <span class="math inline">\(\mathsf{PBC}\)</span> in our proofs then? We will be given enough power to utilize an alternate approach: Assume to the contrary that for all <span class="math inline">\(x\)</span> in <span class="math inline">\(S\)</span>, <span class="math inline">\(\lnot P\)</span> holds. Then we derive a contradiction. Thus, by <span class="math inline">\(\mathsf{PBC}\)</span>, there must exist some <span class="math inline">\(x\)</span> such that <span class="math inline">\(P\)</span> holds (since <span class="math inline">\(\lnot (\exists x : S.P) \equiv \forall x : S.\lnot P\)</span>). Formally, <span class="math display">\[\frac{\Gamma, \forall x : S.\lnot P \vdash \bot}{\Gamma \vdash \exists x : S.P}\]</span> Note that a term <span class="math inline">\(t\)</span> is nowhere to be evident in this form of proof. The downside of this classical approach of <em>existence proof</em> is that it is non-constructive, so even if you can derive a proof that some mathematical object exists, you can’t claim that you necessarily know what it is, since you have not concretely constructed such an object yet. Its existence is just “principally provable”, but not necessarily constructible or witnessable.</p>
<p>I would say it’s too much of a philosophical choice between classical logic and intuitionistic logic – at least for old school mathematicians who don’t practically mechanize their proofs at all. But one with some logic maturity should be able to draw a semantic distinction between a “proof by contradiction” that <span class="math inline">\(\vdash P\)</span> and a “proof of negation” that <span class="math inline">\(\vdash \lnot P\)</span>, bewaring of how their treatments can diverge in non-classical logic settings. It is still questionable to me whether every theorem provable in classical logic can be proved constructively, whatsoever, a constructive proof almost always makes more sense: <strong>If you claim that you have an apple, just show me the apple, instead of arguing to me sophistically that it can’t be the case that you do not have an apple.</strong></p>
<section id="references" class="level2">
<h2>References</h2>
<p>[1] Andrzej Filinski, “Course Notes for Semantics and Types, Lecture 1: Logic”.</p>
<p>[2] Robert Harper, “A ‘proof by contradiction’ is not a proof that ends with a contradiction”. <a href="https://existentialtype.wordpress.com/2017/03/04/a-proof-by-contradiction-is-not-a-proof-that-derives-a-contradiction/" class="uri">https://existentialtype.wordpress.com/2017/03/04/a-proof-by-contradiction-is-not-a-proof-that-derives-a-contradiction/</a></p>
<p>[3] Andrej Bauer, “Proof of negation and proof by contradiction”. <a href="http://math.andrej.com/2010/03/29/proof-of-negation-and-proof-by-contradiction/" class="uri">http://math.andrej.com/2010/03/29/proof-of-negation-and-proof-by-contradiction/</a></p>
<p>[4] Timothy Gowers, “When is proof by contradiction necessary?”. <a href="https://gowers.wordpress.com/2010/03/28/when-is-proof-by-contradiction-necessary/" class="uri">https://gowers.wordpress.com/2010/03/28/when-is-proof-by-contradiction-necessary/</a></p>
<p>[5] Terence Tao, “The ‘no self-defeating object’ argument”. <a href="https://terrytao.wordpress.com/2009/11/05/the-no-self-defeating-object-argument/" class="uri">https://terrytao.wordpress.com/2009/11/05/the-no-self-defeating-object-argument/</a></p>
</section>

]]>
    </content>
  </entry>
  <entry>
    <title>What I Wish I Knew When Learning Boolean Circuits</title>
    <link rel="alternate" type="text/html" href="https://blog.soimort.org/comp/c/boolean-circuit/" />
    <id>tag:www.soimort.org,2017:/posts/170306</id>
    <published>2017-03-06T00:00:00+01:00</published>
    <updated>2017-03-06T00:00:00+01:00</updated>
    <author>
      <name>Mort Yao</name>
    </author>
    <category term="blog" />
    <content type="html" xml:lang="en" xml:base="https://www.soimort.org/">
<![CDATA[


]]>
    </content>
  </entry>
  <entry>
    <title>The Fundamental Justification</title>
    <link rel="alternate" type="text/html" href="https://www.soimort.org/mst/5" />
    <id>tag:www.soimort.org,2017:/mst/5</id>
    <published>2017-02-06T00:00:00+01:00</published>
    <updated>2017-02-06T00:00:00+01:00</updated>
    <author>
      <name>Mort Yao</name>
    </author>
    
    <content type="html" xml:lang="en" xml:base="https://www.soimort.org/">
<![CDATA[
<p>I don’t have much to write about this week. My plan was to finish the sections on statistics and machine learning in <a href="https://wiki.soimort.org/">my wiki</a> before I can move on to more rigorous mathematics and logic, but that turned out to be an impossible task (shortly after the exam week a new, incredibly tenser semester is right under the nose). I wanted to write more about cryptography and information theory as a brush-up account of previous courses I’ve taken, and that’s infeasible too (although the very introductory parts are done in <a href="/mst/3/">#3</a> and <a href="/mst/4/">#4</a>).</p>
<p>Still, I have thought of many fun things I could do with statistical learning: image classification and face recognition (I always want a photo management application to be like that! I take and collect so many photos each day), a CBIR tool (like “Search by Image” in Google Images, but works locally on my computer), a GIMP Script-Fu that does tricks like image synthesis via ConvNets, etc. The good part about applying learning methods in image processing is that, once you can extract feature descriptors, everything becomes statistically learnable (and you as a programmer don’t really need to have prior knowledge about what an object visually is: an apple, or a pen?).</p>
<p>Cryptography, from what I learned, is a differently fun story. For a perfectly secure encryption scheme: <span class="math display">\[\Pr[M=m\,|\,C=c] = \Pr[M=m]\]</span> that is, knowing the ciphertext <span class="math inline">\(c\)</span> will not update any attacker’s belief about whatever the underlying message <span class="math inline">\(m\)</span> is. Even if you have a statistical training model, it cannot learn anything from purely observations of ciphertexts. But this unbreakable level of security comes with a price: The key space must expose substantial entropy that is as high as the message space, thus the key length can be no shorter than the message length (given by Shannon’s theorem). In practice, the messages we sent do not usually have the highest entropy possible, and we can safely assume that the attackers’ computation ability is bounded by polynomial-time algorithms, thus, we as the cryptosystem designers need only to make up schemes that are assumed to be unbreakable (i.e., breakable with only a negligible probability) for any polynomial-time attackers. As we don’t know yet if there actually are any polynomial unsolvable cases (e.g., is P ≠ NP?), the proof of security would eventually rely on some unproven computational hardness assumptions: one-way functions exist, integer factorization is hard, discrete logarithm is hard, etc. If one can construct a provably secure scheme, it is guaranteed that statistical cryptanalysis would be theoretically impossible within polynomial time (except for side-channel attacks); of course, if the hardness assumption we made is proved invalid, then nothing but the one-time pad can be secure.</p>
<p>I might be writing one or two blog posts about cryptographic security from an information-theoretic perspective and some basic cryptanalysis on insecure schemes, but now is the time to move on with my unfinished courses about logic and programming. Before that, I feel that I should add a little bit <a href="https://wiki.soimort.org/philosophy/">philosophy</a> to my wiki so as to refresh my viewpoint and methodology. And here it is.</p>
<p>(Philosophy is a sophisticated, highly arguable subject, so pardon me if there’s any inconsistency with your textbook.)</p>
<ul>
<li><strong>Metaphysics</strong> is about the fundamental nature of being and the world. <strong>Ontology</strong>, as a branch of metaphysics, studies about the basic categories of being of entities and their relations.</li>
<li><a href="https://wiki.soimort.org/philosophy/epistemology/">Epistemology</a> is the study of knowledge.
<ul>
<li>Where does knowledge come form?
<ul>
<li><strong>Empiricism</strong> claims that knowledge comes from empirical evidence.</li>
<li><strong>Rationalism</strong> claims that knowledge requires justification by reasoning.</li>
<li><strong>Skepticism</strong> rejects the certainty in knowledge and claims that it is impossible to have an adequate justification of knowledge.</li>
</ul></li>
<li>How to resolve the <em>regress problem</em> that the justification of knowledge is questioned ad infinitum?
<ul>
<li>In <strong>foundationalism</strong>, a statement is inferred from a basis of unprovably sound premises.
<ul>
<li>This approach leads to the (axiomatic) foundations of mathematics and the constructivism.</li>
<li>The fundamentals of modern <em>mathematics</em> are the <em>axiomatic set theory</em> (which has several variations with different sets of axioms).</li>
<li>The fundamentals of modern <em>probability theory</em> are the <em>Kolmogorov axioms</em>.</li>
<li>The computational hardness assumptions in cryptography may also be seen as a practice of foundationalism.</li>
</ul></li>
<li>In <strong>coherentism</strong>, a statement holds true as long as it coheres with all other justified beliefs, including itself.</li>
<li>In <strong>infinitism</strong>, a justification chain is allowed to be infinite, thus there could never be adequate justification for any statement in the chain (which is the point that it is often criticized for).</li>
</ul></li>
<li>So, what is knowledge, actually?
<ul>
<li><strong>Knowledge</strong> is <em>justified true belief</em>. (though questioned by the <em>Gettier problem</em> <span class="citation" data-cites="gettier1963justified">[1]</span>)</li>
</ul></li>
<li>How do we categorize our knowledge?
<ul>
<li><strong>A priori</strong> knowledge is independent of empirical evidence. Examples: knowledge deduced by logical deductions or mathematical proofs.</li>
<li><strong>A posteriori</strong> knowledge is dependent of empirical evidence. Examples: knowledge induced by statistical inference or learning (either human or machine learning).</li>
</ul></li>
<li><strong>Science</strong> is the approach to filter out unreliable knowledge and gather together reliable knowledge as a <strong>theory</strong>.</li>
<li>What qualifies as a science?
<ul>
<li>See the <em>demarcation problem</em>.</li>
</ul></li>
<li>Scientific discovery is made of <strong>hypotheses</strong>. A hypothesis is a proposed explanation or prediction method for a phenomenon.
<ul>
<li>Only formally proved or statistically tested hypotheses qualify as reliable knowledge.</li>
<li><strong>Epicurus’ principle of multiple explanations</strong>: If multiple hypotheses are consistent with the observations, one should retain them all.</li>
<li><strong>Occam’s razor</strong>: Among all hypotheses consistent with the observations, choose the simplest.</li>
<li>Epicurus’ principle of multiple explanations and Occam’s razor find their uses in the learning theory, e.g., Occam’s razor bound.</li>
</ul></li>
</ul></li>
<li><a href="https://wiki.soimort.org/philosophy/logic/">Logic</a> is the study of reasoning and argument, which plays an essential part in gaining knowledge.
<ul>
<li>How to reason / argue by inference?
<ul>
<li><strong>Deduction</strong> is to infer a conclusion by deriving a logical consequence (“a priori”) from some premises using rules of inference in a formal system. Examples: proofs, a priori probabilities.</li>
<li><strong>Induction</strong> is to infer a probable conclusion (“a posteriori”) from the generalization of some observations. Examples: statistical inference and learning, inductive programming.</li>
<li><strong>Abduction</strong> is to infer a probable explanation from some observations. Examples: deep learning.</li>
</ul></li>
</ul></li>
</ul>
<p>We can talk about the philosophy of science (particularly, philosophy of mathematics and statistics) with the understanding of epistemology and logic: Are you a logician or a statistician? If a logician, does set theory or type theory suit you the best? If a statistician, are you a Bayesian or a frequentist?</p>
<p>(As a personally opinionated note, I often find myself subscribe to the skepticism the most. But that doesn’t mean that logical reasoning and statistical inference aren’t useful to me; they are. Extremely. So as not to go too far with this subjective topic, I’ll be focusing more on classical / modal logic in the next few weeks.)</p>
<section id="references-and-further-reading" class="level2">
<h2>References and further reading</h2>
<p><strong>Papers:</strong></p>
<div id="refs" class="references">
<div id="ref-gettier1963justified">
<p>[1] E. L. Gettier, “Is justified true belief knowledge?” <em>analysis</em>, vol. 23, no. 6, pp. 121–123, 1963. </p>
</div>
</div>
</section>

]]>
    </content>
  </entry>
  <entry>
    <title>The Measurable Entropy</title>
    <link rel="alternate" type="text/html" href="https://www.soimort.org/mst/4" />
    <id>tag:www.soimort.org,2017:/mst/4</id>
    <published>2017-01-11T00:00:00+01:00</published>
    <updated>2017-01-14T00:00:00+01:00</updated>
    <author>
      <name>Mort Yao</name>
    </author>
    
    <content type="html" xml:lang="en" xml:base="https://www.soimort.org/">
<![CDATA[
<p>A brief introduction to basic information theory (entropy/information as a measure for theoretical unpredictability of data) and descriptive statistics (quantitative properties about real-world data including central tendency, dispersion and shape). The maximization of entropy under different constraints yields some common probability distributions: uniform distribution (given no prior knowledge); normal distribution (given that mean and variance are known).</p>
<ul>
<li>What is the measure for <strong>information</strong>?
<ul>
<li>Intuitively, if a sample appears to be more naturally “random”, then it may contain more “information” of interest since it takes a greater size of data (more bits) to describe. But how to measure this quantitatively?</li>
<li>Probability-theoretic view: <em>Shannon entropy</em>.</li>
<li>Algorithmic view: <em>Kolmogorov complexity</em>. (TBD in February or March 2017)</li>
</ul></li>
<li><a href="https://wiki.soimort.org/info/">Basic information theory</a>
<ul>
<li><strong>Shannon entropy</strong>
<ul>
<li>For discrete random variable <span class="math inline">\(X\)</span> with pmf <span class="math inline">\(p(x)\)</span>: <span class="math display">\[\operatorname{H}(X) = -\sum_{x\in\mathcal{X}} p(x) \log p(x).\]</span></li>
<li>For continuous random variable <span class="math inline">\(X\)</span> with pdf <span class="math inline">\(f(x)\)</span>: <span class="math display">\[\operatorname{H}(X) = -\int_\mathcal{X} f(x) \log f(x) dx.\]</span> (also referred to as <em>differential entropy</em>)</li>
<li>The notion of entropy is an extension of the one in statistical thermodynamics (Gibbs entropy) and the <a href="https://wiki.soimort.org/math/dynamical-systems/ergodic/">measure-theoretic entropy of dynamical systems</a>.</li>
<li>Obviously, the entropy is determined by the pmf/pdf, which depends on the parameters of the specific probability distribution.</li>
<li>In the context of Computer Science, the logarithm in the formula is often taken to the base <span class="math inline">\(2\)</span>. Assume that we take a uniform binary string of length <span class="math inline">\(\ell\)</span>, then <span class="math display">\[p(x) = 2^{-\ell}\]</span> Thus, the entropy of the distribution is <span class="math display">\[\operatorname{H}(X) = -\sum_{x\in\mathcal{X}} p(x) \log p(x) = - (2^\ell \cdot 2^{-\ell} \log_2 2^{-\ell}) = \ell\]</span> which is just the length of this (<span class="math inline">\(\ell\)</span>-bit) binary string. Therefore, the unit of information (when applying binary logarithm) is often called a <em>bit</em> (also <em>shannon</em>).</li>
<li>For the <strong>joint entropy</strong> <span class="math inline">\(\operatorname{H}(X,Y)\)</span> and the <strong>conditional entropy</strong> <span class="math inline">\(\operatorname{H}(X\,|\,Y)\)</span>, the following equation holds: <span class="math display">\[\operatorname{H}(X,Y) = \operatorname{H}(X\,|\,Y) + \operatorname{H}(Y) = \operatorname{H}(Y\,|\,X) + \operatorname{H}(X)\]</span> Notice that if <span class="math inline">\(\operatorname{H}(X\,|\,Y) = \operatorname{H}(X)\)</span>, then <span class="math inline">\(\operatorname{H}(X,Y) = \operatorname{H}(X) + \operatorname{H}(Y)\)</span> and <span class="math inline">\(\operatorname{H}(Y\,|\,X) = \operatorname{H}(Y)\)</span>. <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are said to be independent of each other in this case.</li>
<li><strong>Mutual information</strong> <span class="math inline">\(\operatorname{I}(X;Y) = \operatorname{H}(X) + \operatorname{H}(Y) - \operatorname{H}(X,Y) \geq 0\)</span> (equality holds iff <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are independent). Unlike the joint entropy or the conditional entropy, this notion does not reflect an actual probabilistic event thus it is referred to as <em>information</em> (sometimes <em>correlation</em>) rather than entropy.</li>
</ul></li>
<li><strong>Kullback-Leibler divergence (relative entropy)</strong> <span class="math display">\[\operatorname{D}_\mathrm{KL}(p\|q) = \sum_{x\in\mathcal{X}} p(x) \log \frac{p(x)}{q(x)}\]</span> KL divergence is a measurement of the distance of two probability distributions <span class="math inline">\(p(x)\)</span> and <span class="math inline">\(q(x)\)</span>.
<ul>
<li>If <span class="math inline">\(p = q\)</span>, <span class="math inline">\(\operatorname{D}_\mathrm{KL}(p\|q) = 0\)</span>. (Any distribution has a KL divergence of 0 with itself.)</li>
<li><span class="math inline">\(\operatorname{I}(X;Y) = \operatorname{D}_\mathrm{KL}(p(x,y)\|p(x)p(y))\)</span>.</li>
<li><strong>Cross entropy</strong> <span class="math display">\[\operatorname{H}(p,q) = \operatorname{H}(p) + \operatorname{D}_\mathrm{KL}(p\|q)\]</span> Notice that cross entropy is defined on two distributions <span class="math inline">\(p\)</span> and <span class="math inline">\(q\)</span> rather than two random variables taking one distribution <span class="math inline">\(p\)</span> (given by joint entropy <span class="math inline">\(\operatorname{H}(X,Y)\)</span>).</li>
</ul></li>
</ul></li>
<li>Basic probability theory
<ul>
<li><a href="https://wiki.soimort.org/math/probability/distributions/normal/">Normal (Gaussian) distribution</a>.
<ul>
<li>(Univariate) <span class="math inline">\(X \sim \mathcal{N}(\mu,\sigma^2)\)</span> <span class="math display">\[f_X(x) = \frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}\]</span> where <span class="math inline">\(\mu\)</span> is the mean, <span class="math inline">\(\sigma^2\)</span> is the variance of the distribution.<br />
(Multivariate) <span class="math inline">\(\boldsymbol x \sim \mathcal{N}_k(\boldsymbol\mu,\mathbf\Sigma)\)</span> <span class="math display">\[f(\boldsymbol x) = (2\pi)^{-k/2} |\mathbf\Sigma|^{-1/2} e^{-\frac{1}{2} (\boldsymbol x - \boldsymbol\mu)^\mathrm{T} \Sigma^{-1}(\boldsymbol x - \boldsymbol\mu)}\]</span> where <span class="math inline">\(\boldsymbol\mu\)</span> is the mean vector, <span class="math inline">\(\mathbf\Sigma\)</span> is the covariance matrix of the distribution.</li>
<li><em>Maximum entropy</em>: normal distribution is the probability distribution that maximizes the entropy when the mean <span class="math inline">\(\mu\)</span> and the variance <span class="math inline">\(\sigma^2\)</span> are fixed.</li>
<li>The normal distribution does not have any shape parameter. Moreover, its skewness and excess kurtosis are always 0.</li>
</ul></li>
</ul></li>
<li><a href="https://wiki.soimort.org/math/statistics/">Basic descriptive statistics</a>
<ul>
<li><em>Descriptive statistics</em> describe the properties of data sets quantitatively, without making any further inference.</li>
<li><em>Population</em> vs. <em>sample</em>.</li>
<li>Three major descriptive statistics:
<ol type="1">
<li><em>Central tendency</em>: sample means (<strong>arithmetic mean</strong> <span class="math inline">\(\mu\)</span>, geometric, harmonic), <strong>median</strong>, <strong>mode</strong>, mid-range.
<ul>
<li>Arithmetic mean is an unbiased estimator of the population mean (expectation).</li>
<li>Median and mode are most robust in the presence of outliers.</li>
</ul></li>
<li><em>Dispersion (or variability)</em>: minimum, maximum, range, IQR (interquartile range), maximum absolute deviation, MAD (mean absolute deviation), <strong>sample variance</strong> <span class="math inline">\(s^2\)</span> with Bessel’s correction, <strong>CV (coefficient of variance)</strong>, <strong>VMR (index of dispersion)</strong>.
<ul>
<li>IQR and MAD are robust in the presence of outliers.</li>
<li>Sample variance (with Bessel’s correction) is an unbiased estimator of the population variance.</li>
<li>CV and VMR are sample standard deviation and sample variance normalized by the mean respectively, thus they are sometimes called <em>relative standard deviation</em> and <em>relative variance</em>; they are <em>not</em> unbiased though.</li>
</ul></li>
<li><em>Shape</em>: sample skewness, sample excess kurtosis.
<ul>
<li>These statistics show how a sample deviates from normality, since the skewness and the excess kurtosis of a normal distribution are 0. The estimators could vary under different circumstances.</li>
</ul></li>
</ol></li>
</ul></li>
</ul>
<section id="entropy-as-a-measure" class="level2">
<h2>Entropy as a measure<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a></h2>
<p>For random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, we define sets <span class="math inline">\(\tilde X\)</span> and <span class="math inline">\(\tilde Y\)</span>. Then the information entropy <span class="math inline">\(\operatorname{H}\)</span> may be viewed as a signed measure <span class="math inline">\(\mu\)</span> over <a href="https://wiki.soimort.org/math/set/">sets</a>: <span class="math display">\[\begin{align*}
\operatorname{H}(X) &amp;= \mu(\tilde X) \\
\operatorname{H}(Y) &amp;= \mu(\tilde Y) \\
\operatorname{H}(X,Y) &amp;= \mu(\tilde X \cup \tilde Y) \qquad \text{(Joint entropy is the measure of a set union)} \\
\operatorname{H}(X\,|\,Y) &amp;= \mu(\tilde X \setminus \tilde Y) \qquad \text{(Conditional entropy is the measure of a set difference)} \\
\operatorname{I}(X;Y) &amp;= \mu(\tilde X \cap \tilde Y) \qquad \text{(Mutual information is the measure of a set intersection)}
\end{align*}\]</span> The inclusion–exclusion principle: <span class="math display">\[\begin{align*}
\operatorname{H}(X,Y) &amp;= \operatorname{H}(X) + \operatorname{H}(Y) - \operatorname{I}(X;Y) \\
\mu(\tilde X \cup \tilde Y) &amp;= \mu(\tilde X) + \mu(\tilde Y) - \mu(\tilde X \cap \tilde Y)
\end{align*}\]</span> Bayes’ theorem: <span class="math display">\[\begin{align*}
\operatorname{H}(X\,|\,Y) &amp;= \operatorname{H}(Y\,|\,X) + \operatorname{H}(X) - \operatorname{H}(Y) \\
\mu(\tilde X \setminus \tilde Y) &amp;= \mu(\tilde Y \setminus \tilde X) + \mu(\tilde X) - \mu(\tilde Y)
\end{align*}\]</span></p>
</section>
<section id="entropy-and-data-coding" class="level2">
<h2>Entropy and data coding</h2>
<p><em>Absolute entropy (Shannon entropy)</em> quantifies how much information is contained in some data. For data compression, the entropy gives the minimum size that is needed to reconstruct original data (losslessly). Assume that we want to store a random binary string of length <span class="math inline">\(\ell\)</span> (by “random”, we do not have yet any prior knowledge on what data to be stored). Under the <em>principle of maximum entropy</em>, the entropy of its distribution <span class="math inline">\(p(x)\)</span> should be maximized: <span class="math display">\[\max \operatorname{H}(X) = \max \left\{ -\sum_{x\in\mathcal{X}} p(x) \log p(x) \right\}\]</span> given the only constraint <span class="math display">\[\sum_{x\in\mathcal{X}} p(x) = 1\]</span> Let <span class="math inline">\(\lambda\)</span> be the Lagrange multiplier, set <span class="math display">\[\mathcal{L} = - \sum_{x\in\mathcal{X}} p(x) \log p(x) - \lambda\left( \sum_{x\in\mathcal{X}} p(x) - 1 \right)\]</span> We get <span class="math display">\[\begin{align*}
\frac{\partial\mathcal{L}}{\partial x} = -p(x)(\log p(x) + 1 + \lambda) &amp;= 0 \\
\log p(x) &amp;= - \lambda - 1 \\
p(x) &amp;= c \qquad \text{(constant)}
\end{align*}\]</span> That is, the <a href="https://wiki.soimort.org/math/probability/#discrete-uniform-distribution">discrete uniform distribution</a> maximizes the entropy for a random string. Since <span class="math inline">\(|\mathcal{X}| = 2^\ell\)</span>, we have <span class="math inline">\(p(x) = 2^{-\ell}\)</span> and <span class="math inline">\(\operatorname{H}(X) = -\sum_{x\in\mathcal{X}} 2^{-\ell} \log_2 2^{-\ell} = \ell\)</span> (bits). We conclude that the information that can be represented in a <span class="math inline">\(\ell\)</span>-bit string is at most <span class="math inline">\(\ell\)</span> bits. Some practical results include</p>
<ul>
<li>In general, pseudorandom data (assume no prior knowledge) cannot be losslessly compressed, e.g., the uniform key used in one-time pad must have <span class="math inline">\(\log_2 |\mathcal{M}|\)</span> bits (lower bound) so as not to compromise the perfect secrecy. (Further topic: <em>Shannon’s source coding theorem</em>)</li>
<li>Fully correct encoding/decoding of data, e.g., <span class="math inline">\(\mathsf{Enc}(m)\)</span> and <span class="math inline">\(\mathsf{Dec}(c)\)</span> algorithms in a private-key encryption scheme, must ensure that the probability distributions of <span class="math inline">\(m \in \mathcal{M}\)</span> and <span class="math inline">\(c \in \mathcal{C}\)</span> have the same entropy.</li>
<li>An algorithm with finite input cannot generate randomness infinitely. Consider a circuit that takes the encoded algorithm with some input (<span class="math inline">\(\ell\)</span> bits in total) and outputs some randomness, the entropy of the output data is at most <span class="math inline">\(\ell\)</span> bits. (Further topic: <em>Kolmogorov complexity</em>)</li>
</ul>
<p><em>Relative entropy (KL divergence)</em> quantifies how much information diverges between two sets of data. For data differencing, the KL divergence gives the minimum patch size that is needed to reconstruct target data (with distribution <span class="math inline">\(p(x)\)</span>) given source data (with distribution <span class="math inline">\(q(x)\)</span>).</p>
<p>In particular, if <span class="math inline">\(p(x) = q(x)\)</span>, which means that the two distributions are identical, we have <span class="math inline">\(\operatorname{D}_\mathrm{KL}(p\|q) = 0\)</span>. This follows our intuition that no information is gained or lost during data encoding/decoding. If <span class="math inline">\(p(x_0) = 0\)</span> at <span class="math inline">\(x=x_0\)</span>, we take <span class="math inline">\(p(x) \log \frac{p(x)}{q(x)} = 0\)</span>, to justify the fact that the target data is trivial to reconstruct at this point, no matter how much information <span class="math inline">\(q(x)\)</span> contains. However, if <span class="math inline">\(q(x_0) = 0\)</span> at <span class="math inline">\(x=x_0\)</span>, we should take <span class="math inline">\(p(x) \log \frac{p(x)}{q(x)} = \infty\)</span>, so that the target data is impossible to reconstruct if we have only trivial <span class="math inline">\(q(x)\)</span> at some point (unless <span class="math inline">\(p(x_0) = 0\)</span>).</p>
<p><strong>Lemma 4.1. (Gibbs’ inequality)</strong><a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a> <em>The KL divergence is always non-negative: <span class="math inline">\(\operatorname{D}_\mathrm{KL}(p\|q) \geq 0\)</span>.</em></p>
<p>Informally, Lemma 4.1 simply states that in order to reconstruct target data from source data, either more information (<span class="math inline">\(\operatorname{D}_\mathrm{KL}(p\|q) &gt; 0\)</span>) or no further information (<span class="math inline">\(\operatorname{D}_\mathrm{KL}(p\|q) = 0\)</span>) is needed.</p>
</section>
<section id="maximum-entropy-and-normality" class="level2">
<h2>Maximum entropy and normality</h2>
<p><strong>Theorem 4.2.</strong> <em>Normal distribution <span class="math inline">\(\mathcal{N}(\mu,\sigma^2)\)</span> maximizes the differential entropy for given mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>.</em></p>
<p><strong>Proof.</strong><a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a> Let <span class="math inline">\(g(x)\)</span> be a pdf of the normal distribution with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>. Let <span class="math inline">\(f(x)\)</span> be an arbitrary pdf with the same mean and variance.</p>
<p>Consider the KL divergence between <span class="math inline">\(f(x)\)</span> and <span class="math inline">\(g(x)\)</span>. By Lemma 4.1 (Gibbs’ inequality): <span class="math display">\[\operatorname{D}_\mathrm{KL}(f\|g) = \int_{-\infty}^\infty f(x) \log \frac{f(x)}{g(x)} dx = \operatorname{H}(f,g) - \operatorname{H}(f) \geq 0\]</span></p>
<p>Notice that <span class="math display">\[\begin{align*}
\operatorname{H}(f,g) &amp;= - \int_{-\infty}^\infty f(x) \log g(x) dx \\
&amp;= - \int_{-\infty}^\infty f(x) \log \left( \frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{(x-\mu)^2}{2\sigma^2}} \right) dx \\
&amp;= \frac{1}{2} \left( \log(2\pi\sigma^2) + 1 \right) \\
&amp;= \operatorname{H}(g)
\end{align*}\]</span> Therefore, <span class="math display">\[\operatorname{H}(g) \geq \operatorname{H}(f)\]</span> That is, the distribution of <span class="math inline">\(g(x)\)</span> (Gaussian) always has the maximum entropy. <p style='text-align:right !important;text-indent:0 !important;position:relative;top:-1em'>&#9632;</p></p>
<p>It is also possible to derive the normal distribution directly from the principle of maximum entropy, under the constraint such that <span class="math inline">\(\int_{-\infty}^\infty (x-\mu)^2f(x)dx = \sigma^2\)</span>.</p>
<p>The well-known central limit theorem (CLT) which states that the sum of independent random variables <span class="math inline">\(\{X_1,\dots,X_n\}\)</span> tends toward a normal distribution may be alternatively expressed as the monotonicity of the entropy of the normalized sum: <span class="math display">\[\operatorname{H}\left( \frac{\sum_{i=1}^n X_i}{\sqrt{n}} \right)\]</span> which is an increasing function of <span class="math inline">\(n\)</span>. <span class="citation" data-cites="artstein2004solution">[1]</span></p>
</section>
<section id="references-and-further-reading" class="level2">
<h2>References and further reading</h2>
<p><strong>Books:</strong></p>
<p>T. M. Cover and J. A. Thomas. <em>Elements of Information Theory</em>, 2nd ed.</p>
<p><strong>Papers:</strong></p>
<div id="refs" class="references">
<div id="ref-artstein2004solution">
<p>[1] S. Artstein, K. Ball, F. Barthe, and A. Naor, “Solution of shannon’s problem on the monotonicity of entropy,” <em>Journal of the American Mathematical Society</em>, vol. 17, no. 4, pp. 975–982, 2004. </p>
</div>
</div>
</section>
<section class="footnotes">
<hr />
<ol>
<li id="fn1"><p><a href="https://en.wikipedia.org/wiki/Information_theory_and_measure_theory" class="uri">https://en.wikipedia.org/wiki/Information_theory_and_measure_theory</a><a href="#fnref1" class="footnoteBack">↩</a></p></li>
<li id="fn2"><p><a href="https://en.wikipedia.org/wiki/Gibbs&#39;_inequality" class="uri">https://en.wikipedia.org/wiki/Gibbs'_inequality</a><a href="#fnref2" class="footnoteBack">↩</a></p></li>
<li id="fn3"><p><a href="https://en.wikipedia.org/wiki/Differential_entropy#Maximization_in_the_normal_distribution" class="uri">https://en.wikipedia.org/wiki/Differential_entropy#Maximization_in_the_normal_distribution</a><a href="#fnref3" class="footnoteBack">↩</a></p></li>
</ol>
</section>

]]>
    </content>
  </entry>
  <entry>
    <title>The Adversarial Computation</title>
    <link rel="alternate" type="text/html" href="https://www.soimort.org/mst/3" />
    <id>tag:www.soimort.org,2017:/mst/3</id>
    <published>2017-01-01T00:00:00+01:00</published>
    <updated>2017-01-01T00:00:00+01:00</updated>
    <author>
      <name>Mort Yao</name>
    </author>
    
    <content type="html" xml:lang="en" xml:base="https://www.soimort.org/">
<![CDATA[
<p><a href="https://wiki.soimort.org/comp/">Theory of computation</a> (computability and complexity) forms the basis for modern cryptography:</p>
<ul>
<li>What is an <a href="https://wiki.soimort.org/comp/algorithm/">algorithm</a>?
<ul>
<li>An algorithm is a <em>computational method</em> for solving an <em>abstract problem</em>.</li>
<li>An algorithm takes as input a set <span class="math inline">\(I\)</span> of <em>problem instances</em>, and outputs a solution from the set <span class="math inline">\(S\)</span> of <em>problem solutions</em>.</li>
<li>An algorithm is represented in a well-defined <a href="https://wiki.soimort.org/comp/language/">formal language</a>.</li>
<li>An algorithm must be able to be represented within a finite amount of time and space (otherwise it cannot be actually used for solving any problem).</li>
<li>An algorithm can be simulated by any <em>model of computation</em>:
<ul>
<li><em>Turing machine</em> is a model implemented through internal <em>states</em>.</li>
<li><em>λ-calculus</em> is a model based on pure <em>functions</em>.</li>
<li>All Turing-complete models are equivalent in their computational abilities.</li>
</ul></li>
<li>Computability: Not every abstract problem is solvable. Notably, there exists a decision problem for which some instances can neither be accepted nor rejected by any algorithm. (<em>Undecidable problem</em>)</li>
<li>Complexity:
<ul>
<li>The complexity class P is closed under polynomial-time reductions. Hence, proof by reduction can be a useful technique in provable security of cryptosystems.</li>
<li>If one can prove that P = NP, then one-way functions do not exist. This would invalidate the construction of cryptographically secure pseudorandom generators (PRG). (<em>Pseudorandom generator theorem</em>)</li>
</ul></li>
<li>In many scenarios, we assume that an algorithm acts as a stateless computation and takes independent and identically distributed inputs. It differs from a computer program conceptually.</li>
<li>An algorithm can be either <em>deterministic</em> or <em>probabilistic</em>.
<ul>
<li>For probabilistic algorithms, the source of randomness may be from:
<ul>
<li>External (physical) input of high entropy.</li>
<li>Pseudorandomness: Since everything computational is deterministic, the existence of pseudorandomness relies on the (assumed) existence of one-way functions and PRGs.</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<p>Generally, pseudorandom generators used in probabilistic algorithms yield random bits according to the uniform distribution, so it is worth mentioning:</p>
<ul>
<li>Basic probability theory
<ul>
<li><a href="https://wiki.soimort.org/math/probability/#discrete-uniform-distribution">Discrete uniform distribution</a>. <span class="math inline">\(\mathcal{U}\{a,b\}\)</span>. The probability distribution where a finite number of values are equally likely to be observed (with probability <span class="math inline">\(\frac{1}{b-a+1}\)</span>).</li>
</ul></li>
</ul>
<p>Cryptographic schemes are defined as tuples of deterministic or probabilistic algorithms:</p>
<ul>
<li><a href="https://wiki.soimort.org/crypto/intro/">Principles of modern cryptography</a>
<ul>
<li>Formal description of a <em>private-key encryption scheme</em> <span class="math inline">\(\Pi=(\mathsf{Gen},\mathsf{Enc},\mathsf{Dec})\)</span> with message space <span class="math inline">\(\mathcal{M}\)</span>.
<ul>
<li><span class="math inline">\(\mathsf{Gen}\)</span>, <span class="math inline">\(\mathsf{Enc}\)</span>, <span class="math inline">\(\mathsf{Dec}\)</span> are three algorithms.</li>
<li>Correctness: <span class="math inline">\(\mathsf{Dec}_k(\mathsf{Enc}_k(m)) = m\)</span>.</li>
<li>For the correctness equality to hold, <span class="math inline">\(\mathsf{Dec}\)</span> should be deterministic.</li>
<li>Assume that we have access to a source of randomness, <span class="math inline">\(\mathsf{Gen}\)</span> should choose a key at random thus is probabilistic. If <span class="math inline">\(\mathsf{Gen}\)</span> is deterministic and always generate the same key, such an encryption scheme is of no practical use and easy to break.</li>
<li><span class="math inline">\(\mathsf{Enc}\)</span> can be either deterministic (e.g., as in one-time pads) or probabilistic. Later we will see that for an encryption scheme to be CPA-secure, <span class="math inline">\(\mathsf{Enc}\)</span> should be probabilistic.</li>
</ul></li>
<li><strong>Kerchhoffs’ principle (Shannon’s maxim)</strong> claims that a cryptosystem should be secure even if the scheme <span class="math inline">\((\mathsf{Gen},\mathsf{Enc},\mathsf{Dec})\)</span> is known to the adversary. That is, security should rely solely on the secrecy of the private key.</li>
<li>Provable security of cryptosystems requires:
<ol type="1">
<li>Formal definition of security;</li>
<li>Minimal assumptions;</li>
<li>Rigorous proofs of security.</li>
</ol></li>
<li>Common attacks and notions of security:
<ul>
<li><strong>Ciphertext-only attack</strong>.
<ul>
<li>A cryptosystem is said to be <em>perfectly secret</em> if it is theoretically unbreakable under ciphertext-only attack.</li>
<li>A cryptosystem is said to be <em>computationally secure</em> if it is resistant to ciphertext-only attack (by any polynomial-time adversary).</li>
</ul></li>
<li><strong>Known-plaintext attack (KPA)</strong>. A cryptosystem is <em>KPA-secure</em> if it is resistant to KPA.
<ul>
<li>KPA-security implies ciphertext-only security.</li>
</ul></li>
<li><strong>Chosen-plaintext attack (CPA)</strong>. A cryptosystem is <em>CPA-secure</em> (or <em>IND-CPA</em>) if it is resistant to CPA.
<ul>
<li>IND-CPA implies KPA-security.</li>
</ul></li>
<li><strong>Chosen-ciphertext attack (CCA)</strong>. A cryptosystem is <em>CCA-secure</em> (or <em>IND-CCA1</em>) if it is resistant to CCA; furthermore, a cryptosystem is <em>IND-CCA2</em> if it is resistant to adaptive CCA (where the adversary may make further calls to the oracle, but may not submit the challenge ciphertext).
<ul>
<li>IND-CCA1 implies IND-CPA.</li>
<li>IND-CCA2 implies IND-CCA1. Thus, IND-CCA2 is the strongest of above mentioned definitions of security.</li>
</ul></li>
</ul></li>
</ul></li>
<li><a href="https://wiki.soimort.org/crypto/perfect-secrecy/">Perfect secrecy</a>
<ul>
<li>Two equivalent definitions: (proof of equivalence uses Bayes’ theorem)
<ul>
<li><span class="math inline">\(\Pr[M=m\,|\,C=c] = \Pr[M=m]\)</span>. (Observing a ciphertext <span class="math inline">\(c\)</span> does not leak any information about the underlying message <span class="math inline">\(m\)</span>)</li>
<li><span class="math inline">\(\Pr[\mathsf{Enc}_K(m)=c] = \Pr[\mathsf{Enc}_K(m&#39;)=c]\)</span>. (The adversary has no bias when distinguishing two messages if given only the ciphertext <span class="math inline">\(c\)</span>)</li>
</ul></li>
<li><strong>Perfect indistinguishability</strong> defined on adversarial indistinguishability experiment <span class="math inline">\(\mathsf{PrivK}_{\mathcal{A},\Pi}^\mathsf{eav}\)</span>:
<ul>
<li><span class="math inline">\(\Pr[\mathsf{PrivK}_{\mathcal{A},\Pi}^\mathsf{eav} = 1] = \frac{1}{2}\)</span>. (No adversary can win the indistinguishability game with a probability better than random guessing)</li>
</ul></li>
<li>Perfect indistinguishability is equivalent to the definition of perfect secrecy.</li>
<li>The adversarial indistinguishability experiment is a very useful setting in defining provable security, e.g., the definition of computational indistinguishability: (for arbitrary input size <span class="math inline">\(n\)</span>)
<ul>
<li><span class="math inline">\(\Pr[\mathsf{PrivK}_{\mathcal{A},\Pi}^\mathsf{eav}(n) = 1] \leq \frac{1}{2} + \mathsf{negl}(n)\)</span> where <span class="math inline">\(\mathsf{negl}(n)\)</span> is a negligible function.</li>
</ul></li>
<li>Perfect secrecy implies that <span class="math inline">\(|\mathcal{K}| \geq |\mathcal{M}|\)</span>, i.e., the key space must be larger than the message space. If <span class="math inline">\(|\mathcal{K}| &lt; |\mathcal{M}|\)</span>, then the scheme cannot be perfectly secure.</li>
<li><strong>Shannon’s theorem</strong>: If <span class="math inline">\(|\mathcal{K}| = |\mathcal{M}| = |\mathcal{C}|\)</span>, an encryption scheme is perfectly secret iff:
<ul>
<li><span class="math inline">\(k \in \mathcal{K}\)</span> is chosen uniformly.</li>
<li>For every <span class="math inline">\(m \in \mathcal{M}\)</span> and <span class="math inline">\(c \in \mathcal{C}\)</span>, there exists a unique <span class="math inline">\(k \in \mathcal{K}\)</span> such that <span class="math inline">\(\mathsf{Enc}_k(m) = c\)</span>.</li>
</ul></li>
</ul></li>
</ul>
<p>A brief, formalized overview of some classical ciphers, and their security:</p>
<ul>
<li><a href="https://wiki.soimort.org/crypto/one-time-pad/">One-time pad (Vernam cipher)</a>: XOR cipher when <span class="math inline">\(|\mathcal{K}| = |\mathcal{M}|\)</span>.
<ul>
<li>One-time pad is perfectly secret. The proof simply follows from Bayes’ theorem. (Also verified by Shannon’s theorem. While one-time pad was initially introduced in the 19th century and patented by G. Vernam in 1919, it was not until many years later Claude Shannon gave a formal definition of information-theoretical security and proved that one-time pad is a perfectly secret scheme in his groundbreaking paper. <a href="#ref-shannon1949communication"><span class="citation" data-cites="shannon1949communication">[1]</span></a>)</li>
<li>One-time pad is deterministic. Moreover, it is a reciprocal cipher (<span class="math inline">\(\mathsf{Enc} = \mathsf{Dec}\)</span>).</li>
<li>One-time pad is <em>not</em> secure when the same key is applied in multiple encryptions, and it is <em>not</em> CPA-secure. In fact, an adversary can succeed in such indistinguishability experiments with probability 1.</li>
</ul></li>
<li>Insecure historical ciphers:
<ul>
<li><a href="https://wiki.soimort.org/crypto/classical/shift/">Shift cipher</a>: Defined with key space <span class="math inline">\(\mathcal{K}=\{0,\dots,n-1\}\)</span>. (<span class="math inline">\(n=|\Sigma|\)</span>)
<ul>
<li><span class="math inline">\(|\mathcal{K}|=n\)</span>, <span class="math inline">\(|\mathcal{M}|=n^\ell\)</span>.</li>
<li>Cryptanalysis using frequency analysis.</li>
</ul></li>
<li><a href="https://wiki.soimort.org/crypto/classical/substitution/">Substitution cipher</a>: Defined with key space <span class="math inline">\(\mathcal{K} = \mathfrak{S}_\Sigma\)</span> (symmetric group on <span class="math inline">\(\Sigma\)</span>).
<ul>
<li><span class="math inline">\(|\mathcal{K}|=n!\)</span>, <span class="math inline">\(|\mathcal{M}|=n^\ell\)</span>.</li>
<li>Cryptanalysis using frequency analysis.</li>
</ul></li>
<li><a href="https://wiki.soimort.org/crypto/classical/vigenere/">Vigenère cipher (poly-alphabetic shift cipher)</a>: Like (mono-alphabetic) shift cipher, but the key length is an (unknown) integer <span class="math inline">\(t\)</span>.
<ul>
<li><span class="math inline">\(|\mathcal{K}|=n^t\)</span>, <span class="math inline">\(|\mathcal{M}|=n^\ell\)</span>. (Typically <span class="math inline">\(t \ll \ell\)</span>)</li>
<li>Cryptanalysis using Kasiski’s method, index of coincidence method and frequency analysis.</li>
</ul></li>
</ul></li>
</ul>
<p>Lessons learned from these classical ciphers: While perfect secrecy is easy to achieve (one-time pads), designing practical cryptographic schemes (with shorter keys, and computationally hard to break) can be difficult.</p>
<section id="where-do-random-bits-come-from" class="level2">
<h2>Where do random bits come from?</h2>
<p>The construction of private-key encryption schemes involves probabilistic algorithms. We simply assume that an unlimited supply of independent, unbiased random bits is available for these cryptographic algorithms. But in practice, this is a non-trivial issue, as the source of randomness must provide high-entropy data so as to accommodate cryptographically secure random bits.</p>
<p>In the perfectly secret scheme of one-time pads, the key generation algorithm <span class="math inline">\(\mathsf{Gen}\)</span> requires the access to a source of randomness in order to choose the uniformly random key <span class="math inline">\(k \in \mathcal{K}\)</span>. Practically, high-entropy data may be collected via physical input or even fully written by hand with human labor.</p>
<p>Theoretically, without external intervention, we have:</p>
<p><strong>Conjecture 3.1.</strong> <em>Pseudorandom generators exist.</em></p>
<p><strong>Theorem 3.2. (Pseudorandom generator theorem)</strong> <em>Pseudorandom generators exist if and only if one-way functions exist.</em></p>
<p>Pseudorandomness is also a basic construction in CPA-secure encryption algorithms (<span class="math inline">\(\mathsf{Enc}\)</span>), e.g., in stream ciphers and block ciphers.</p>
<p>So what is an acceptable level of pseudorandomness, if we are not sure whether such generators theoretically exist? Intuitively, if one cannot distinguish between a “pseudorandom” string (generated by a PRG) and a truly random string (chosen according to the uniform distribution), we have confidence that the PRG is a good one. Various statistical tests have been designed for testing the randomness of PRGs.</p>
</section>
<section id="pseudorandomness-and-ind-cpa" class="level2">
<h2>Pseudorandomness and IND-CPA</h2>
<p>It holds true that:</p>
<p><strong>Corollary 3.3.</strong> By redefining the key space, we can assume that any encryption scheme <span class="math inline">\(\Pi=(\mathsf{Gen},\mathsf{Enc},\mathsf{Dec})\)</span> satisfies</p>
<ol type="1">
<li><span class="math inline">\(\mathsf{Gen}\)</span> chooses a uniform key.</li>
<li><span class="math inline">\(\mathsf{Enc}\)</span> is deterministic.</li>
</ol>
<p>If so, why do we still need probabilistic <span class="math inline">\(\mathsf{Enc}\)</span> in CPA-secure encryptions? Can’t we just make <span class="math inline">\(\mathsf{Enc}\)</span> deterministic while still being CPA-secure?</p>
<p>The first thing to realize is that chosen-plaintext attacks are geared towards multiple encryptions (with the same secret key <span class="math inline">\(k\)</span>), so when the adversary obtains a pair <span class="math inline">\((m_0, c_0)\)</span> such that <span class="math inline">\(\Pr[C=c_0\,|\,M=m_0] = 1\)</span>, <em>the key is already leaked</em>. (Recall that the adversary knows the <em>deterministic</em> algorithm <span class="math inline">\(\mathsf{Enc}_k\)</span>, thus reversing <span class="math inline">\(k\)</span> from known <span class="math inline">\(m_0\)</span> and <span class="math inline">\(c_0\)</span> can be quite feasible; e.g., in a one-time pad, <span class="math inline">\(k = m_0 \oplus c_0\)</span>.) The only way to get around this is make <span class="math inline">\(\mathsf{Enc}_k\)</span> <em>probabilistic</em> (constructed from a <em>pseudorandom function</em>), such that an adversary cannot reverse the key efficiently within polynomial time.</p>
<p>Note that perfect secrecy is not possible under CPA, since there is a small possibility that the adversary will reverse the key (by, for example, traversing an exponentially large lookup table of all random bits) and succeed in the further indistinguishability experiment with a slightly higher (but negligible) probability.</p>
</section>
<section id="historical-exploits-of-many-time-pad" class="level2">
<h2>Historical exploits of many-time pad</h2>
<p>One-time pad is one of the most (provably) secure encryption schemes, and its secrecy does not rely on any computational hardness assumptions. However, it requires that <span class="math inline">\(|\mathcal{K}| \geq |\mathcal{M}|\)</span> (which in fact is a necessary condition for any perfectly secret scheme), thus its real-world use is limited.</p>
<p>The one-time key <span class="math inline">\(k\)</span> (uniformly chosen from the key space <span class="math inline">\(\mathcal{K}\)</span>) may <em>not</em> be simply reused in multiple encryptions. Assume that <span class="math inline">\(|\mathcal{K}| = |\mathcal{M}|\)</span>, for encryptions of <span class="math inline">\(n\)</span> messages, the message space is expanded to size <span class="math inline">\(|\mathcal{M}|^n\)</span>, while the key space remains <span class="math inline">\(\mathcal{K}\)</span>, thus we have <span class="math inline">\(|\mathcal{K}| &lt; |\mathcal{M}|^n\)</span>. Such a degraded scheme (many-time pad) is theoretically insecure and vulnerable to several practical cryptanalyses.</p>
<p>A historical exploit of the vulnerability of many-time pad occurred in the VENONA project, where the U.S. Army’s Signal Intelligence Service (later the NSA) aimed at decrypting messages sent by the USSR intelligence agencies (KGB) over a span of 4 decades. As the KGB mistakenly reused some portions of their one-time key codebook, the SIS was able to break a good amount of the messages.<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a></p>
</section>
<section id="references-and-further-reading" class="level2">
<h2>References and further reading</h2>
<p><strong>Books:</strong></p>
<p>J. Katz and Y. Lindell, <em>Introduction to Modern Cryptography</em>, 2nd ed.</p>
<p><strong>Papers:</strong></p>
<div id="refs" class="references">
<div id="ref-shannon1949communication">
<p>[1] C. E. Shannon, “Communication theory of secrecy systems,” <em>Bell system technical journal</em>, vol. 28, no. 4, pp. 656–715, 1949. </p>
</div>
</div>
</section>
<section class="footnotes">
<hr />
<ol>
<li id="fn1"><p>R. L. Benson, “The Venona story.” <a href="https://www.nsa.gov/about/cryptologic-heritage/historical-figures-publications/publications/coldwar/assets/files/venona_story.pdf" class="uri">https://www.nsa.gov/about/cryptologic-heritage/historical-figures-publications/publications/coldwar/assets/files/venona_story.pdf</a><a href="#fnref1" class="footnoteBack">↩</a></p></li>
</ol>
</section>

]]>
    </content>
  </entry>
  <entry>
    <title>The Probable Outcome</title>
    <link rel="alternate" type="text/html" href="https://www.soimort.org/mst/2" />
    <id>tag:www.soimort.org,2017:/mst/2</id>
    <published>2016-12-23T00:00:00+01:00</published>
    <updated>2016-12-23T00:00:00+01:00</updated>
    <author>
      <name>Mort Yao</name>
    </author>
    
    <content type="html" xml:lang="en" xml:base="https://www.soimort.org/">
<![CDATA[
<p>A refresher of basic probability theory, which is just common knowledge but plays a supporting role in information theory, statistical methods, and consequently, computer science.</p>
<ul>
<li><a href="https://wiki.soimort.org/math/probability/">Basic probability theory</a>
<ul>
<li>An <strong>experiment</strong> has various <strong>outcomes</strong>. The set of all probable outcomes constitute the <strong>sample space</strong> of that experiment.</li>
<li>Any <em>measurable</em> subset of the sample space <span class="math inline">\(\Omega\)</span> is known as an <strong>event</strong>.</li>
<li>A <strong>probability measure</strong> is a real-valued function defined on a set of events <span class="math inline">\(\mathcal{F}\)</span> in a probability space <span class="math inline">\((\Omega,\mathcal{F},\Pr)\)</span> that satisfies measure properties such as countable additivity. (See <strong>Kolmogorov’s axioms</strong>.)</li>
<li>The <strong>union bound</strong> (Boole’s inequality) follows from the fact that a probability measure is σ-sub-additive.</li>
<li><em>Events</em> can be <em>independent</em>. The following conditions hold equivalently for any independent events:
<ul>
<li><span class="math inline">\(\Pr[A_1 \cap A_2] = \Pr[A_1] \cdot \Pr[A_2]\)</span></li>
<li><span class="math inline">\(\Pr[A_1|A_2] = \Pr[A_1]\)</span></li>
</ul></li>
<li><strong>Bayes’ theorem</strong> and the <strong>law of total probability</strong> describe the basic properties of conditional probability.</li>
<li>A <strong>random variable</strong> is a mapping that maps a <em>value</em> to an <em>event</em>. Hence, we have probability measure defined on random variables, such as <span class="math inline">\(\Pr[X=x]\)</span>.
<ul>
<li>For <em>discrete</em> random variables, a <strong>probability mass function (pmf)</strong> determines a <strong>discrete probability distribution</strong>.</li>
<li>For <em>continuous</em> random variables, a <strong>probability density function (pdf)</strong> determines a <strong>continuous probability distribution</strong>.</li>
</ul></li>
<li><em>Random variables</em> can be <em>uncorrelated</em>. (<span class="math inline">\(\operatorname{Cov}(X,Y)=0 \iff \operatorname{E}[XY] = \operatorname{E}[X] \cdot \operatorname{E}[Y]\)</span>.)
<ul>
<li><em>Independent</em> random variables are uncorrelated.</li>
<li>However, uncorrelated random variables are not necessarily independent.</li>
</ul></li>
<li>A <em>distribution</em> can be presented using <strong>moments</strong>:
<ul>
<li><strong>Expectation (mean)</strong> <span class="math inline">\(\operatorname{E}[X]\)</span>: first raw moment.</li>
<li><strong>Variance</strong> <span class="math inline">\(\operatorname{Var}(X)\)</span>: second central moment.</li>
<li><strong>Skewness</strong> <span class="math inline">\(\operatorname{Skew}(X)\)</span>: third standardized moment.</li>
<li><strong>Kurtosis</strong> <span class="math inline">\(\operatorname{Kurt}(X)\)</span>: fourth standardized moment.</li>
<li>For a bounded distribution of probability, the collection of all the moments (of all orders) uniquely determines the distribution.</li>
<li>Some distributions, notably Cauchy distributions, do not have their moments defined.</li>
</ul></li>
<li><strong>Concentration inequalities</strong> provide bounds on how a random variable deviates from some value (usually one of its <em>moments</em>).
<ul>
<li><strong>Markov’s inequality</strong> is the simplest and weakest probability bound.</li>
<li><strong>Chebyshev’s inequality</strong> provides an upper bound on the probability that a random variable deviates from its expectation.</li>
<li><strong>Chernoff bound</strong> is stronger than Markov’s inequality.</li>
<li><strong>Hoeffding’s inequality</strong> provides an upper bound on the probability that the sum of random variables deviates from its expectation. It’s also useful for analyzing the number of required samples needed to obtain a confidence interval.</li>
</ul></li>
<li>Some common <em>discrete probability distributions</em>:
<ul>
<li><strong>Bernoulli distribution</strong>. Special case of Binomial distribution: <span class="math inline">\(\text{B}(1,p)\)</span>.</li>
<li><strong>Binomial distribution</strong> <span class="math inline">\(\text{B}(n,p)\)</span>. Given number of draws <span class="math inline">\(n\)</span>, the distribution of the number of successes.</li>
<li><strong>Geometric distribution</strong> <span class="math inline">\(\text{Geom}(p)\)</span>. Special case of negative binomial distribution: <span class="math inline">\(\text{NB}(1,1-p)\)</span>.</li>
<li><strong>Negative binomial distribution</strong> <span class="math inline">\(\text{NB}(r,p)\)</span>. Given number of failures <span class="math inline">\(r\)</span>, the distribution of the number of successes.</li>
</ul></li>
</ul></li>
</ul>
<section id="probability-measure-distribution-and-generalized-function" class="level2">
<h2>Probability measure, distribution and generalized function</h2>
<p>Intuitively, probability is a measure of uncertainty. Mathematically, probability is a real-valued function defined on a set of events in a probability space that satisfies measure properties such as countable additivity (or simply, <em>measure</em> on probability space).</p>
<p>Typically, a probability density function (pdf) or a probability mass function (pmf) determines a distribution in the probability space.</p>
<p><strong>Example 2.1.</strong> Consider the wave function of a particle: <span class="math display">\[\Psi(x,t)\]</span> where <span class="math inline">\(x\)</span> is position and <span class="math inline">\(t\)</span> is time.</p>
<p>If the particle’s position is measured, its location cannot be determined but is described by a probability distribution: The probability that the particle is found in <span class="math inline">\([x, x+\Delta x]\)</span> is <span class="math display">\[\Delta\Pr = |\Psi(x,t)|^2 \Delta x\]</span></p>
<p>The square modulus of the wave function (which is real-valued, non-negative) <span class="math display">\[\left|\Psi(x, t)\right|^2 = {\Psi(x, t)}^{*}\Psi(x, t) = \rho(x, t)\]</span> is interpreted as the pdf.</p>
<p>Since the particle must be found somewhere, we have the normalization condition: (by the assumption of unit measure) <span class="math display">\[\int\limits_{-\infty}^\infty |\Psi(x,t)|^2 dx = 1\]</span></p>
<p>Distributions are also called generalized functions in analysis. It expands the notion of functions to functions whose derivatives may not exist in the classical sense. Thus, it is not uncommon that many probability distributions cannot be described using classical (differentiable) functions. The Dirac delta function <span class="math inline">\(\delta\)</span> (which is a generalized function) is often used to represent a discrete distribution, or a partially discrete, partially continuous distribution, using a pdf.</p>
</section>
<section id="bayes-theorem-and-common-fallacies" class="level2">
<h2>Bayes’ theorem and common fallacies</h2>
<p>Bayes’ theorem forms the basis for <em>Bayesian inference</em>, which is an important method of statistical inference that updates the probability for a <em>hypothesis</em> as more evidence or information becomes available.</p>
<p>Hypotheses can also be fallacies. In Bayesian inference, if one can make the assumption that every event occurs independently and the probability is identically distributed throughout lasting trials, it is clear to see that some common beliefs are mistaken.</p>
<p><strong>Gambler’s fallacy (Monte Carlo fallacy).</strong> If an outcome occurs more frequently than normal during some period, it will happen less frequently in the future; contrariwise, if an outcome happens less frequently than normal during some period, it will happen more frequently in the future. This is presumed to be a means of <em>balancing</em> nature.</p>
<p>Gambler’s fallacy is considered a fallacy if the probability of outcomes is known to be independently, identically distributed. Assume that the future (the probability of event <span class="math inline">\(A_2\)</span>) has no effect on the past (the probability of event <span class="math inline">\(A_1\)</span>), we have <span class="math inline">\(\Pr[A_1|A_2] = \Pr[A_1]\)</span>. From Bayes’ theorem, it holds true that <span class="math display">\[\Pr[A_2|A_1] = \Pr[A_2]\]</span> That is, past events should not increase or decrease our confidence in a future event.</p>
<p><strong>Hot-hand fallacy.</strong> A person who has experienced success with a seemingly random event has a greater chance of further success in additional attempts. That is, if an outcome occurs more frequently than normal during some period, it will also happen frequently in the future.</p>
<p>If psychological factors can be excluded, then hot-hand fallacy is a fallacy caused by people’s confirmation bias. Like the gambler’s fallacy, if we can’t assume that the probability of outcomes is independently, identically distributed, we can’t simply conclude that this belief is mistaken.</p>
<p><strong>Inverse gambler’s fallacy.</strong> If an unlikely outcome occurs, then the trials must have been repeated many times before.</p>
<p>Assume that the past (the probability of event <span class="math inline">\(A_1\)</span>) has no effect on the future (the probability of event <span class="math inline">\(A_2\)</span>), we have <span class="math inline">\(\Pr[A_2|A_1] = \Pr[A_2]\)</span>. From Bayes’ theorem, it holds true that <span class="math display">\[\Pr[A_1|A_2] = \Pr[A_1]\]</span> That is, our confidence in <span class="math inline">\(A_1\)</span> should remain unchanged after we observe <span class="math inline">\(A_2\)</span>.</p>
</section>
<section id="lln-and-chebyshevs-inequality" class="level2">
<h2>LLN and Chebyshev’s inequality</h2>
<p><strong>Fallacies of hasty generalization and slothful induction (law of small numbers).</strong> Informal fallacies reaching an inductive generalization based on insufficient evidence, or denying a reasonable conclusion of an inductive argument.</p>
<p>Statistically saying, sampling from a small group can lead to misbeliefs that fail to hold for the entire population, if hypothesis testing is not carefully conducted.</p>
<p><strong>Theorem 2.2. (Law of large numbers)</strong> Let <span class="math inline">\(X_1, \dots, X_n\)</span> be an infinite sequence of i.i.d. Lebesgue integrable random variables with fixed expectation <span class="math inline">\(\operatorname{E}[X_1] = \cdots = \operatorname{E}[X_n] = \mu\)</span>. Define the sample average <span class="math display">\[\overline{X}_n = \frac{1}{n}(X_1 + \dots + X_n)\]</span></p>
<ol type="1">
<li><strong>(Weak law of large numbers; Khintchine’s law)</strong> The sample average converges in probability towards the expectation: <span class="math display">\[\lim_{n\to\infty} \Pr[|\overline{X}_n - \mu| &gt; \varepsilon] = 0\]</span></li>
<li><strong>(Strong law of large numbers)</strong> The sample average converges <em>almost surely</em> to the expectation: <span class="math display">\[\Pr[\lim_{n\to\infty} \overline{X}_n = \mu] = 1\]</span></li>
</ol>
<p>Chebyshev’s inequality provides an upper bound on the probability that a random variable deviates from its expected value. Thus, it may be used as a proof for the weak law of large numbers.</p>
</section>
<section id="how-is-mathematical-expectation-only-mathematical" class="level2">
<h2>How is mathematical expectation only “mathematical”?</h2>
<p>The expected value of a random variable <span class="math inline">\(X\)</span>: <span class="math display">\[\operatorname{E}[X] = \sum_{x \in \mathcal{X}} x \Pr[X=x]\]</span> While it seemingly gives an estimate on how people would “expect” a random variable to take its value, it can sometimes lead to counterintuitive results, as shown by the following paradox.</p>
<p><strong>St. Petersburg Paradox.</strong><a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> A casino offers a game of chance for a gambler to flip a fair coin until it comes up tails. The initial stake starts at <span class="math inline">\(2\)</span> dollars and is doubled every time heads appears. The first time tails appears, the game ends and the gambler wins whatever is in the pot. Thus if the coin comes up tails the first time, the gambler wins <span class="math inline">\(2^1=2\)</span> dollars, and the game ends. If the coin comes up heads, the coin is flipped again. If the coin comes up tails the second time, the gambler wins <span class="math inline">\(2^2=4\)</span> dollars, and the game ends. If the coin comes up heads again, the coin is flipped again. If the coin comes up tails the third time, the gambler wins <span class="math inline">\(2^3=8\)</span> dollars, and the game ends. So on and so like. Eventually the gambler wins <span class="math inline">\(2^k\)</span> dollars, where <span class="math inline">\(k\)</span> is the number of coin flips until tails appears. (It is easy to see that <span class="math inline">\(k\)</span> satisfies the geometric distribution.) What would be a fair price to pay the casino for entering such a game? (Assume that there is no house edge)</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;"><span class="math inline">\(k\)</span>th coin flip</th>
<th style="text-align: center;"><span class="math inline">\(\Pr[\text{Tails}]\)</span></th>
<th style="text-align: center;">Stake</th>
<th style="text-align: center;">Expected payoff</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">1</td>
<td style="text-align: center;"><span class="math inline">\(\frac{1}{2}\)</span></td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="even">
<td style="text-align: center;">2</td>
<td style="text-align: center;"><span class="math inline">\(\frac{1}{4}\)</span></td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="odd">
<td style="text-align: center;">3</td>
<td style="text-align: center;"><span class="math inline">\(\frac{1}{8}\)</span></td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="even">
<td style="text-align: center;">4</td>
<td style="text-align: center;"><span class="math inline">\(\frac{1}{16}\)</span></td>
<td style="text-align: center;">16</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="odd">
<td style="text-align: center;">5</td>
<td style="text-align: center;"><span class="math inline">\(\frac{1}{32}\)</span></td>
<td style="text-align: center;">32</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="even">
<td style="text-align: center;">…</td>
<td style="text-align: center;">…</td>
<td style="text-align: center;">…</td>
<td style="text-align: center;">…</td>
</tr>
<tr class="odd">
<td style="text-align: center;">k</td>
<td style="text-align: center;"><span class="math inline">\((1/2)^k\)</span></td>
<td style="text-align: center;"><span class="math inline">\(2^k\)</span></td>
<td style="text-align: center;">1</td>
</tr>
</tbody>
</table>
<p>The price should be made equal to the expected value that a gambler wins the stake, which is <span class="math display">\[\operatorname{E}[\text{Payoff}]
= \sum_{k=1}^{+\infty} \left(\frac{1}{2}\right)^k \cdot 2^k
= \sum_{k=1}^{+\infty} 1
= +\infty\]</span></p>
<p>If a rational gambler pays for entering a game if and only if its average payoff is larger than its price, then he would pay any price to enter this game (since the expected payoff of this game is infinitely large). But in reality, few of us are willing to pay even tens of dollars to enter such a game. What went wrong? Furthermore, if <em>mathematical</em> expectation does not reflect correctly what people expect from a game, how to quantify the “<em>true</em>” expectation?</p>
<p>The St. Petersburg paradox was initially stated by Nicolas Bernoulli in 1713. There are several proposed approaches for solving the paradox, including the <a href="https://en.wikipedia.org/wiki/Expected_utility_hypothesis">expected utility</a> theory with the hypothesis of diminishing marginal utility <a href="#ref-sep-paradox-stpetersburg"><span class="citation" data-cites="sep-paradox-stpetersburg">[1]</span></a>, and the cumulative prospect theory. However, none of them is purely probability theoretical, as they require the use of hypothesized economic/behavioral models.</p>
</section>
<section id="bias-of-sample-variance-and-bessels-correction" class="level2">
<h2>Bias of sample variance and Bessel’s correction</h2>
<p>In probability theory, the variance of a random variable <span class="math inline">\(X\)</span> is defined as <span class="math display">\[\operatorname{Var}(X) = \operatorname{E}[(X-\mu)^2]
= \frac{1}{N} \sum_{i=1}^N (X_i-\bar{X})^2\]</span></p>
<p>In statistics, when calculating the sample variance in order to give an estimation of the population variance, and the population mean is unknown, Bessel’s correction<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a> (use of <span class="math inline">\(N-1\)</span> instead of <span class="math inline">\(N\)</span>) is often preferred: <span class="math display">\[s^2 = \frac{1}{N-1} \sum_{i=1}^N (X_i-\bar{X})^2\]</span></p>
<p>A few remarks and caveats:</p>
<ol type="1">
<li>Bessel’s correction is only necessary when the population mean is unknown and estimated as the sample mean.</li>
<li>Without Bessel’s correction, the estimated variance would be <em>biased</em>; the biased sample variance <span class="math inline">\(s_n^2\)</span> tends to be much smaller than the population variance <span class="math inline">\(\sigma^2\)</span>, whether the sample mean is smaller or larger than the population mean.</li>
<li>Bessel’s correction does not yield an unbiased estimator of standard deviation, only variance and covariance.</li>
<li>The corrected estimator often has a larger mean squared error (MSE).</li>
</ol>
</section>
<section id="references-and-further-reading" class="level2">
<h2>References and further reading</h2>
<p><strong>Books:</strong></p>
<p>M. Mitzenmacher and E. Upfal, <em>Probability and Computing: Randomized Algorithms and Probabilistic Analysis</em>.</p>
<p>M. Baron, <em>Probability and Statistics for Computer Scientists</em>, 2nd ed.</p>
<p><strong>Articles:</strong></p>
<div id="refs" class="references">
<div id="ref-sep-paradox-stpetersburg">
<p>[1] R. Martin, “The st. petersburg paradox,” in <em>The stanford encyclopedia of philosophy</em>, Summer 2014., E. N. Zalta, Ed. <a href="https://plato.stanford.edu/archives/sum2014/entries/paradox-stpetersburg/" class="uri">https://plato.stanford.edu/archives/sum2014/entries/paradox-stpetersburg/</a>; Metaphysics Research Lab, Stanford University, 2014. </p>
</div>
</div>
</section>
<section class="footnotes">
<hr />
<ol>
<li id="fn1"><p><a href="https://en.wikipedia.org/wiki/St._Petersburg_paradox" class="uri">https://en.wikipedia.org/wiki/St._Petersburg_paradox</a><a href="#fnref1" class="footnoteBack">↩</a></p></li>
<li id="fn2"><p><a href="https://en.wikipedia.org/wiki/Bessel&#39;s_correction" class="uri">https://en.wikipedia.org/wiki/Bessel's_correction</a><a href="#fnref2" class="footnoteBack">↩</a></p></li>
</ol>
</section>

]]>
    </content>
  </entry>
  <entry>
    <title>Remember My Last Tabs, File Manager</title>
    <link rel="alternate" type="text/html" href="https://www.soimort.org/notes/161208" />
    <id>tag:www.soimort.org,2017:/notes/161208</id>
    <published>2016-12-08T00:00:00+01:00</published>
    <updated>2016-12-13T00:00:00+01:00</updated>
    <author>
      <name>Mort Yao</name>
    </author>
    <category term="tooling" />
    <content type="html" xml:lang="en" xml:base="https://www.soimort.org/">
<![CDATA[
<p>It’s 2016, and I can’t believe that there is still no “Continue where you left off” option in most dominant GUI file managers (as far as I know)!</p>
<p>Yes, it bugs me when I can’t restore my last open tabs and I want my old session so badly. Remembering last tabs, if I get the history right, was a feature first introduced by Google Chrome, and soon it started to play an indispensable part in my daily workflow. I’m a multitasker, but the computing resource of my laptop is very limited – Say, if I have a session in which I am working on a homework report, having loads of folders, web pages and editor buffers open and those can fill up gigabytes of RAM easily, then I realize that I will need to compile something really hard-core, or maybe just take a short rest and do some random surfing on the web, certainly I would rather close all those engrossing processes for the time being, hoping that they could continue with all the open tabs I left off.</p>
<p>It’s mainly four types of applications that account for so-called “work sessions” for me:</p>
<ul>
<li>Terminal emulator</li>
<li>File manager</li>
<li>Web browser</li>
<li>Text editor</li>
</ul>
<p>Terminals don’t take up a lot of memory, so I wouldn’t mind leaving them open. Typical browsers, including Chromium and Firefox, do support session resuming (and there are even <a href="https://chrome.google.com/webstore/detail/session-buddy/edacconmaakjimmfgnblocblbcdcpbko">extensions</a> which allow you to save current tabs and recover them at any later time). Any decent text editor (or IDE) may also be configured to remember open tabs / sessions. After all, average file managers fail to meet my basic needs of productivity.</p>
<section id="file-managers-the-unremembered-ux" class="level2">
<h2>File managers: The unremembered UX</h2>
<p>I’m on GNOME 3, but currently using the <a href="https://github.com/mate-desktop/caja">Caja</a> file manager – ever since Nautilus 3.6 decided to remove two or three features I found important to me (<a href="https://bugzilla.gnome.org/show_bug.cgi?id=676842">compact mode</a>, <a href="https://bugzilla.gnome.org/show_bug.cgi?id=692852">backspace navigation</a>) and introduced an awkward, smug “search-whatever-shit-as-you-type” feature.</p>
<p>File managers I’ve tried so far:</p>
<ul>
<li>Nautilus (GNOME). As said, already rendered unusable for me.</li>
<li>Pantheon. Like Nautilus, it doesn’t feature a compact mode either.</li>
<li>Nemo (Cinnamon). Nope, segfaults too often.</li>
<li>Caja (MATE). It’s OK, just what I’m using right now.
<ul>
<li>Open issue for saving sessions: <a href="https://github.com/mate-desktop/caja/issues/523" class="uri">https://github.com/mate-desktop/caja/issues/523</a></li>
</ul></li>
<li>Dolphin (KDE). OK, unless it’s from the foreign land of KDE.
<ul>
<li>Open issue for saving sessions: <a href="https://bugs.kde.org/show_bug.cgi?id=246028" class="uri">https://bugs.kde.org/show_bug.cgi?id=246028</a></li>
</ul></li>
<li>Konqueror (KDE). It’s both a web browser and a file manager, and it’s the only one I know that can save / restore open tabs. Unfortunately it has only limited file management functionality. (sufficient as a <em>file viewer</em>, though?)</li>
</ul>
<p>Among all above, I settled down with Caja, simply because there was no reasonably good alternative. Still, I’m wishing for something that can save session states for me. After doing a little research, I realized that:</p>
<ol type="1">
<li>There is no commonly adopted protocol addressing this issue. <a href="https://wiki.gnome.org/Projects/SessionManagement/SavingState">Not even on GNOME</a>.</li>
<li>There is <a href="https://wiki.gnome.org/Projects/SessionManagement/EggSMClient">EggSMClient</a>, but state saving is implemented on the X (desktop) session level thus only available on the <a href="https://www.x.org/releases/X11R7.7/doc/libSM/xsmp.html">XSMP</a> backend. It works when you logout your desktop session and login, but not when you close the window and restart the application again.</li>
<li>It is ultimately the application itself which must maintain its session states and restore them when required.</li>
</ol>
</section>
<section id="a-quick-working-patch-for-caja" class="level2">
<h2>A quick working patch for Caja</h2>
<p>Let’s take the issue into more technical details. On Caja (or other similarly GTK+/GLib-based file managers), one need to implement:</p>
<ul>
<li>On the <code>destroy</code> callback of the main <code>GtkObject</code>, all last remaining session data (e.g., internal states about open tabs, windows) must be saved to disk. (after the main loop ends there’s no more chance to get this information back)</li>
<li>On GUI initialization, read last session data (if exist) from disk, and reopen saved tabs as well as windows.</li>
<li>On the event of changing state (e.g., creating or closing tab/window, repositioning tabs), session data are updated respectively and, optionally, saved to disk.</li>
</ul>
<p>With <code>caja_application_get_session_data()</code>, making a quick workaround that enables Caja to save and restore a session is somewhat trivial labor; however, it seems Caja doesn’t record the correct (spatial) ordering of tabs in its session data – so I wouldn’t consider this as a satisfying solution to the issue, and I have no intent to send such an incomplete patch to Caja. Nevertheless, it’s better than nothing, and, if ordering of tabs really matters, it would be feasible to write a <a href="https://github.com/soimort/dotfiles/blob/b721e42238a90e88c83d1feb20682d0605367b11/Scripts/Open-Folders">wrapper script</a> that manipulates the XML file in <code>$HOME/.config/caja/last-session</code>.</p>
<p>And here goes the patch: (Applied to Caja 1.16.1; definitely UNWARRANTED)</p>
<script src="https://gist.github.com/soimort/73c75266d1610ff0af68b40e7b07d939.js"></script>
</section>

]]>
    </content>
  </entry>
  <entry>
    <title>Boilerplating Pandoc for Academic Writing</title>
    <link rel="alternate" type="text/html" href="https://www.soimort.org/notes/161117" />
    <id>tag:www.soimort.org,2017:/notes/161117</id>
    <published>2016-11-17T00:00:00+01:00</published>
    <updated>2016-11-17T00:00:00+01:00</updated>
    <author>
      <name>Mort Yao</name>
    </author>
    <category term="tooling" />
    <content type="html" xml:lang="en" xml:base="https://www.soimort.org/">
<![CDATA[
<p>For starters, this is how you might want to turn your well-written Markdown file (with common metadata fields like <code>title</code>, <code>author</code> and <code>date</code>) into a properly typeset PDF document:</p>
<pre><code>$ pandoc src.md -o out.pdf</code></pre>
<p>However, Markdown is not TeX. <em>Not even close.</em> Once you need to have some bleeding edge control over the typesetting outcome, or perhaps just a little refinement on its LaTeX templating, you’ll soon notice that Pandoc has its quirks and gotchas. I’ve been utilizing Pandoc in all my serious academic writing (incl. homework reports) for years, ever since I gave up on learning more about the overwhelmingly sophisticated TeX ecosystem and turned to something that “just works”. Pandoc fits my needs well. And when it doesn’t, there’s almost always a workaround that achieves the same thing neatly. And this is what this write-up is mostly about.</p>
<section id="tweaking-default.latex-bad-idea." class="level2">
<h2>Tweaking <code>default.latex</code>? Bad idea.</h2>
<p>You could, of course, modify the default template (<a href="https://github.com/jgm/pandoc-templates/blob/master/default.latex"><code>default.latex</code></a>) provided by Pandoc, as long as you’re no stranger to LaTeX. In this way, you can achieve anything you want – in <em>pure</em> LaTeX.</p>
<pre><code>$ pandoc <span class="do">--template my-default.latex</span> src.md -o out.pdf</code></pre>
<p>There are, however, a few problems with this naïve approach:</p>
<ol type="1">
<li>If you are tweaking the template just for something you’re currently working on, you will end up with some highly document-specific, hardly reusable template. Also this won’t give you any good for using Pandoc – you could just write plain LaTeX anyway.</li>
<li>If Pandoc improves its default template for a newer version, your home-brewed template won’t benefit from this (unless you’re willing to merge the diffs and resolve any conflicts by hand).</li>
</ol>
<p>I’m conservative about changing the templates. If it’s a general issue that needs to be fixed in the default template, sending a pull request to <a href="https://github.com/jgm/pandoc-templates">pandoc-templates</a> might be a better idea. Of course, if there’s a certain submission format you have to stick with (given LaTeX templates for conference papers), then you will fall back on your own.</p>
</section>
<section id="separating-the-formatting-stuff" class="level2">
<h2>Separating the formatting stuff</h2>
<p>I wouldn’t claim that I know the best practice of using Pandoc, but there’s such a common idiom that cannot be overstressed: <em>Separate presentation and content!</em></p>
<p>In the YAML front matter of <code>src.md</code> (the main Markdown file you’re writing), put only things that matter to your potential readers:</p>
<div class="sourceCode"><pre class="sourceCode yaml"><code class="sourceCode yaml"><span class="ot">---</span>
<span class="fu">title:</span><span class="at"> Boilerplating Pandoc for Academic Writing</span>
<span class="fu">subtitle:</span><span class="at"> or How I Learned to Stop Typesetting and Concentrate on the Math</span>
<span class="fu">author:</span><span class="at"> Mort Yao</span>
<span class="fu">date:</span><span class="at"> 17 November 2016</span>
<span class="fu">abstract:</span><span class="at"> |</span>
  Lorem ipsum dolor sit amet, consectetur adipiscing elit,
  sed do eiusmod tempor incididunt ut labore et dolore magna
  aliqua. Ut enim ad minim veniam, quis nostrud exercitation
  ullamco laboris nisi ut aliquip ex ea commodo consequat.
<span class="ot">---</span></code></pre></div>
<p>And in a separate YAML file (let’s call it <code>default.yaml</code>), here goes the formatting stuff:</p>
<div class="sourceCode"><pre class="sourceCode yaml"><code class="sourceCode yaml"><span class="ot">---</span>
<span class="fu">geometry:</span><span class="at"> margin=1.5in</span>
<span class="fu">indent:</span><span class="at"> true</span>
<span class="fu">header-includes:</span><span class="at"> |</span>
  \usepackage<span class="kw">{</span>tcolorbox<span class="kw">}</span>
  \newcommand\qed<span class="kw">{</span>\hfill\rule{1em<span class="kw">}{</span>1em<span class="kw">}</span>}
<span class="ot">---</span></code></pre></div>
<p>Above is my personal default, and it’s worth a few words to explain:</p>
<ul>
<li><code>geometry</code> is where you control the geometric settings of your document. For example, you may narrow down the page margin to <code>margin=1.5in</code>, and this is equivalent to raw LaTeX:</li>
</ul>
<pre><code>\usepackage[margin=1.5in]{geometry}</code></pre>
<ul>
<li>Set <code>indent</code> to any value other than <code>false</code> if paragraph indentation is desired. (And it is often desired in formal publications.)</li>
<li><code>header-includes</code> is where you define your own macros, configure existing ones, or claim <code>\usepackage</code> in case you want to use a package not enabled by Pandoc (e.g., <a href="https://www.ctan.org/pkg/tcolorbox"><code>tcolorbox</code></a>). Although you might as well define those in other places (e.g., in the content of a Markdown file), <em>don’t do that</em>.
<ul>
<li>This decent Q.E.D. tombstone: <code>\newcommand\qed{\hfill\rule{1em}{1em}}</code> is my favorite of all time. It doesn’t require the <code>amsthm</code> package.</li>
</ul></li>
</ul>
<p>With a separate <code>default.yaml</code>, now here we are:</p>
<pre><code>$ pandoc <span class="do">default.yaml</span> src.md -o out.pdf</code></pre>
</section>
<section id="separating-header-includes" class="level2">
<h2>Separating <code>header-includes</code></h2>
<p>You might have already noticed that the <code>subtitle</code> field won’t display in the produced PDF file. As far as I’m concerned (in Pandoc 1.18), this is the expected behavior. See <a href="http://pandoc.org/MANUAL.html#fn1">here in README</a>:</p>
<blockquote>
<p>To make <code>subtitle</code> work with other LaTeX document classes, you can add the following to <code>header-includes</code>:</p>
<div class="sourceCode"><pre class="sourceCode tex"><code class="sourceCode latex"><span class="fu">\providecommand</span>{<span class="fu">\subtitle</span>}[1]{<span class="co">%</span>
  <span class="bu">\usepackage</span>{<span class="ex">titling</span>}
  <span class="fu">\posttitle</span>{<span class="co">%</span>
    <span class="fu">\par\large</span>#1<span class="kw">\end</span>{<span class="ex">center</span>}}
}</code></pre></div>
</blockquote>
<p>Unfortunately, this won’t work (until <a href="https://github.com/jgm/pandoc/issues/2139">Issue #2139</a> is resolved) since Pandoc parses the <code>header-includes</code> metadata field as Markdown, and the bracketed <code>[1]</code> is misinterpreted as literals rather than a part of LaTeX control sequence. So the workaround is: Instead of embedding <code>header-includes</code> as a metadata field in YAML, we should separate it into another file for this dedicated purpose (it’s simply raw LaTeX anyway), and include it using <code>--include-in-header/-H</code>:</p>
<pre><code>$ pandoc <span class="do">-H header.tex</span> default.yaml src.md -o out.pdf</code></pre>
<p>Note that you can’t have two <code>header-includes</code> for one document. So the <code>header-includes</code> field specified in YAML metadata will be overridden by the content of <code>header.tex</code>.</p>
</section>
<section id="citing-sources" class="level2">
<h2>Citing sources</h2>
<p>While the Markdown syntax for citing is rather easy (<code>[@id]</code>), it takes effort to make things right, especially if you have a certain preferred citation format (APA, MLA, Chicago, IEEE, etc.).</p>
<p>The suggestion is: Use <a href="https://hackage.haskell.org/package/pandoc-citeproc">pandoc-citeproc</a>. Once you have a list of references you’re interested in, you need two things to typeset those nicely in your document:</p>
<ul>
<li>A CSL (Citation Style Language) file (<code>.csl</code>), to specify the citation format you want to use.
<ul>
<li>You can preview (and download) many common citation styles in the <a href="https://www.zotero.org/styles">Zotero Style Repository</a>.</li>
</ul></li>
<li>A BibTeX file (<code>.bib</code>), which is a list of all entries you might cite.
<ul>
<li>Citation entries in BibTeX format may be found easily on the Internet, through academic search engines and databases. Concatenate them one by one.</li>
</ul></li>
</ul>
<p>As part of the YAML metadata: (Assume you have <code>ieee.csl</code> and <code>references.bib</code>)</p>
<div class="sourceCode"><pre class="sourceCode yaml"><code class="sourceCode yaml"><span class="fu">csl:</span><span class="at"> ieee.csl</span>
<span class="fu">bibliography:</span><span class="at"> references.bib</span></code></pre></div>
<p>Using <code>pandoc-citeproc</code> as a filter, generate the document with citations:</p>
<pre><code>$ pandoc <span class="do">--filter pandoc-citeproc</span> -H header.tex default.yaml src.md -o out.pdf</code></pre>
<p>The list of references is appended to the end of the document. It is often desirable to give the references an obvious title (“References”), start from a new page and avoid any further indentation, so the following comes in the end of the Markdown source:</p>
<div class="sourceCode"><pre class="sourceCode tex"><code class="sourceCode latex"><span class="fu">\newpage</span>
<span class="fu">\setlength\parindent</span>{0pt}

# References</code></pre></div>
</section>
<section id="putting-it-all-together" class="level2">
<h2>Putting it all together!</h2>
<p>Basically, we need 5 files in total:</p>
<ul>
<li>For content:
<ul>
<li><code>src.md</code> (Markdown + possibly LaTeX mixed format): Main text.</li>
<li><code>references.bib</code> (BibTeX/BibLaTeX format): List of references.</li>
</ul></li>
<li>For presentation:
<ul>
<li><code>default.yaml</code> (YAML format): Format-related metadata.</li>
<li><code>header.tex</code> (LaTeX format): Content of <code>header-includes</code>; package imports and macro definitions.</li>
<li><code>ieee.csl</code> (CSL XML format): Citation style.</li>
</ul></li>
</ul>
<p>And one command:</p>
<pre><code>$ pandoc --filter pandoc-citeproc -H <span class="do">header.tex</span> <span class="do">default.yaml</span> <span class="do">src.md</span> -o out.pdf</code></pre>
</section>
<section id="open-question-lightweight-replacement-for-amsthm" class="level2">
<h2>Open question: Lightweight replacement for <code>amsthm</code>?</h2>
<p>Pandoc doesn’t provide native support for <a href="https://www.ctan.org/pkg/amsthm"><code>amsthm</code></a> (and I wonder if there will ever be). You can still have the same thing in Pandoc Markdown:</p>
<div class="sourceCode"><pre class="sourceCode tex"><code class="sourceCode latex"><span class="fu">\newtheorem</span>{definition}{Definition}

<span class="kw">\begin</span>{<span class="ex">definition</span>}
Man is a rational animal.
<span class="kw">\end</span>{<span class="ex">definition</span>}</code></pre></div>
<p>However, everything in between <code>\begin</code> and <code>\end</code> will be treated as raw LaTeX, and the expressiveness of Markdown is lost there. More importantly, this is purely a LaTeX-specific thing, so there’s no way for Pandoc to convert this to HTML or any other format (unless you have a filter that does the trick). Consequently, I tend to write all definitions / theorems (lemmas, claims, corollaries, propositions…) in simple Markdown:</p>
<pre><code>**Definition 1.** *Man is a rational animal.*</code></pre>
<p>It does have some advantages over <code>amsthm</code>:</p>
<ul>
<li>Using <code>amsthm</code>, you cannot see the numbering of each theorem (definition, etc.) in the text editor (well, you can’t without a dedicated plugin at least). This is inconvenient when you need to refer to a prior one later. By numbering them explicitly, you can clearly see these ordinals in the Markdown source.</li>
<li>It is perfectly valid Markdown, so it converts to any format as you wish (HTML, for example).</li>
</ul>
<p>This also has some drawbacks compared to using <code>amsthm</code>, though:</p>
<ul>
<li>It doesn’t have theorem counters. You need to number things explicitly, manually. (Clearly you can’t have implicit numbering and explicit numbering at the same time, so here’s the trade-off.)</li>
<li>It doesn’t have automatic formatting. That is, you could possibly get the style for a certain entry (plain, definition, remark) wrong.</li>
<li>Semantically, they are not recognized as theorems, just normal text paragraphs. This is problematic if you want to prevent definitions and theorems from being indented, since there’s no way for LaTeX to tell them from a normal text.</li>
</ul>
<p>(Probably) The best solution is to write a filter that (conventionally) converts any plain text like <code>Definition 1</code> (and <code>Lemma 2</code>, <code>Theorem 3</code>, etc.) in the beginning of a paragraph to proper Markdown (for HTML target) or corresponding <code>amsthm</code> block (for LaTeX target). Even better, it should be able to do cross-references accordingly (Remember <code>Lemma 10.42</code>? Let’s put an anchored link on that!). This is yet to be done, but would be very helpful to someone who does a lot of theorems and proofs thus wants to avoid the kludge of mixing raw LaTeX with semantically evident Markdown.</p>
</section>

]]>
    </content>
  </entry>
  <entry>
    <title>Bloom Filters in Adversarial Environments</title>
    <link rel="alternate" type="text/html" href="https://www.soimort.org/reports/bloom-filters-in-adversarial-environments" />
    <id>tag:www.soimort.org,2017:/reports/bloom-filters-in-adversarial-environments</id>
    <published>2016-11-15T00:00:00+01:00</published>
    <updated>2016-11-15T00:00:00+01:00</updated>
    <author>
      <name>Mort Yao</name>
    </author>
    
    <content type="html" xml:lang="en" xml:base="https://www.soimort.org/">
<![CDATA[
<p><p style='background-color:yellow'> This is an expository reading summary of a selected <a href="https://eprint.iacr.org/2015/543.pdf">CRYPTO 2015 paper</a> I did as an assignment in KU’s <a href="http://kurser.ku.dk/course/nscphd1080/2016-2017">Introduction to Modern Cryptography</a> course. Adversarial-resilient Bloom filters are the counterparts of cryptographically secure hash functions in an adversarial setting, where adaptive adversaries that have access to a deterministic or non-deterministic query oracle may challenge the data structure in a way that intentionally increases the false positive rate of querying. As a preliminary result, this paper shows that the resistance of Bloom filters against computationally bounded adversaries requires that <a href="/mst/1/#p-versus-np-problem-and-one-way-functions">one-way functions exist</a>; furthermore, such constructions are possible using pseudorandom permutations. I do find the proof a bit involved, but the notions of security introduced for Bloom filters are new and appealing (which I haven’t read previously anywhere else).</p></p>
<p>Original paper:</p>
<ul>
<li><strong>M. Naor and E. Yogev, “Bloom filters in adversarial environments,” in Annual Cryptology Conference, 2015.</strong> <a href="https://arxiv.org/abs/1412.8356">[arXiv:1412.8356]</a></li>
</ul>
<hr />
<p style="text-align:center !important;text-indent:0 !important"><strong>Abstract</strong></p>
<p>Bloom filter is a hash-based probabilistic data structure which is space-efficient for set membership querying, with a small probability of false positives. Naor and Yogev’s 2015 paper introduces the adversarial model and formally proposes a strong notion of security for Bloom filters, i.e., <em>adversarial resilience</em>, based on an adversarial game under a cryptographic setting. This paper also discusses the correspondence between adversarial-resilient Bloom filters and the open assumption that one-way functions exist, thus enables theoretical constructions using pseudorandom permutations. We believe that such an understanding will help design practical Bloom filters that are safe from known attacks in software systems.</p>
<section id="introduction" class="level1">
<h1>1. Introduction</h1>
<p>Probabilistic data structures are data structures that employ randomness in their designs to enable more efficient approaches of storing and querying data, compared to deterministic ones. Traditionally, the algorithmic probabilistic analysis of such data structures assumes the model where all inputs and queries are <em>independent</em> of the internal randomness of data structures. In this work, we consider an adversarial environment, where a computationally bounded adversary<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> may adaptively chooses inputs and queries with the intention of degrading the efficiency of the underlying data structure of some computer system. By introducing the adversarial model, we analyze the behavior of such data representations under the cryptographic notion of computational security against adversaries; furthermore, it enables us to construct more efficient, provably secure schemes of probabilistic data structures.</p>
<p>As a concrete example, a Bloom filter is a probabilistic data structure that holds a set <span class="math inline">\(S\)</span> of elements approximately, using significantly fewer bits of storage and allowing for faster access than a complete representation. As a trade-off between efficiency and preciseness, for any query of <span class="math inline">\(x \in S\)</span>, a Bloom filter always outputs a <em>yes</em>-answer, and for any query of <span class="math inline">\(x \not\in S\)</span>, it should output a <em>yes</em>-answer only with small probability. In other words, a <em>no</em>-answer given by a Bloom filter indicates unambiguously that <span class="math inline">\(x \not\in S\)</span>, while a <em>yes</em>-answer indicates that <span class="math inline">\(x \in S\)</span> probably holds<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a>, that is, it allows false positives. Ideally, the error probability that a Bloom filter returns a false positive should be as small as possible.</p>
<p>Approaching the commonly-seen set membership problem, Bloom filters have been implemented widely in real-world applications, specifically as internal data representations for optimizing large-scale software systems. For example, Akamai’s CDN<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a> servers maintain Bloom filters in their memories to decide whether to lookup the disk cache for a requested resource, and a false positive of the Bloom filter causes a cache miss, which means that the server has to make an unnecessary disk lookup at an expense of time and system workload; if an attacker exploits the behaviors of the Bloom filter, it is possible for them to cast queries that degrade the disk cache hit rate of the CDN servers, and consequently, perform a Denial-of-Service (DoS) attack.<span class="citation" data-cites="maggs2015algorithmic">[1]</span> On another scenario, where Bitcoin clients apply Bloom filters in the Simplified Payment Verification (SPV) mode to increase the overall performance of wallet synchronization, an adversary may perform a DoS attack on an SPV node by learning from the responses of Bloom filters they have access to.<span class="citation" data-cites="benjaminattacks">[2]</span></p>
<p>As discussed above, the adversarial model addresses some security issues, thus the necessity of defining security in adversarial environments and constructing provably secure Bloom filters arises. Essentially, it is desirable for a well-constructed Bloom filter to maintain its small error probability in an adversarial environment; we say that such a Bloom filter is <em>adversarial resilient</em> (or just <em>resilient</em>). In an adversarial game, where an adversary has oracle access to the Bloom filter and is allowed to make a number of <span class="math inline">\(t\)</span> queries before it outputs a certain <span class="math inline">\(x^*\)</span> (that has not been queried before) which is believed to be a false positive, and if it is, the adversary wins the game. We say that a Bloom filter is <span class="math inline">\((n,t,\varepsilon)\)</span>-<em>adversarial resilient</em> if when initialized over sets of size <span class="math inline">\(n\)</span> then after <span class="math inline">\(t\)</span> queries the probability of <span class="math inline">\(x^*\)</span> being a false positive is at most <span class="math inline">\(\varepsilon\)</span>. A Bloom filter that is resilient for any polynomially many queries is said to be <em>strongly resilient</em>.</p>
<p>Clearly, a trivial construction of a strongly resilient Bloom filter would be a deterministic lookup table that stores <span class="math inline">\(S\)</span> precisely, so that there is no false positive which an adversary can find. However, such a construction does not take advantage of the space and time efficiency as a normal Bloom filter would do, since it stores every element in the memory. In the following, we consider only non-trivial Bloom filters, and we show that for a non-trivial Bloom filter to be adversarial-resilient, one-way functions must exist; that is, if one-way functions do not exist, then any non-trivial Bloom filter can be attacked with a non-negligible probability by an efficient adversary. Furthermore, under the assumption that one-way functions exist, a pseudorandom permutation (PRP) can be used to construct a strongly resilient Bloom filter which has a reasonable memory consumption.</p>
<p>The construction of a Bloom filter consists of two algorithms: an initialization algorithm that gets a set <span class="math inline">\(S\)</span> and outputs a memory-efficient representation of <span class="math inline">\(S\)</span>; a query algorithm that gets a representation of <span class="math inline">\(S\)</span> and an <span class="math inline">\(x\)</span> to be checked and outputs <span class="math inline">\(1\)</span> if <span class="math inline">\(x \in S\)</span>, otherwise <span class="math inline">\(0\)</span>. Typically, the initialization algorithm is randomized but the query algorithm is deterministic, that is, a query operation does not amend the existing representation. We say that such a Bloom filter has a <em>steady representation</em>.<a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a></p>
</section>
<section id="definitions" class="level1">
<h1>2. Definitions</h1>
<p>In the following model, we consider a universal set <span class="math inline">\(U\)</span> and a subset <span class="math inline">\(S \subset U\)</span> to be stored in a Bloom filter. We denote that <span class="math inline">\(u=|U|\)</span> and <span class="math inline">\(n=|S|\)</span>.</p>
<p><strong>Definition 1. (Steady-representation Bloom filter)</strong> <em>Let <span class="math inline">\(\mathbf{B}=(\mathbf{B}_1,\mathbf{B}_2)\)</span> be a pair of polynomial-time algorithms, where <span class="math inline">\(\mathbf{B}_1\)</span> is a randomized algorithm that gets as input a set <span class="math inline">\(S\)</span> and outputs a representation <span class="math inline">\(M\)</span>, and <span class="math inline">\(\mathbf{B}_2\)</span> is a deterministic algorithm that gets as input a representation <span class="math inline">\(M\)</span> and a query element <span class="math inline">\(x \in U\)</span>. We say that <span class="math inline">\(\mathbf{B}\)</span> is an <span class="math inline">\((n,\varepsilon)\)</span>-Bloom filter (with a steady representation) if for any set <span class="math inline">\(S \subset U\)</span> of size <span class="math inline">\(n\)</span> it holds that:</em></p>
<ol type="1">
<li><p><span class="math inline">\(\forall x \in S, \Pr[\mathbf{B}_2(\mathbf{B}_1(S), x) = 1] = 1\)</span> <strong>(Completeness)</strong></p></li>
<li><p><span class="math inline">\(\forall x \not\in S, \Pr[\mathbf{B}_2(\mathbf{B}_1(S), x) = 1] \leq \varepsilon\)</span> <strong>(Soundness)</strong></p></li>
</ol>
<p><em>where the probability is taken over the randomness used by the algorithm <span class="math inline">\(\mathbf{B}_1\)</span>.</em></p>
<p>Intuitively, the first property (completeness) says that for all elements in the set <span class="math inline">\(S\)</span>, the Bloom filter is guaranteed to output a <em>yes</em>-answer correctly; the second property (soundness) gives the upper bound that the Bloom filter outputs a false positive, that is, the query algorithm returns <span class="math inline">\(1\)</span> when an element does not actually belong to the set <span class="math inline">\(S\)</span>. Formally,</p>
<p><strong>False positive and error rate.</strong> Given a representation <span class="math inline">\(M\)</span> of <span class="math inline">\(S\)</span>, if <span class="math inline">\(x \not\in S\)</span> and <span class="math inline">\(\mathbf{B}_2(M,x)=1\)</span>, we say that <span class="math inline">\(x\)</span> is a <em>false positive</em>. And we say that the probability bound <span class="math inline">\(\varepsilon\)</span> of outputting false positives is the <em>error rate</em> of <span class="math inline">\(\mathbf{B}\)</span>.</p>
<p>In an adversarial environment, consider the following experiment for any Bloom filter <span class="math inline">\(\mathbf{B}=(\mathbf{B}_1,\mathbf{B}_2)\)</span>, adversary <span class="math inline">\(\mathcal{A}\)</span>, value <span class="math inline">\(t\)</span> as the bound of the amount of queries which <span class="math inline">\(\mathcal{A}\)</span> can make, and value <span class="math inline">\(\lambda\)</span> as the security parameter.</p>
<p><strong>The Bloom filter resilience challenge experiment <span class="math inline">\(\mathsf{Challenge}_{\mathcal{A},\mathbf{B},t}(\lambda)\)</span>:</strong></p>
<ol type="1">
<li><span class="math inline">\(M \leftarrow \mathbf{B}_1(1^\lambda,S)\)</span>.<a href="#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a></li>
<li><span class="math inline">\(x^* \leftarrow \mathcal{A}^{\mathbf{B}_2(M,\cdot)}(1^\lambda,S)\)</span>, where <span class="math inline">\(\mathcal{A}\)</span> performs at most <span class="math inline">\(t\)</span> queries <span class="math inline">\(x_1,\dots,x_t\)</span> to the oracle <span class="math inline">\(\mathbf{B}_2(M,\cdot)\)</span>. Note that <span class="math inline">\(\mathcal{A}\)</span> has only oracle access to the Bloom filter and cannot see the representation <span class="math inline">\(M\)</span>.<a href="#fn6" class="footnoteRef" id="fnref6"><sup>6</sup></a></li>
<li>The output of the experiment is defined to be <span class="math inline">\(1\)</span>, if <span class="math inline">\(x^* \not\in S \cup \{x_1,\dots,x_t\}\)</span> and <span class="math inline">\(\mathbf{B}_2(M,x^*)=1\)</span>, and <span class="math inline">\(0\)</span> otherwise. If the output of the experiment is <span class="math inline">\(1\)</span>, we say that <span class="math inline">\(\mathcal{A}\)</span> succeeds.</li>
</ol>
<p><strong>Definition 2. (Adversarial-resilient Bloom filter)</strong> <em>Let <span class="math inline">\(\mathbf{B}=(\mathbf{B}_1,\mathbf{B}_2)\)</span> be an <span class="math inline">\((n,\varepsilon)\)</span>-Bloom filter (with a steady representation). We say that <span class="math inline">\(\mathbf{B}\)</span> is an <span class="math inline">\((n,t,\varepsilon)\)</span>-adversarial resilient Bloom filter if for any set <span class="math inline">\(S\)</span> of size <span class="math inline">\(n\)</span>, for all sufficiently large <span class="math inline">\(\lambda \in \mathbb{N}\)</span> and for all probabilistic polynomial-time adversaries <span class="math inline">\(\mathcal{A}\)</span>, it holds that</em> <span class="math display">\[\Pr[\mathsf{Challenge}_{\mathcal{A},\mathbf{B},t}(\lambda) = 1] \leq \varepsilon\]</span></p>
<p><em>where the probability is taken over the randomness used by the algorithm <span class="math inline">\(\mathbf{B}_1\)</span> and <span class="math inline">\(\mathcal{A}\)</span>.</em></p>
<p>To define the non-triviality of a Bloom filter formally, notice that it is always desirable to minimize the memory use of the Bloom filter. Let <span class="math inline">\(\mathbf{B}\)</span> be an <span class="math inline">\((n,\varepsilon)\)</span>-Bloom filter that uses <span class="math inline">\(m\)</span> bits of memory. It is shown<span class="citation" data-cites="carter1978exact">[3]</span> that the lower bound of <span class="math inline">\(m\)</span> is <span class="math inline">\(m \geq n \log \frac{1}{\varepsilon}\)</span>. Thus, we define</p>
<p><strong>Definition 3. (Minimal error)</strong> <em>Let <span class="math inline">\(\mathbf{B}\)</span> be an <span class="math inline">\((n,\varepsilon)\)</span>-Bloom filter. We say that <span class="math inline">\(\varepsilon_0 = 2^{-\frac{m}{n}}\)</span> is the minimal error of <span class="math inline">\(\mathbf{B}\)</span>.</em></p>
<p>As mentioned previously, a trivial construction of Bloom filters is a lookup table that stores <span class="math inline">\(S\)</span> precisely, in which case, the memory use <span class="math inline">\(m=\log \binom{u}{n} \approx n \log(\frac{u}{n})\)</span>, thus by using the bound <span class="math inline">\(m \geq n \log \frac{1}{\varepsilon}\)</span>, a construction is trivial if <span class="math inline">\(\varepsilon &gt; \frac{n}{u}\)</span>. On the other hand, if <span class="math inline">\(u\)</span> is super-polynomial in <span class="math inline">\(n\)</span>, then <span class="math inline">\(\varepsilon\)</span> is negligible in <span class="math inline">\(n\)</span> and every polynomial-time adversary has only negligible probability to find any false positive, therefore for such <span class="math inline">\(S \subset U\)</span>, the Bloom filter must be trivial. Notice that <span class="math inline">\(\varepsilon_o \leq \varepsilon\)</span>, we then define</p>
<p><strong>Definition 4. (Non-trivial Bloom filter)</strong> <em>Let <span class="math inline">\(\mathbf{B}\)</span> be an <span class="math inline">\((n,\varepsilon)\)</span>-Bloom filter and let <span class="math inline">\(\varepsilon_0\)</span> be the minimal error of <span class="math inline">\(\mathbf{B}\)</span>. We say that <span class="math inline">\(\mathbf{B}\)</span> is non-trivial if there exists a constant <span class="math inline">\(c \geq 1\)</span> such that <span class="math inline">\(\varepsilon_0 &gt; \max\{\frac{n}{u},\frac{1}{n^c}\}\)</span>.</em></p>
</section>
<section id="resilient-bloom-filters-and-one-way-functions" class="level1">
<h1>3. Resilient Bloom Filters and One-Way Functions</h1>
<p>We now show that the existence of adversarial resilient Bloom filters depends on the existence of one-way functions, that is, if any non-trivial, strongly resilient Bloom filter exists, then one-way functions also exist.</p>
<p><strong>Theorem 5.</strong> <em>Let <span class="math inline">\(\mathbf{B}=(\mathbf{B}_1,\mathbf{B}_2)\)</span> be any non-trivial Bloom filter (with a steady representation) of <span class="math inline">\(n\)</span> elements that uses <span class="math inline">\(m\)</span> bits of memory, and let <span class="math inline">\(\varepsilon_0\)</span> be the minimal error of <span class="math inline">\(\mathbf{B}\)</span>. If <span class="math inline">\(\mathbf{B}\)</span> is <span class="math inline">\((n,t,\varepsilon)\)</span>-adversarial resilient for <span class="math inline">\(t=\mathcal{O}(\frac{m}{\varepsilon_0^2})\)</span>, then one-way functions exist.</em></p>
<p><strong>Proof.</strong> First we assume that one-way functions do not exist, then we show that we can construct a polynomial-time adversary <span class="math inline">\(\mathcal{A}\)</span> such that <span class="math display">\[\Pr[\mathsf{Challenge}_{\mathcal{A},\mathbf{B},t}(\lambda) = 1] &gt; \varepsilon\]</span> given a fixed value <span class="math inline">\(\varepsilon\)</span>. That is, <span class="math inline">\(\mathbf{B}\)</span> cannot be <span class="math inline">\((n,t,\varepsilon)\)</span>-adversarial resilient.</p>
<p>Define the following function <span class="math inline">\(f\)</span>: <span class="math display">\[f(S,r,x_1,\dots,x_t) = (x_1,\dots,x_t,\mathbf{B}_2(M,x_1),\dots,\mathbf{B}_2(M,x_t))\]</span> where <span class="math inline">\(S\)</span> is a set of size <span class="math inline">\(n\)</span>, <span class="math inline">\(r\)</span> is the number of bits used by the randomness of <span class="math inline">\(\mathbf{B}_1\)</span>, <span class="math inline">\(M\)</span> is a representation of <span class="math inline">\(S\)</span> generated by <span class="math inline">\(\mathbf{B}_1\)</span>, and <span class="math inline">\(t=\frac{200m}{\varepsilon_0}\)</span>. Clearly, <span class="math inline">\(f\)</span> is polynomial-time computable.</p>
<p>Since <span class="math inline">\(f\)</span> is not a one-way function (under the assumption that one-way functions do not exist), there is also an algorithm that can invert <span class="math inline">\(f\)</span> efficiently. Thus we have,</p>
<p><strong>Claim 6.</strong> <em>Assume that one-way functions do not exist, there exists a polynomial-time algorithm <span class="math inline">\(\mathcal{A}\)</span> that inverts <span class="math inline">\(f\)</span> with a failure probability of at most <span class="math inline">\(\frac{1}{100}\)</span>:</em> <span class="math display">\[\Pr[f(\mathcal{A}(f(S,r,x_1,\dots,x_t))) \neq f(S,r,x_1,\dots,x_t)] &lt; \frac{1}{100}\]</span></p>
<p><strong>Proof.</strong> Because <span class="math inline">\(f\)</span> is not a one-way function, there exists<span class="citation" data-cites="katz2014introduction">[4]</span> an algorithm <span class="math inline">\(\mathcal{A}&#39;\)</span> such that <span class="math inline">\(\Pr[\mathsf{Invert}_{\mathcal{A}&#39;,f}(n) = 1] \geq \frac{1}{p(n)}\)</span>, where <span class="math inline">\(p(n)\)</span> is polynomial in <span class="math inline">\(n\)</span>. Construct an algorithm <span class="math inline">\(\mathcal{A}\)</span> that runs <span class="math inline">\(\mathcal{A}&#39;\)</span> individually for <span class="math inline">\(\lceil\frac{\log 100}{\log(p(n)) - \log(p(n)-1)}\rceil\)</span> times, so we have the total failure probability <span class="math inline">\(\Pr[f(\mathcal{A}(f(S,r,x_1,\dots,x_t))) \neq f(S,r,x_1,\dots,x_t)] &lt; \left(1-\frac{1}{p(n)}\right)^{\lceil\frac{\log 100}{\log(p(n)) - \log(p(n)-1)}\rceil} \leq \frac{1}{100}\)</span> <p style='text-align:right !important;text-indent:0 !important;position:relative;top:-1em'>&#9632;</p></p>
<p>Using <span class="math inline">\(\mathcal{A}\)</span>, construct the following probabilistic polynomial-time algorithm <span class="math inline">\(\mathsf{Attack}\)</span>:</p>
<blockquote style="background:gainsboro; border-radius:1em; padding:.25em .5em;">
<p><strong>The Algorithm <span class="math inline">\(\mathsf{Attack}\)</span></strong></p>
<p><span class="math inline">\(\mathsf{Attack}\)</span> is given oracle access to the query algorithm <span class="math inline">\(\mathbf{B}_2(M,\cdot)\)</span>, and gets <span class="math inline">\(1^\lambda\)</span> as input.</p>
<ol type="1">
<li>For <span class="math inline">\(i \in \{1,\dots,t\}\)</span>, sample <span class="math inline">\(x_i \in U\)</span> uniformly, and query <span class="math inline">\(y_i = \mathbf{B}_2(M,x_i)\)</span>.</li>
<li>Run <span class="math inline">\(\mathcal{A}\)</span> (the inverter of <span class="math inline">\(f\)</span>) and get <span class="math inline">\((S&#39;,r&#39;,x_1,\dots,x_t) \leftarrow \mathcal{A}(x_1,\dots,x_t,y_1,\dots,y_t)\)</span>.</li>
<li>Compute <span class="math inline">\(M&#39; \overset{r&#39;}{\leftarrow} \mathbf{B}_1(1^\lambda,S&#39;)\)</span>, using <span class="math inline">\(r&#39;\)</span> as the randomness bits in the initialization.</li>
<li>For <span class="math inline">\(k=1,\dots,\frac{100}{\varepsilon_0}\)</span>, do:
<ol type="a">
<li>Sample <span class="math inline">\(x^* \in U\)</span> uniformly.</li>
<li>If <span class="math inline">\(\mathbf{B}_2(M&#39;,x^*)=1\)</span> and <span class="math inline">\(x^* \not\in \{x_1,\dots,x_t\}\)</span>, output <span class="math inline">\(x^*\)</span> and HALT.</li>
</ol></li>
<li>Sample <span class="math inline">\(x^* \in U\)</span> uniformly, and output <span class="math inline">\(x^*\)</span>.</li>
</ol>
</blockquote>
<p><strong>Claim 7.</strong> <em>Assume that <span class="math inline">\(\mathcal{A}\)</span> inverts <span class="math inline">\(f\)</span> successfully. For any representation <span class="math inline">\(M\)</span>, the probability such that there exists a representation <span class="math inline">\(M&#39;\)</span> that for <span class="math inline">\(i \in \{1,\dots,t\}\)</span>, <span class="math inline">\(\mathbf{B}_2(M,x_i)=\mathbf{B}_2(M&#39;,x_i)\)</span>, and that the error rate <span class="math inline">\(\Pr[\mathbf{B}_2(M,x) \neq \mathbf{B}_2(M&#39;,x)] &gt; \frac{\varepsilon_0}{100}\)</span> is at most <span class="math inline">\(\frac{1}{100}\)</span>.</em></p>
<p><strong>Proof.</strong> From the error rate of any <span class="math inline">\(x\)</span> and the independence of the choice of <span class="math inline">\(x_i\)</span>, we get <span class="math display">\[\Pr[\forall i \in \{1,\dots,t\} : \mathbf{B}_2(M,x_i) = \mathbf{B}_2(M&#39;,x_i)] \leq \left(1 - \frac{\varepsilon_0}{100}\right)^t\]</span></p>
<p>Since the Bloom filter uses <span class="math inline">\(m\)</span> bits of memory, there are <span class="math inline">\(2^m\)</span> possible representations as candidates for <span class="math inline">\(M&#39;\)</span>. Thus, by union bound, <span class="math display">\[\Pr[\exists M&#39; \ \forall i \in \{1,\dots,t\} : \mathbf{B}_2(M,x_i) = \mathbf{B}_2(M&#39;,x_i)] \leq 2^m \left(1 - \frac{\varepsilon_0}{100}\right)^t \leq \frac{1}{100}\]</span></p>
<p>Since <span class="math inline">\(\mathcal{A}\)</span> is assumed to invert <span class="math inline">\(f\)</span> successfully, it must output a representation <span class="math inline">\(M&#39;\)</span> such that for <span class="math inline">\(i \in \{1,\dots,t\}\)</span>, <span class="math inline">\(\mathbf{B}_2(M,x_i)=\mathbf{B}_2(M&#39;,x_i)\)</span>. Therefore, the above bound holds. <p style='text-align:right !important;text-indent:0 !important;position:relative;top:-1em'>&#9632;</p></p>
<p>Define <span class="math inline">\(\mu(M)=\Pr_{x \in U}[\mathbf{B}_2(M,x)=1]\)</span> as the positive rate over <span class="math inline">\(U\)</span>, we now show that for almost all possible representations <span class="math inline">\(M\)</span> generated from set <span class="math inline">\(S\)</span> and randomness <span class="math inline">\(r\)</span>, it holds true that <span class="math inline">\(\mu(M) &gt; \frac{\varepsilon_0}{8}\)</span>, with only a negligible probability of error:</p>
<p><strong>Claim 8.</strong> <span class="math inline">\(\Pr_S[\exists r : \mu(M_r^S) \leq \frac{\varepsilon}{8}] \leq 2^{-n}\)</span>.</p>
<p><strong>Proof.</strong> Let <span class="math inline">\(\mathsf{BAD}\)</span> be the set of all sets <span class="math inline">\(S\)</span> such that there exists an <span class="math inline">\(r\)</span> such that <span class="math inline">\(\mu(M_r^S) \leq \frac{\varepsilon_0}{8}\)</span>. Given <span class="math inline">\(S \in \mathsf{BAD}\)</span>, let <span class="math inline">\(\hat{S}\)</span> be the set of all elements <span class="math inline">\(x\)</span> such that <span class="math inline">\(\mathbf{B}_2(M_r^S,x)=1\)</span>, then <span class="math inline">\(|\hat{S}| \leq \frac{\varepsilon_0}{8} \cdot u\)</span>. Notice that we can encode the set <span class="math inline">\(S\)</span> using the representation <span class="math inline">\(M_r^S\)</span> while specifying <span class="math inline">\(S\)</span> from all subsets of <span class="math inline">\(\hat{S}\)</span> of size <span class="math inline">\(n\)</span>, and the encoding bits must be no less than <span class="math inline">\(\log|\mathsf{BAD}|\)</span> (which is the number of bits required to encode <span class="math inline">\(|\mathsf{BAD}|\)</span>): <span class="math display">\[\log|\mathsf{BAD}| \leq m + \log\binom{\frac{\varepsilon_0 u}{8}}{n}
\leq m + n \log\left(\frac{\varepsilon_0 u}{8}\right) - n \log n + 2n
\leq -n + \log\binom{u}{n}
\]</span> thus <span class="math inline">\(|\mathsf{BAD}| \leq 2^{-n}\binom{u}{n}\)</span>. Since the number of sets <span class="math inline">\(S\)</span> is <span class="math inline">\(\binom{u}{n}\)</span>, <span class="math inline">\(\Pr_S[\exists r : \mu(M_r^S) \leq \frac{\varepsilon}{8}] \leq 2^{-n}\)</span>. <p style='text-align:right !important;text-indent:0 !important;position:relative;top:-1em'>&#9632;</p></p>
<p><strong>Claim 9.</strong> <em>Assume that <span class="math inline">\(\Pr[\mathbf{B}_2(M,x) \neq \mathbf{B}_2(M&#39;,x)] \leq \frac{\varepsilon_0}{100}\)</span> and that <span class="math inline">\(\mu(M) &gt; \frac{\varepsilon_0}{8}\)</span>. The probability that <span class="math inline">\(\mathsf{Attack}\)</span> does not halt on Step 4 is at most <span class="math inline">\(\frac{1}{100}\)</span>.</em></p>
<p><strong>Proof.</strong> It follows directly from the assumptions that <span class="math inline">\(\mu(M&#39;) &gt; \frac{\varepsilon_0}{8} - \frac{\varepsilon_0}{100} &gt; \frac{\varepsilon_0}{10}\)</span>. For convenience, let <span class="math inline">\(\mathcal{X} = \{x_1,\dots,x_t\}\)</span> and <span class="math inline">\(\hat{S&#39;} = \{x : \mathbf{B}_2(M&#39;,x)=1\}\)</span>. We have that</p>
<p><span class="math display">\[E[|\hat{S&#39;} \cap \mathcal{X}|] = t \cdot \mu(M&#39;) &gt; \frac{200m}{\varepsilon_0} \cdot \frac{\varepsilon_0}{10} = 20m\]</span></p>
<p>By Chernoff bound with a probability of at least <span class="math inline">\((1-e^{-\Omega(m)})\)</span> we have that <span class="math inline">\(|\hat{S&#39;} \cap \mathcal{X}| &lt; 40m\)</span>, <span class="math display">\[|\hat{S&#39;} \backslash \mathcal{X}|=|\hat{S&#39;}|-|\hat{S&#39;} \cap \mathcal{X}| &gt; |\hat{S&#39;}| - 40m \geq \frac{\varepsilon_0 u}{10} - 40m\]</span></p>
<p><em>Case 1.</em> <span class="math inline">\(u=n^d\)</span> (<span class="math inline">\(d\)</span> is a constant). We show that <span class="math inline">\(|\hat{S&#39;} \backslash \mathcal{X}| \geq 1\)</span>, so that an exhaustive search over the universal set <span class="math inline">\(U\)</span> is efficient and guaranteed to find an element <span class="math inline">\(x^*\)</span> in <span class="math inline">\(\hat{S&#39;} \backslash \mathcal{X}\)</span>. Let <span class="math inline">\(c\)</span> be a constant such that <span class="math inline">\(\varepsilon_0 &gt; \frac{1}{n^c}\)</span>, <span class="math inline">\(\varepsilon_0 &lt; \frac{1}{n^{c-1}}\)</span>. We have <span class="math inline">\(\frac{u}{n} = n^{d-1} \geq \frac{1}{\varepsilon_0} &gt; n^{c-1}\)</span>, then <span class="math inline">\(d-c&gt;1\)</span>. Moreover, <span class="math inline">\(m \leq n \log\frac{u}{n} \leq nd \log n\)</span>, thus, <span class="math display">\[|\hat{S&#39;} \backslash \mathcal{X}| \geq \frac{\varepsilon_0 u}{10} - 40m
\geq \frac{n^{d-c}}{10} - 40nd \log n &gt; 1\]</span></p>
<p><em>Case 2.</em> <span class="math inline">\(u\)</span> is super-polynomial in <span class="math inline">\(n\)</span>. We show that the fraction of <span class="math inline">\(|\hat{S&#39;} \backslash \mathcal{X}|\)</span> is large enough so that sampling can find an <span class="math inline">\(x^*\)</span>, with only a small failure probability. Since <span class="math inline">\(\frac{\varepsilon_0}{20}\)</span> is polynomial in <span class="math inline">\(\frac{1}{n}\)</span> but <span class="math inline">\(\frac{40m}{u} \leq \frac{40n \log u}{u}\)</span> is negligible, we get that <span class="math inline">\(\frac{\varepsilon_0}{20} &gt; \frac{40m}{u}\)</span>. It follow from <span class="math inline">\(\frac{|\hat{S&#39;} \backslash \mathcal{X}|}{u} &gt; \frac{\varepsilon_0}{10} - \frac{40m}{u}\)</span> that <span class="math inline">\(\frac{|\hat{S&#39;} \backslash \mathcal{X}|}{u} &gt; \frac{\varepsilon_0}{20}\)</span>. Thus, the probability of sampling <span class="math inline">\(x \not\in \hat{S&#39;} \backslash \mathcal{X}\)</span> in all <span class="math inline">\(k\)</span> attempts is bounded by <span class="math display">\[\left(1-\frac{\varepsilon_0}{20}\right)^k
= \left(1-\frac{\varepsilon_0}{20}\right)^\frac{100}{\varepsilon_0}
&lt; \frac{1}{100}
\]</span></p>
<p>In both cases, the probability that <span class="math inline">\(\mathsf{Attack}\)</span> fails to find <span class="math inline">\(x^*\)</span> and halt on Step 4 is less than <span class="math inline">\(\frac{1}{100}\)</span>. <p style='text-align:right !important;text-indent:0 !important;position:relative;top:-1em'>&#9632;</p></p>
<p><strong>Claim 10.</strong> <span class="math inline">\(\Pr[\mathbf{B}(M&#39;,x^*)=1; \mathbf{B}_2(M,x^*)=0] \leq \frac{1}{100}\)</span></p>
<p><strong>Proof.</strong> This follows from the assumption that <span class="math inline">\(\Pr[\mathbf{B}_2(M,x) \neq \mathbf{B}_2(M&#39;,x)] \leq \frac{\varepsilon}{100}\)</span>. <p style='text-align:right !important;text-indent:0 !important;position:relative;top:-1em'>&#9632;</p></p>
<p>Consider <strong>Claim 6, 7, 8 &amp; 10</strong> which cover all cases that <span class="math inline">\(\mathsf{Attack}\)</span> fails, each happens only if the respective assumptions hold, so they provide an upper bound of failure probability. Taking a union bound, we have the total failure probability is at most <span class="math inline">\(\frac{4}{100}\)</span>. Thus, we have constructed a polynomial-time adversary <span class="math inline">\(\mathsf{Attack}\)</span> such that <span class="math display">\[\Pr[\mathsf{Challenge}_{\mathsf{Attack},\mathbf{B},t}(\lambda) = 1] &gt; \varepsilon \geq 1-\frac{4}{100}\]</span> therefore <span class="math inline">\(\mathbf{B}\)</span> cannot be <span class="math inline">\((n,t,\varepsilon)\)</span>-adversarial resilient, which is a contradiction implying that such adversarial resilient Bloom filters do not exist, under the assumption that one-way functions do not exist. By modus tollens, we have that if non-trivial <span class="math inline">\((n,t,\varepsilon)\)</span>-adversarial resilient Bloom filters exist, then one-way functions exist. <p style='text-align:right !important;text-indent:0 !important;position:relative;top:-1em'>&#9632;</p></p>
</section>
<section id="further-reading" class="level1">
<h1>4. Further Reading</h1>
<p>In <strong>Theorem 5</strong> we showed that the existence of adversarial resilient Bloom filters implies that one-way functions exist. Furthermore, assume that adversarial resilient Bloom filters exist (thus one-way functions exist), it can be shown that pseudorandom permutations may be used to construct non-trivial, strongly adversarial resilient Bloom filters. We have</p>
<p><strong>Proposition 11. (Construction using pseudorandom permutations)</strong><a href="#fn7" class="footnoteRef" id="fnref7"><sup>7</sup></a> <em>Let <span class="math inline">\(\mathbf{B}\)</span> be an <span class="math inline">\((n,\varepsilon)\)</span>-Bloom filter using <span class="math inline">\(m\)</span> bits of memory. If pseudorandom permutations exist, then for any security parameter <span class="math inline">\(\lambda\)</span>, there exists an <span class="math inline">\((n,\varepsilon+\mathsf{negl}(\lambda))\)</span>-strongly resilient Bloom filter that uses <span class="math inline">\(m&#39;=m+\lambda\)</span> bits of memory.</em></p>
<p><strong>Unsteady representation and computationally unbounded adversary.</strong> The above discussion about Bloom filters assumes that steady representation is used, that is, the query algorithm <span class="math inline">\(\mathbf{B}_2\)</span> is deterministic. Some implementations allow <span class="math inline">\(\mathbf{B}_2\)</span> to change the internal representation thus querying can also be probabilistic. Further results regarding <em>unsteady representations</em> may be found in <span class="citation" data-cites="naor2015bloom">[5]</span>, with the ACD<a href="#fn8" class="footnoteRef" id="fnref8"><sup>8</sup></a> framework proposed in <span class="citation" data-cites="naor2006learning">[6]</span>. Moreover, some results are shown to hold even for <em>computationally unbounded adversaries</em>.</p>
<p><strong>Bloom filters and secrecy.</strong> Bloom filters, like hash functions, are not designed as encryption schemes. Thus, even adversarial resilient Bloom filters may leak considerable information in an unintended way. As a concrete example, in Bitcoin lightweight SPV clients which rely on Bloom filters to store users’ Bitcoin addresses, an adversary can efficiently distinguish information about these addresses. See <span class="citation" data-cites="gervais2014privacy">[7]</span> for a discussion on this interesting scenario.</p>
</section>
<section id="references" class="level1 unnumbered">
<h1>References</h1>
<div id="refs" class="references">
<div id="ref-maggs2015algorithmic">
<p>[1] B. M. Maggs and R. K. Sitaraman, “Algorithmic nuggets in content delivery,” <em>ACM SIGCOMM Computer Communication Review</em>, vol. 45, no. 3, pp. 52–66, 2015. </p>
</div>
<div id="ref-benjaminattacks">
<p>[2] R. Benjamin and E. K. Yasmine, “Attacks on bitcoin,” 2015. </p>
</div>
<div id="ref-carter1978exact">
<p>[3] L. Carter, R. Floyd, J. Gill, G. Markowsky, and M. Wegman, “Exact and approximate membership testers,” in <em>Proceedings of the tenth annual acm symposium on theory of computing</em>, 1978, pp. 59–65. </p>
</div>
<div id="ref-katz2014introduction">
<p>[4] J. Katz and Y. Lindell, “Introduction to modern cryptography,” 2014. </p>
</div>
<div id="ref-naor2015bloom">
<p>[5] M. Naor and E. Yogev, “Bloom filters in adversarial environments,” in <em>Annual cryptology conference</em>, 2015, pp. 565–584. </p>
</div>
<div id="ref-naor2006learning">
<p>[6] M. Naor and G. N. Rothblum, “Learning to impersonate,” in <em>Proceedings of the 23rd international conference on machine learning</em>, 2006, pp. 649–656. </p>
</div>
<div id="ref-gervais2014privacy">
<p>[7] A. Gervais, S. Capkun, G. O. Karame, and D. Gruber, “On the privacy provisions of bloom filters in lightweight bitcoin clients,” in <em>Proceedings of the 30th annual computer security applications conference</em>, 2014, pp. 326–335. </p>
</div>
</div>
</section>
<section class="footnotes">
<hr />
<ol>
<li id="fn1"><p>We will only consider polynomial-time adversaries here.<a href="#fnref1" class="footnoteBack">↩</a></p></li>
<li id="fn2"><p>For this reason, a <em>yes</em>-answer is also referred to as a <em>maybe</em>-answer in some texts.<a href="#fnref2" class="footnoteBack">↩</a></p></li>
<li id="fn3"><p>A CDN (Content Delivery Network) is a globally distributed network of proxy servers deployed in multiple data centers, in order to serve cached content to end-users with high availability and high performance.<a href="#fnref3" class="footnoteBack">↩</a></p></li>
<li id="fn4"><p>In this work, we will consider only steady representations.<a href="#fnref4" class="footnoteBack">↩</a></p></li>
<li id="fn5"><p>The security parameter <span class="math inline">\(\lambda\)</span> is implied in the initialization algorithm <span class="math inline">\(\mathbf{B}_1\)</span>, thus we denote it as <span class="math inline">\(\mathbf{B}_1(1^\lambda,S)\)</span>.<a href="#fnref5" class="footnoteBack">↩</a></p></li>
<li id="fn6"><p>To strengthen our definition, we assume that the adversary also gets the set <span class="math inline">\(S\)</span>, and it is important that the adversary can hardly find any false positive even if given <span class="math inline">\(S\)</span>.<a href="#fnref6" class="footnoteBack">↩</a></p></li>
<li id="fn7"><p>A proof of this can be found in <span class="citation" data-cites="naor2015bloom">[5]</span>.<a href="#fnref7" class="footnoteBack">↩</a></p></li>
<li id="fn8"><p>Learning model of adaptively changing distributions (ACD).<a href="#fnref8" class="footnoteBack">↩</a></p></li>
</ol>
</section>

]]>
    </content>
  </entry>
  <entry>
    <title>The Decisional Hardness</title>
    <link rel="alternate" type="text/html" href="https://www.soimort.org/mst/1" />
    <id>tag:www.soimort.org,2017:/mst/1</id>
    <published>2016-11-01T00:00:00+01:00</published>
    <updated>2016-11-20T00:00:00+01:00</updated>
    <author>
      <name>Mort Yao</name>
    </author>
    
    <content type="html" xml:lang="en" xml:base="https://www.soimort.org/">
<![CDATA[
<p><p style='background-color:yellow'> <strong>(20 Nov 2016) Correction:</strong> P ≠ NP is not sufficient to imply that one-way functions exist. See <a href="#p-versus-np-problem-and-one-way-functions">P versus NP problem and one-way functions</a>.</p></p>
<hr />
<p><strong>Intro.</strong> Starting from November, I’ll summarize my study notes on <a href="https://wiki.soimort.org">wiki</a> into weekly blog posts. I always wanted to keep my study progress on track; I feel that it’s hard even to convince myself without visible footprints.</p>
<p>So here we have the first episode. (Hopefully it won’t be the last one)</p>
<hr />
<p>Asymptotic notation is an important tool in analyzing the time/space efficiency of algorithms.</p>
<ul>
<li><a href="https://wiki.soimort.org/math/calculus/limit/">Limit</a>
<ul>
<li>Formal definition of limit (the (ε, δ)-definition) in calculus. Note that limits involving infinity are closely related to asymptotic analysis. In addition to basic limit rules, L’Hôpital’s rule is also relevant.</li>
</ul></li>
<li><a href="https://wiki.soimort.org/algo/asymptotic-notation/">Asymptotic notation</a>
<ul>
<li>Introduction to the Bachmann–Landau notation family (among them are the most widely-used Big O notation and Big Theta notation).</li>
<li>Master theorem is used to find the asymptotic bound for recurrence. This is particularly helpful when analyzing recursive algorithms (e.g., binary search, merge sort, tree traversal).</li>
<li>Based on common orders of asymptotic running time using Big O notation, we can categorize algorithms into various classes of time complexities (among them are P, DLOGTIME, SUBEXP and EXPTIME). Note that we have not formally defined the word “algorithm” and “complexity class” yet.</li>
</ul></li>
</ul>
<p>For decision problems, we now formally define the time complexity classes P and NP, and propose the hardness of NP-complete problems, which plays an indispensable role in the study of algorithm design and modern cryptography.</p>
<ul>
<li><a href="https://wiki.soimort.org/comp/language/">Formal language</a>
<ul>
<li>Formal definition of language. We will revisit this when studying formal grammars like the context-free grammar and parsing techniques for compilers. For now, it suffices to know that binary string is a common encoding for all kinds of problems (especially, decision problems).</li>
</ul></li>
<li><a href="https://wiki.soimort.org/comp/decidability/">Decidability</a>
<ul>
<li>Among all abstract problems, we are mostly interested in decision problems.</li>
<li>The decidability of a language depends on whether there exists an algorithm that decides it.</li>
</ul></li>
<li><a href="https://wiki.soimort.org/comp/reducibility/">Reducibility</a>
<ul>
<li>Polynomial-time reduction is a commonly used technique that maps one language to another.</li>
<li>What is a hard language for a complexity class; what is a complete language for a complexity class.</li>
</ul></li>
<li><a href="https://wiki.soimort.org/comp/complexity/time/">Time complexity</a>
<ul>
<li>Encodings of concrete problems matter. Normally we would choose a “standard encoding” for our language of interest.</li>
<li>Polynomial-time algorithms are considered to be efficient and languages which have polynomial-time algorithms that decide them are considered tractable.</li>
<li>P is the time complexity class of all problems that are polynomial-time solvable.</li>
<li>NP is the time complexity class of all problems that are polynomial-time verifiable.</li>
</ul></li>
<li><a href="https://wiki.soimort.org/comp/complexity/time/npc/">NP-completeness</a>
<ul>
<li>The set of languages that are complete for the complexity class NP, that is, the “hardest problems” in NP.</li>
<li>NP-complete problems are central in answering the open question whether P = NP.</li>
<li>We (informally) show that every NP problem is polynomial-time reducible to CIRCUIT-SAT, and that CIRCUIT-SAT is NP-complete.</li>
<li>There are other problems (SAT, 3-CNF-SAT, CLIQUE, VERTEX-COVER, HAM-CYCLE, TSP, SUBSET-SUM) polynomial-time reducible from one to another, thus they are also shown to be NP-complete.</li>
</ul></li>
</ul>
<p><strong>Computational hardness assumption P ≠ NP.</strong> Although it is still an open proposition, many believe that P ≠ NP. Notably, if P ≠ NP holds true,</p>
<ol type="1">
<li>If a decision problem is polynomial-time unsolvable in general case, we should strive to find approximations or randomized algorithms; exact algorithms cannot be run in worst-case polynomial time thus may not be efficient. This applies to optimization problems too.</li>
<li><del>
One-way functions exist, which implies that pseudorandom generators and functions exist. Consequently, many cryptographic constructions (private-key encryption, MACs, etc.) are provably computationally secure.
</del></li>
</ol>
<p><p style='background-color:yellow'> (I stand corrected: There is no such a known proof showing that P ≠ NP implies the existence of one-way functions. However, reversely, the existence of one-way functions implies that P ≠ NP. There is an informal argument given by Peter Shor on StackExchange<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>, rephrased in the section <a href="#p-versus-np-problem-and-one-way-functions">P versus NP problem and one-way functions</a>.)</p></p>
<p>Later we will cover the notion of security in cryptography, so there is a refresher of basic probability: (Probability is also considerably used in analyzing the behaviors of non-deterministic algorithms, hash functions, etc.)</p>
<ul>
<li><a href="https://wiki.soimort.org/math/probability/">Probability</a>
<ul>
<li>An intuitive introduction to basic probability theory based on Kolmogorov’s axioms, including the union bound (Boole’s inequality) and its generalized form Bonferroni inequalities, the conditional probability and Bayes’ theorem. We will revisit the notion of probability space when coming to measure theory.</li>
</ul></li>
</ul>
<p>Plan for next week:</p>
<ul>
<li><strong>(Algorithms)</strong> More involved NP-complete problems. Exact algorithms. Approximation algorithms. Probabilistic algorithms.</li>
<li><strong>(Cryptography)</strong> Information-theoretic/computational security (semantic security, IND, IND-CPA, IND-CCA). Private-key encryption. Message authentication codes. Hash functions. Theoretical constructions (one-way functions, pseudorandomness). Practical constructions (Feistel network, substitution-permutation network, DES, AES).</li>
</ul>
<section id="p-versus-np-problem-and-one-way-functions" class="level2">
<h2>P versus NP problem and one-way functions</h2>
<p>Consider the following map: <span class="math display">\[f : (x, r) \to s\]</span> where <span class="math inline">\(x\)</span> is an arbitrary bit string, <span class="math inline">\(r\)</span> is a string of random bits, and <span class="math inline">\(s\)</span> is an instance of a <span class="math inline">\(k\)</span>-SAT problem having <span class="math inline">\(x\)</span> as a planted solution, while the randomness of <span class="math inline">\(r\)</span> determines uniquely which <span class="math inline">\(k\)</span>-SAT problem to choose.</p>
<p>If we can invert the above function <span class="math inline">\(f\)</span> (in polynomial time), we must already have solved the corresponding <span class="math inline">\(k\)</span>-SAT problem <span class="math inline">\(s\)</span> with a planted solution <span class="math inline">\(x\)</span>. <span class="math inline">\(k\)</span>-SAT problems are known to be NP-complete, and inverting such a function would be as hard as solving a <span class="math inline">\(k\)</span>-SAT problem with a planted solution, that is, inverting <span class="math inline">\(f\)</span> <em>at one point</em> can be hard. Clearly, should we have a one-way function, then inverting it is guaranteed to be no easier than inverting <span class="math inline">\(f\)</span>.</p>
<p>So what does it mean if P ≠ NP? We know that <span class="math inline">\(k\)</span>-SAT problem is hard to solve in its <em>worst case</em>, so function <span class="math inline">\(f\)</span> can be made as hard to invert as solving a <span class="math inline">\(k\)</span>-SAT problem in its <em>worst case</em>. However, we don’t know whether it’s possible to have a class <span class="math inline">\(\mathcal{S}\)</span> of <span class="math inline">\(k\)</span>-SAT problems with planted solutions that are as hard as general-case <span class="math inline">\(k\)</span>-SAT problems. If such a class <span class="math inline">\(\mathcal{S}\)</span> exists, then given any <span class="math inline">\(s \in \mathcal{S}\)</span>, no probabilistic polynomial-time algorithm is able to get <span class="math inline">\(x\)</span> with a non-negligible probability, so we can conclude that <span class="math inline">\(f\)</span> is indeed a one-way function. <a href="#ref-selman1992survey"><span class="citation" data-cites="selman1992survey">[1]</span></a></p>
<p><strong>Problem 1.1.</strong> Does there exist a class <span class="math inline">\(\mathcal{S}\)</span> of <span class="math inline">\(k\)</span>-SAT problems with planted solutions, such that every <span class="math inline">\(L \in \mathcal{S}\)</span> is NP-hard?</p>
<p><strong>Conjecture 1.2.</strong> <em>If <span class="math inline">\(\mathrm{P} \neq \mathrm{NP}\)</span>, then one-way functions exist.</em></p>
<p>On the other hand, assume that <span class="math inline">\(f\)</span> is a one-way function, so that one-way functions do exist, then this implies that <span class="math inline">\(k\)</span>-SAT problem is hard to solve (in its worse case) by a polynomial-time algorithm, thus we have P ≠ NP. By modus tollens, if P = NP, then no one-way function exists. <a href="#ref-abadi1990generating"><span class="citation" data-cites="abadi1990generating">[2]</span></a></p>
<p><strong>Theorem 1.3.</strong> <em>If one-way functions exist, then <span class="math inline">\(\mathrm{P} \neq \mathrm{NP}\)</span>.</em></p>
<p><em>Proof.</em> <em>(Sketch)</em> Let <span class="math inline">\(f : \{0,1\}^*\to\{0,1\}^*\)</span> be a one-way function. There is a polynomial-time algorithm <span class="math inline">\(M_f\)</span> that computes <span class="math inline">\(y=f(x)\)</span> for all <span class="math inline">\(x\)</span>, thus, there exists a polynomial-time computable circuit that outputs <span class="math inline">\(y=f(x)\)</span> for all <span class="math inline">\(x\)</span>.</p>
<p>Since <span class="math inline">\(f\)</span> is a one-way function, that is, for every probabilistic polynomial-time algorithm <span class="math inline">\(\mathcal{A}\)</span>, there is a negligible function <span class="math inline">\(\mathsf{negl}\)</span> such that <span class="math inline">\(\Pr[\mathsf{Invert}_{\mathcal{A},f}(n) = 1] \leq \mathsf{negl}(n)\)</span>, so we know that no <span class="math inline">\(\mathcal{A}\)</span> can fully compute <span class="math inline">\(f^{-1}(x)\)</span> for any given <span class="math inline">\(x\)</span>. <span class="math inline">\(\mathcal{A}\)</span> fully computes <span class="math inline">\(f^{-1}\)</span> if and only if it solves the corresponding <code>CIRCUIT-SAT</code> problems of the circuit in all cases. Thus, there must exist some <code>CIRCUIT-SAT</code> problems that cannot be decided by a polynomial-time algorithm, therefore, <span class="math inline">\(\mathrm{P} \neq \mathrm{NP}\)</span>. <p style='text-align:right !important;text-indent:0 !important;position:relative;top:-1em'>&#9632;</p></p>
<p><em>Remark 1.4.</em> If one can come up with a construction of the one-way function or a proof that such functions exist, then it holds true that <span class="math inline">\(\mathrm{P} \neq \mathrm{NP}\)</span>.</p>
</section>
<section id="references-and-further-reading" class="level2">
<h2>References and further reading</h2>
<p><strong>Books:</strong></p>
<p>T. H. Cormen, C. E. Leiserson, R. L. Rivest, and C. Stein, <em>Introduction to Algorithms</em>, 3rd ed.</p>
<p>M. Sipser, <em>Introduction to the Theory of Computation</em>, 3rd ed.</p>
<p>J. Katz and Y. Lindell, <em>Introduction to Modern Cryptography</em>, 2nd ed.</p>
<p><strong>Papers:</strong></p>
<div id="refs" class="references">
<div id="ref-selman1992survey">
<p>[1] A. L. Selman, “A survey of one-way functions in complexity theory,” <em>Mathematical Systems Theory</em>, vol. 25, no. 3, pp. 203–221, 1992. </p>
</div>
<div id="ref-abadi1990generating">
<p>[2] M. Abadi, E. Allender, A. Broder, J. Feigenbaum, and L. A. Hemachandra, “On generating solved instances of computational problems,” in <em>Proceedings on advances in cryptology</em>, 1990, pp. 297–310. </p>
</div>
</div>
</section>
<section class="footnotes">
<hr />
<ol>
<li id="fn1"><p><a href="http://cstheory.stackexchange.com/a/8843/21291" class="uri">http://cstheory.stackexchange.com/a/8843/21291</a><a href="#fnref1" class="footnoteBack">↩</a></p></li>
</ol>
</section>

]]>
    </content>
  </entry>
</feed>
